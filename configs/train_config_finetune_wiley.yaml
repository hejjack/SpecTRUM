data_args:
  show_raw_preds: true
  buffer_size: 100000
  data_seed: 42
  shuffle_train: true
  dataset_for_choosing_best_model: NIST
  datasets:
    NIST:
      train_path: ../data/datasets/NIST/NIST_split_filip/train.jsonl
      valid_path: ../data/datasets/NIST/NIST_split_filip/valid.jsonl
      weight: 1.0
      limit_train_split: null
      limit_val_split: null
      limit_example_split: 100
      source_token: <nist>
    WILEY:
      train_path: ../data/datasets/WILEY/train.jsonl
      valid_path: ../data/datasets/WILEY/valid.jsonl
      weight: 1.0
      limit_train_split: null
      limit_val_split: null
      limit_example_split: 100
      source_token: <source1>

preprocess_args:
  log_base: 1.2
  log_shift: 39

model_args:
  tokenizer_path: ../tokenizer/bbpe_tokenizer/bart_bbpe_tokenizer_1M_mf10000000.model
  decoder_seq_len: 200
  max_mz: 500
  separate_encoder_decoder_embeds: true
  encoder_layers: 12
  encoder_ffn_dim: 4096
  encoder_attention_heads: 16
  decoder_layers: 12
  decoder_ffn_dim: 4096
  decoder_attention_heads: 16


example_generation_args:
  top_k: null
  top_p: null
  do_sample: true
  num_beams: 5
  temperature: null
  penalty_alpha: null
  num_return_sequences: 1
  length_penalty: 1.0


hf_training_args:
  do_train: True
  do_eval: True

  max_steps: 74_000
  optim: "adamw_torch"
  warmup_steps: 1000

  learning_rate: 0.00005
  auto_bs: True
  bart_size: "base" # "large" or "base"
  effective_train_batch_size: 128
  effective_eval_batch_size: 128

  dataloader_num_workers: 6
  dataloader_drop_last: False

  report_to: "wandb" # "wandb"
  remove_unused_columns: False # NEVER TOUCH THIS
  logging_steps: 5

  fp16: True
  seed: 42

  predict_with_generate: True # NEVER TOUCH THIS
  generation_num_beams: 1
  generation_max_length: 200  # NEVER TOUCH THIS
  evaluation_strategy: "steps"
  eval_steps: 5267 ### make it match (5267 ~ approx 3*full NIST dataset)

  save_steps: 5267 ### make it match (5267 ~ approx 3*full NIST dataset)
  save_strategy: "steps"
  save_total_limit: 3

  load_best_model_at_end: True
  metric_for_best_model: "eval_morgan_tanimoto_simil"
  greater_is_better: True
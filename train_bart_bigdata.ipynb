{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "actual-transfer",
   "metadata": {},
   "source": [
    "## My train using Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-procedure",
   "metadata": {},
   "source": [
    "Training BART with a changed script from the BERT project (adding position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-question",
   "metadata": {},
   "source": [
    "### !! PROBLEMS\n",
    "Miska call\n",
    "* chyba, ze mam jen jeden tokenizer.... PROC?\n",
    "* generate nezere position_ids \n",
    "* zkusit tomu nedavat decoder_input_ids, jenom labels (melo by si je to snad dopocitat z labels)... JO TO ASI POMOHLO\n",
    "    * prepare_decoder_input_ids_from_labels\n",
    "    * pokud nejsou shiftnuty labely doleva, vysvetluje to nizkou loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "visible-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.21.0\n",
    "# !pip install ipywidgets --user#\n",
    "#pip install pandas==1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afraid-incidence",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, BartConfig, BartForConditionalGeneration, logging\n",
    "# from transformers.file_utils import logging\n",
    "# from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "\n",
    "# custom veci\n",
    "from dataset import SpectroDataset, SpectroDataCollator\n",
    "sys.path.append('data')\n",
    "sys.path.append('bart_spektro')\n",
    "from modeling_bart_spektro import BartSpektoForConditionalGeneration\n",
    "from configuration_bart_spektro import BartSpektroConfig\n",
    "from data_preprocess1 import print_args\n",
    "from bart_spektro_tokenizer import BartSpektroTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# from utils import add_special_tokens, generate_sample, sample_seq, set_seed, top_k_top_p_filtering, print_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-bryan",
   "metadata": {},
   "source": [
    "#### Setting basic training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage-brno2/home/ahajek/Spektro/MassGenie\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equal-impression",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA: 8\n",
      "last checkpoint: ./models/bart_2022-06-28-10_02_31_bigdata/checkpoint-99704\n",
      "save checkpoint to: bart_2022-06-28-10_02_31_bigdata/\n"
     ]
    }
   ],
   "source": [
    "### TODO ###\n",
    "# alter log steps    ... will not do for now\n",
    "# alter save steps   ... will not do\n",
    "# alter eval steps   ... will not do\n",
    "# make a script that will run the training without jupyter\n",
    "\n",
    "ncpus=8 #16\n",
    "ngpus=2 #4\n",
    "bs = 32 #4\n",
    "gas = int(16/ngpus) # 16/int(os.environ[\"PBS_NGPUS\"]) #16\n",
    "print(\"GA:\", gas)\n",
    "which_bart = \"spektro\" #\"original\" # \"spektro\"\n",
    "data_type = \"8M\"\n",
    "tokenizer_type = \"_bbpe_1M\" # for spektro tokenizer use \"\"\n",
    "tokenizer = Tokenizer.from_file(f\"./tokenizer/bbpe_tokenizer/bart{tokenizer_type}_tokenizer.model\")\n",
    "\n",
    "SEQ_LEN = 200\n",
    "num_epochs = 20\n",
    "# 100 # 10 (BARTy se trenovaly 10 epoch celkem) # int(os.environ[\"TOTAL_EPOCHS\"])\n",
    "resume_training = True # True # bool(int(os.environ[\"RESUME_TRAINING\"]))\n",
    "resume_wandb_id = \"191h62zs\" # \"191h62zs\" #pass # \"\"\n",
    "\n",
    "model = None # aby nebyl nedefinovany\n",
    "\n",
    "# find the last checkpoint\n",
    "\n",
    "# models_pth = \"./models/bart_trial\"\n",
    "# runs = glob.glob(models_pth)\n",
    "# checkpoints =  glob.glob(runs[-1]+\"/checkpoint-*\")\n",
    "# checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "# load_checkpoint = checkpoints[-1]\n",
    "# print(f\"last checkpoint: {load_checkpoint}\")\n",
    "\n",
    "# load_checkpoint = \"./models/bart_2022-06-28-10_02_31/checkpoint-18128\"\n",
    "\n",
    "# LOAD CHECKPOINT FROM\n",
    "prefered_run = \"./models/bart_2022-06-28-10_02_31_bigdata/\"\n",
    "checkpoints =  glob.glob(prefered_run+\"checkpoint-*\")\n",
    "checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "load_checkpoint = checkpoints[-1]\n",
    "print(f\"last checkpoint: {load_checkpoint}\") # the newest from particular folder\n",
    "\n",
    "# SAVE CHECKPOINTS TO  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "save_checkpoint = \"bart_2022-06-28-10_02_31_bigdata/\" # if None -> saves to newly generated folder bart_{now}\n",
    "print(\"save checkpoint to:\", save_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-atlanta",
   "metadata": {},
   "source": [
    "#### Setting all training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exact-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "GPU-14fbf1d0-9297-ef80-4574-18d14d4b5767,GPU-e1c52ac4-fcc8-64da-9264-77f75c3d6ac3\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"PBS_NGPUS\"]\n",
    "!echo $PBS_NGPUS\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medieval-match",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "now = str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "now = now.replace(\":\",\"_\").replace(\" \", \"-\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n",
    "parser.add_argument(\"--gradient-accumulation-steps\",default=gas, type=int, help=\"gradient_accumulation_steps\")\n",
    "parser.add_argument(\"--batch-size\",default=bs, type=int,  help=\"batch_size\")\n",
    "parser.add_argument(\"--warmup\",default=500, type=int,  help=\"warmup steps for learning rate\")\n",
    "parser.add_argument(\"--weight-decay\",default=0.01, type=float,  help=\"weight decay rate parameter\")\n",
    "parser.add_argument(\"--n-gpu\",default=ngpus, type=int, required=False, help=\"no of gpu available\")\n",
    "parser.add_argument(\"--fairscale\",default=\"\", type=str, required=False, choices=[\"simple\", \"zero_dp_2\", \"zero_dp_3\"], help=\"GPU paralellization via Fairscale, \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--deepspeed\", default=None, type=str, required=False, help=\"GPU paralellization via Deepspeed, the value is the location of DeepSpeed json config file; \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--num-workers\",default=ncpus, type=int,  help=\"num of cpus available\")\n",
    "parser.add_argument(\"--device\",default=torch.device('cuda'), help=\"torch.device object\")\n",
    "parser.add_argument(\"--num-train-epochs\",default=num_epochs, type=int,  help=\"number of training epochs\")\n",
    "parser.add_argument(\"--output-dir\",default='./output', type=str,  help=\"Path to save evaluation results\")\n",
    "parser.add_argument(\"--save-dir\",default='./models', type=str,  help=\"Path to save trained model\")\n",
    "parser.add_argument(\"--save-name\", type=str, default=f'bart_{now}', help=\"Name of the model, used for saves\")\n",
    "parser.add_argument(\"--load-checkpoint\", type=str, default='', help=\"Path to the checkpoint to resume training\")\n",
    "parser.add_argument(\"--config-dir\",default='./configs', type=str,  help=\"Path to save config files of models\")\n",
    "parser.add_argument(\"--fp16\",default=True, type=bool, required=False, help=\"whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "parser.add_argument(\"--max-grad-norm\",default=1.0, type=float, help=\"max gradient norm.\")\n",
    "parser.add_argument(\"--train-data-path\",default=f'./data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_train.pkl', type=str, help=\"Path to jsonl train dataset\")\n",
    "parser.add_argument(\"--valid-data-path\",default=f'./data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_valid.pkl', type=str, help=\"Path to jsonl validation dataset\")\n",
    "parser.add_argument(\"--log-steps\",default=50, type=int,  help=\"number of steps between logs\")\n",
    "parser.add_argument(\"--eval-steps\",default=7142, type=int,  help=\"number of steps between evaluations\")\n",
    "parser.add_argument(\"--tokenizer-path\",default='/storage/brno6/home/ahajek/nic', type=str, help=\"location of the desied tokenizer (special sep token will be added))\")\n",
    "parser.add_argument(\"--model-path\",default='./models/NECO', type=str, help=\"location of the desired model to finetune\")\n",
    "parser.add_argument(\"--wandb\", action='store_true', default=True, help=\"optinal logging via Weights&Biases\")\n",
    "parser.add_argument(\"--wandb-resume\", action='store_true', default=resume_training, help=\"resume logging via wandb, needs an valid run ID set in args.wandb-id\")\n",
    "parser.add_argument(\"--wandb-id\", type=str, default=wandb.util.generate_id(), help=\"Process unique wandb ID used for resumin the training process\")\n",
    "parser.add_argument(\"--tensorboard\", action='store_true', default=False, help=\"optinal logging via TensorBoard\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# extended outputs\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-bargain",
   "metadata": {},
   "source": [
    "#### Loading data, tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brilliant-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART CONIGURATION\n",
    "if which_bart == \"spektro\":\n",
    "    config = BartSpektroConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12,\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0,\n",
    "                                 max_log_id=9)\n",
    "\n",
    "if which_bart == \"original\":\n",
    "    config = BartConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12,\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "varied-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "args.save_name = save_checkpoint if save_checkpoint else args.save_name # change args only if user specifies different save name in the initial cell\n",
    "\n",
    "args.train_data_path = \"./data/trial_set/8M_bbpe_1M_bart_prepared_data_train.pkl\"\n",
    "args.valid_data_path = \"./data/trial_set/8M_bbpe_1M_bart_prepared_data_valid_half.pkl\"\n",
    "\n",
    "train_data = SpectroDataset(args.train_data_path, original=which_bart==\"original\")\n",
    "valid_data = SpectroDataset(args.valid_data_path, original=which_bart==\"original\")\n",
    "\n",
    "# clean memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arabic-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kratkej vypis :D\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "if which_bart == \"original\":\n",
    "    model = BartForConditionalGeneration(config)\n",
    "else:\n",
    "    model = BartSpektoForConditionalGeneration(config)\n",
    "# model = BartForConditionalGeneration.from_pretrained(args.model_path)\n",
    "model.to(args.device)\n",
    "\n",
    "print(\"kratkej vypis :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lovely-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 1M dataset\n",
    "# train_data.data.rename(columns={\"lm_labels\":\"labels\"}, inplace=True)\n",
    "# valid_data.data.rename(columns={\"lm_labels\":\"labels\"}, inplace=True)\n",
    "if which_bart == \"original\":\n",
    "    try:\n",
    "        train_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        train_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "humanitarian-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destereo_smiles</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>decoder_input_ids</th>\n",
       "      <th>encoder_attention_mask</th>\n",
       "      <th>decoder_attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>position_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(cc1)CNN=Nc1ccccc1</td>\n",
       "      <td>[14, 15, 26, 27, 28, 29, 30, 32, 33, 37, 38, 3...</td>\n",
       "      <td>[3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...</td>\n",
       "      <td>[2, 0, 3, 5, 6, 3, 5, 1, 2, 3, 5, 8, 6, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C1CCC2C(C3C1C3(C)C)C(CC2)(C)O</td>\n",
       "      <td>[26, 27, 28, 29, 30, 31, 37, 38, 39, 40, 41, 4...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...</td>\n",
       "      <td>[5, 8, 6, 8, 5, 6, 1, 5, 8, 7, 9, 7, 9, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC(=S)C1(CCC1)COc1ccccc1</td>\n",
       "      <td>[14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30, 3...</td>\n",
       "      <td>[3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...</td>\n",
       "      <td>[1, 3, 2, 3, 3, 1, 5, 7, 6, 6, 4, 4, 2, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cccc2c1n(CC(=O)C)c(cc2=O)C</td>\n",
       "      <td>[14, 15, 26, 27, 29, 31, 33, 37, 38, 39, 40, 4...</td>\n",
       "      <td>[3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...</td>\n",
       "      <td>[0, 2, 1, 1, 3, 1, 3, 4, 6, 7, 6, 7, 7, 9, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clc1cccc(c1)n1c(=O)cc([nH]c1=O)C(=O)O</td>\n",
       "      <td>[25, 26, 29, 33, 34, 35, 36, 37, 38, 39, 40, 4...</td>\n",
       "      <td>[3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...</td>\n",
       "      <td>[1, 2, 0, 1, 3, 6, 7, 7, 8, 8, 8, 8, 8, 7, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641073</th>\n",
       "      <td>Oc1ccc(cc1)C1CCN(CC1)C(=O)c1ccco1</td>\n",
       "      <td>[33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...</td>\n",
       "      <td>[3, 3, 4, 6, 8, 6, 7, 7, 6, 6, 4, 3, 5, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641074</th>\n",
       "      <td>CC(=O)Nc1ccc(cc1)C(c1ccc(cc1)C)(C)C</td>\n",
       "      <td>[33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 50, 5...</td>\n",
       "      <td>[3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...</td>\n",
       "      <td>[2, 2, 3, 7, 6, 8, 5, 9, 5, 2, 6, 7, 6, 7, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641075</th>\n",
       "      <td>Brc1ccc(cc1)C(c1ccncc1)N</td>\n",
       "      <td>[14, 15, 17, 18, 25, 26, 27, 28, 29, 30, 34, 3...</td>\n",
       "      <td>[3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...</td>\n",
       "      <td>[0, 2, 2, 1, 1, 5, 5, 6, 4, 3, 1, 3, 6, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641076</th>\n",
       "      <td>OC(=O)c1cc(nc2c1c(C)no2)c1ccccc1F</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...</td>\n",
       "      <td>[6, 3, 5, 6, 7, 9, 8, 8, 8, 8, 9, 9, 6, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641077</th>\n",
       "      <td>CCN(C(=O)C1CC(CN1C(=O)c1n[nH]c2c1CCC2)N)CC</td>\n",
       "      <td>[31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...</td>\n",
       "      <td>[3, 5, 4, 4, 3, 5, 8, 7, 9, 9, 7, 9, 7, 6, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4641078 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    destereo_smiles  \\\n",
       "0                           c1ccc(cc1)CNN=Nc1ccccc1   \n",
       "1                   O=C1CCC2C(C3C1C3(C)C)C(CC2)(C)O   \n",
       "2                          NC(=S)C1(CCC1)COc1ccccc1   \n",
       "3                    COc1cccc2c1n(CC(=O)C)c(cc2=O)C   \n",
       "4             Clc1cccc(c1)n1c(=O)cc([nH]c1=O)C(=O)O   \n",
       "...                                             ...   \n",
       "4641073           Oc1ccc(cc1)C1CCN(CC1)C(=O)c1ccco1   \n",
       "4641074         CC(=O)Nc1ccc(cc1)C(c1ccc(cc1)C)(C)C   \n",
       "4641075                    Brc1ccc(cc1)C(c1ccncc1)N   \n",
       "4641076           OC(=O)c1cc(nc2c1c(C)no2)c1ccccc1F   \n",
       "4641077  CCN(C(=O)C1CC(CN1C(=O)c1n[nH]c2c1CCC2)N)CC   \n",
       "\n",
       "                                                 input_ids  \\\n",
       "0        [14, 15, 26, 27, 28, 29, 30, 32, 33, 37, 38, 3...   \n",
       "1        [26, 27, 28, 29, 30, 31, 37, 38, 39, 40, 41, 4...   \n",
       "2        [14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30, 3...   \n",
       "3        [14, 15, 26, 27, 29, 31, 33, 37, 38, 39, 40, 4...   \n",
       "4        [25, 26, 29, 33, 34, 35, 36, 37, 38, 39, 40, 4...   \n",
       "...                                                    ...   \n",
       "4641073  [33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "4641074  [33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 50, 5...   \n",
       "4641075  [14, 15, 17, 18, 25, 26, 27, 28, 29, 30, 34, 3...   \n",
       "4641076  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "4641077  [31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...   \n",
       "\n",
       "                                         decoder_input_ids  \\\n",
       "0        [3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...   \n",
       "1        [3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...   \n",
       "2        [3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...   \n",
       "3        [3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...   \n",
       "4        [3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...   \n",
       "...                                                    ...   \n",
       "4641073  [3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...   \n",
       "4641074  [3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...   \n",
       "4641075  [3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...   \n",
       "4641076  [3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...   \n",
       "4641077  [3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...   \n",
       "\n",
       "                                    encoder_attention_mask  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                    ...   \n",
       "4641073  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641074  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641075  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641076  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641077  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                    decoder_attention_mask  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                    ...   \n",
       "4641073  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641074  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641075  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641076  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641077  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                    labels  \\\n",
       "0        [3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...   \n",
       "1        [3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...   \n",
       "2        [3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...   \n",
       "3        [3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...   \n",
       "4        [3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...   \n",
       "...                                                    ...   \n",
       "4641073  [3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...   \n",
       "4641074  [3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...   \n",
       "4641075  [3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...   \n",
       "4641076  [3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...   \n",
       "4641077  [3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...   \n",
       "\n",
       "                                              position_ids  \n",
       "0        [2, 0, 3, 5, 6, 3, 5, 1, 2, 3, 5, 8, 6, 7, 6, ...  \n",
       "1        [5, 8, 6, 8, 5, 6, 1, 5, 8, 7, 9, 7, 9, 6, 6, ...  \n",
       "2        [1, 3, 2, 3, 3, 1, 5, 7, 6, 6, 4, 4, 2, 4, 4, ...  \n",
       "3        [0, 2, 1, 1, 3, 1, 3, 4, 6, 7, 6, 7, 7, 9, 7, ...  \n",
       "4        [1, 2, 0, 1, 3, 6, 7, 7, 8, 8, 8, 8, 8, 7, 9, ...  \n",
       "...                                                    ...  \n",
       "4641073  [3, 3, 4, 6, 8, 6, 7, 7, 6, 6, 4, 3, 5, 7, 6, ...  \n",
       "4641074  [2, 2, 3, 7, 6, 8, 5, 9, 5, 2, 6, 7, 6, 7, 3, ...  \n",
       "4641075  [0, 2, 2, 1, 1, 5, 5, 6, 4, 3, 1, 3, 6, 7, 7, ...  \n",
       "4641076  [6, 3, 5, 6, 7, 9, 8, 8, 8, 8, 9, 9, 6, 3, 0, ...  \n",
       "4641077  [3, 5, 4, 4, 3, 5, 8, 7, 9, 9, 7, 9, 7, 6, 2, ...  \n",
       "\n",
       "[4641078 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.input_ids])\n",
    "# assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.decoder_input_ids])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.encoder_attention_mask])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.decoder_attention_mask])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.labels])\n",
    "if which_bart == \"spektro\":\n",
    "    assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.position_ids])\n",
    "    \n",
    "# NA TOTO BACHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA  POZOOOOOOOOOOOOOOOOOR POZOROROROROROROROROROORORORORORKVOKVOEK    \n",
    "# train_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "# valid_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "informal-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair type at position_ids\n",
    "\n",
    "#for x in train_data.data.position_ids:\n",
    "# #     print(x.dtype)\n",
    "#     if x.dtype != np.dtype('int32'):\n",
    "#         print(x)\n",
    "# train_data.data.position_ids[0].dtype == np.dtype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hydraulic-principle",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 354200576\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-circulation",
   "metadata": {},
   "source": [
    "#### Setting run resuming and WandB logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "material-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhajekad\u001b[0m (\u001b[33mmsgc_boys\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhajekad\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/storage-brno2/home/ahajek/Spektro/MassGenie/wandb/run-20220829_084849-191h62zs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hajekad/BART_for_gcms/runs/191h62zs\" target=\"_blank\">bart_2022-06-28-10_02_31_bigdata/</a></strong> to <a href=\"https://wandb.ai/hajekad/BART_for_gcms\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resume training\n",
    "if resume_training:\n",
    "    args.load_checkpoint = load_checkpoint\n",
    "    if args.wandb_resume:\n",
    "        args.wandb_id = resume_wandb_id\n",
    "\n",
    "# Init wandb\n",
    "if args.wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(id=args.wandb_id, resume=\"allow\", entity=\"hajekad\", project=\"BART_for_gcms\")\n",
    "    wandb.run.name = args.save_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-sewing",
   "metadata": {},
   "source": [
    "#### Setting training arguments (according to args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "piano-discount",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=args.save_dir+\"/\"+args.save_name,         # output directory\n",
    "    num_train_epochs=args.num_train_epochs,              # total # of training epochs\n",
    "    per_device_train_batch_size=args.batch_size,         # batch size per device during training\n",
    "    per_device_eval_batch_size=args.batch_size,          # batch size for evaluation\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    warmup_steps=args.warmup,                                    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=args.weight_decay,                                   # strength of weight decay\n",
    "    logging_dir=args.save_dir + './logs',                # directory for storing logs\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=args.save_name,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "#     eval_steps=args.eval_steps,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1, # args.log_steps,\n",
    "    save_strategy=\"epoch\",\n",
    "#     save_steps=1000,\n",
    "    fp16=args.fp16,\n",
    "    dataloader_drop_last=True,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=args.num_workers,\n",
    "    sharded_ddp=args.fairscale,\n",
    "    deepspeed=args.deepspeed,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=valid_data,             # evaluation dataset\n",
    "    data_collator = SpectroDataCollator(original=(which_bart==\"original\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-program",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-singing",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments:\n",
      "  lr ........................... 5e-05\n",
      "  seed ......................... 42\n",
      "  gradient_accumulation_steps .. 8\n",
      "  batch_size ................... 32\n",
      "  warmup ....................... 500\n",
      "  weight_decay ................. 0.01\n",
      "  n_gpu ........................ 2\n",
      "  fairscale .................... \n",
      "  deepspeed .................... None\n",
      "  num_workers .................. 8\n",
      "  device ....................... cuda\n",
      "  num_train_epochs ............. 20\n",
      "  output_dir ................... ./output\n",
      "  save_dir ..................... ./models\n",
      "  save_name .................... bart_2022-06-28-10_02_31_bigdata/\n",
      "  load_checkpoint .............. ./models/bart_2022-06-28-10_02_31_bigdata/checkpoint-99704\n",
      "  config_dir ................... ./configs\n",
      "  fp16 ......................... True\n",
      "  max_grad_norm ................ 1.0\n",
      "  train_data_path .............. ./data/trial_set/8M_bbpe_1M_bart_prepared_data_train.pkl\n",
      "  valid_data_path .............. ./data/trial_set/8M_bbpe_1M_bart_prepared_data_valid_half.pkl\n",
      "  log_steps .................... 50\n",
      "  eval_steps ................... 7142\n",
      "  tokenizer_path ............... /storage/brno6/home/ahajek/nic\n",
      "  model_path ................... ./models/NECO\n",
      "  wandb ........................ True\n",
      "  wandb_resume ................. True\n",
      "  wandb_id ..................... 191h62zs\n",
      "  tensorboard .................. False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from ./models/bart_2022-06-28-10_02_31_bigdata/checkpoint-99704.\n",
      "/storage/brno2/home/ahajek/.local-PyTorch:22.04.SIF/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4641078\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 181280\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 11\n",
      "  Continuing training from global step 99704\n",
      "  Will skip the first 11 epochs then the first 0 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012169837951660156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62586ed8d7a45ff81c3ba559c95261a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99839' max='181280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 99839/181280 04:50 < 49:24:15, 0.46 it/s, Epoch 11.01/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log args to \"args\" file in args.save_dir (right before the training starts, to be the latest)\n",
    "Path(f'{args.save_dir}/{args.save_name}').mkdir(exist_ok=True)\n",
    "arg_log = print_args(args)\n",
    "with open(f'{args.save_dir}/{args.save_name}/args', 'w+') as output_file:\n",
    "    output_file.write(arg_log)\n",
    "\n",
    "if args.load_checkpoint:\n",
    "    trainer.train(args.load_checkpoint)\n",
    "else:\n",
    "    #trainer.evaluate()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-supply",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# tokenizer = BartSpektroTokenizer().init_tokenizer()\n",
    "tok = \"./tokenizer/bbpe_tokenizer/bart_bbpe_1M_tokenizer.model\"\n",
    "tokenizer = Tokenizer.from_file(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-worship",
   "metadata": {},
   "source": [
    "#### Generate and display SMILES from valid data and show the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import glob \n",
    "\n",
    "# load model if not defined\n",
    "model=None     # force the model loading\n",
    "if not model:\n",
    "    models_pth = \"./models/*\"\n",
    "    runs = glob.glob(models_pth)\n",
    "    print(runs)\n",
    "    checkpoints =  glob.glob(sorted(runs)[-3]+\"/checkpoint-*\")\n",
    "    checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    print(checkpoints)\n",
    "    load_checkpoint = checkpoints[-1]\n",
    "    print(f\"last checkpoint: {load_checkpoint}\")\n",
    "    model = BartSpektoForConditionalGeneration.from_pretrained(load_checkpoint)\n",
    "    model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = valid_data[500] # 489\n",
    "    outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "    generated = model.generate(\n",
    "               input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "               bos_token_id=503,\n",
    "               forced_bos_token_id=503,\n",
    "               top_p=0.5,\n",
    "               top_k=50,\n",
    "               min_length=30,\n",
    "               do_sample=True,\n",
    "               temperature=0.7\n",
    "               ).tolist()[0],\n",
    "               \n",
    "\n",
    "\n",
    "# print(\"ground truth:\", tokenizer.ids_to_smiles(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "# print(\"ground truth:\", tokenizer.decode(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "print(\"ground truth ids:\", tokenizer.decode(np.array(inputs[\"labels\"].tolist())*np.array(inputs[\"decoder_attention_mask\"].tolist())), \"\\n\\n\")\n",
    "print(\"mask:\", inputs[\"decoder_attention_mask\"].tolist(), \"\\n\\n\")\n",
    "print(\"generated:\", generated, \"\\n\")\n",
    "# print(\"generated:\", tokenizer.ids_to_smiles(generated[0]), \"\\n\")\n",
    "print(\"generated:\", tokenizer.decode(generated[0]), \"\\n\")\n",
    "print(f\"loss: {outputs.loss}\")\n",
    "print(f\"logit bos: {outputs.logits[0][68][503].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "x = outputs.logits[0][10].cpu().numpy()\n",
    "top_k = np.partition(x, -k)[-k:]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-facing",
   "metadata": {},
   "source": [
    "### Run evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-coalition",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=valid_data,             # evaluation dataset\n",
    "    data_collator = SpectroDataCollator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# own evaluation \n",
    "model.eval()\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1000)):#tqdm(range(valid_data.len)):\n",
    "        inputs = valid_data[i]\n",
    "        outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "        losses.append(outputs.loss.item())\n",
    "print(f\"my evaluation loss: {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-expense",
   "metadata": {},
   "source": [
    "### Debugging tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokenizer(t):\n",
    "    print(f\"tok to id: {t.tok_to_id.items()}\\n\")\n",
    "    print(f\"id to tok: {t.id_to_tok.items()}\\n\")\n",
    "    print(f\"tl to tok: {t.tl_to_tok.items()}\\n\")\n",
    "    print(f\"tok to tl: {t.tok_to_tl.items()}\\n\")\n",
    "\n",
    "    print(f\"unk_tok: {t.unk_tok}\")\n",
    "    print(f\"pad_tok: {t.pad_tok}\")\n",
    "    print(f\"eos_tok: {t.eos_tok}\")\n",
    "    print(f\"bos_tok: {t.bos_tok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-ordering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.ids_to_smiles([501])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-rolling",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

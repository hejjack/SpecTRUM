command: ../predict.py --checkpoint ../checkpoints/finetune/fearless-wildflower-490_rassp1_neims1_224kPretrain_148k/checkpoint-147476
  --output-folder ../predictions --config-file ../configs/predict_config_nist_test.yaml
cuda_visible_devices: GPU-83f9775f-f502-4683-141b-c510e5f0c080
dataloader:
  batch_size: 1
  num_workers: 1
dataset:
  data_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  data_split: test
  dataset_name: NIST_denovo
general:
  additional_naming_info: beam10
  device: cuda
generation_args:
  do_sample: false
  length_penalty: 1.0
  max_length: 200
  num_beams: 10
  num_return_sequences: 10
  penalty_alpha: null
  temperature: null
  top_k: null
  top_p: null
preprocess_args:
  inference_mode: false
  keep_all_columns: true
  log_base: 1.2
  log_shift: 39
  max_cumsum: null
  max_mol_repr_len: 100
  max_mz: 500
  max_num_peaks: 300
  mol_repr: smiles
  restrict_intensities: false
  source_token: <nist>
start_loading_time: 15/05/2024 12:12:26
tokenizer_path: ../tokenizer/bbpe_tokenizer/bart_bbpe_tokenizer_1M_mf10000000.model
finished_time_utc: 15/05/2024 15:34:56
generation_time: 03:22:26
wall_time_utc: 03:22:29

evaluation_0:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds: '2236'
  counter_fp_simil_fails_preds_prob: '477'
  counter_invalid_preds: '0'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_invalid_preds: '0.0'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.565712668482683), (3, 0.6575512081225457),
    (4, 0.716064669048714), (5, 0.7542363887218311), (6, 0.7801323097604981), (7,
    0.7985283192415183), (8, 0.8098489404606077), (9, 0.8162167898963456), (10, 0.8190823221424276)]'
  start_time_utc: 16/05/2024 14:12:17
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_1:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7fe4de6c2940>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 15:52:34
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_2:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f2cfdac0940>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:57
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 15:57:18
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_3:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f14dd741940>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:00:54
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_4:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f373eb81790>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:07:36
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_5:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7fb0e2742790>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:59
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:10:11
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_6:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f4c91b02790>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:59
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:12:55
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_7:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f7290bc1790>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:24:26
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_8:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  counter_fp_simil_fails_preds_prob: '477'
  counter_fp_simil_fails_preds_simil: '98'
  counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f173c102700>,
    {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 00:00:58
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_better_than_threshold_probsort: '11789'
  num_better_than_threshold_similsort: '17930'
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  num_probsort_precise_preds: '11480'
  num_similsort_precise_preds: '17754'
  percentage_of_better_than_threshold_probsort: '0.41705876109951534'
  percentage_of_better_than_threshold_similsort: '0.6343085576821028'
  percentage_of_precise_preds_probsort: '0.40612728623483213'
  percentage_of_precise_preds_similsort: '0.6280822160116036'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  start_time_utc: 16/05/2024 16:36:23
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_9:
  counter_datapoints_tested: '28267'
  counter_empty_preds: '1'
  denovo:
    mean_db_score: '0.391845725802349'
    mean_fpsd_score_probsort: '0.25925609345001627'
    mean_fpsd_score_similsort: '0.4032522324284453'
    percentage_of_BART_wins_probsort: '0.751476987299678'
    percentage_of_BART_wins_similsort: '0.8755085435313262'
  eval_config:
    do_denovo: true
    filtering_args:
      max_mol_repr_len: 100
      max_mz: 500
      max_num_peaks: 300
      mol_repr: smiles
    fingerprint_type: morgan
    on_the_fly: true
    save_best_predictions: true
    simil_function: tanimoto
    threshold: 0.85
  eval_time: 01/01/1970 01:01:00
  formula_stats:
    num_all_correct_formulas: '69887'
    num_at_least_one_correct_formula: '23733'
    num_correct_formulas_at_best_prob: '18364'
    num_correct_formulas_at_best_simil: '17692'
    percentage_of_at_least_one_correct_formula: '0.10298144138436773'
    percentage_of_correct_formulas_at_best_prob: '0.07968445580341839'
    percentage_of_correct_formulas_at_best_simil: '0.07676853583500753'
  labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
  num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
    19932, 16257, 10611]'
  precise_preds_stats:
    num_precise_preds_probsort: '11003'
    num_precise_preds_similsort: '17656'
    percentage_of_precise_preds_probsort: '0.389252485230127'
    percentage_of_precise_preds_similsort: '0.6246152757632575'
  hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
    (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268), (7,
    0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271), (10, 0.6280822160116036)]'
  simil_1_hits:
    counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7efeb1544820>,
      {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2, 7: 23})'
    num_1_hits_as_first_probsort: '11480'
    num_1_hits_as_first_similsort: '17754'
    num_fp_simil_fail_prob: '477'
    num_fp_simil_fail_simil: '98'
    percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
    percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
  start_time_utc: 16/05/2024 20:23:44
  threshold_stats:
    num_better_than_threshold_probsort: '11789'
    num_better_than_threshold_similsort: '17930'
    percentage_of_better_than_threshold_probsort: '0.41705876109951534'
    percentage_of_better_than_threshold_similsort: '0.6343085576821028'
    threshold: '0.85'
  topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
    0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
    0.3561227651643802, 0.33264284264086164]'
  topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
    0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
    0.27273397560819046, 0.23961643287229908]'
evaluation_10:
    counter_datapoints_tested: '28267'
    counter_empty_preds: '1'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 01/01/1970 01:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '17692'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.625888845650405'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7efbb0d02820>,
            {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2,
            7: 23})'
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 16/05/2024 20:29:41
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_11:
    counter_datapoints_tested: '28267'
    counter_empty_preds: '1'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 01/01/1970 01:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: 'defaultdict(<function main.<locals>.<lambda> at 0x7f2e25d84790>,
            {1: 14797, 2: 1428, 3: 1012, 5: 134, 4: 291, 8: 13, 6: 47, 9: 7, 10: 2,
            7: 23})'
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 16/05/2024 20:36:40
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_12:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 01/01/1970 01:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 10:26:38
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_13:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 01/01/1970 01:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 16:48:23
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_14:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 18:18:36
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_15:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 18:45:38
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_16:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 18:53:20
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_17:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 19:05:13
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_18:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 17/05/2024 19:10:03
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_19:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.0778292708812396'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.8964428977272727'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '2200'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.8086363636363636'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:00
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 18/05/2024 23:07:59
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_20:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.13641348569002723'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.7250375498058265'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '3856'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.46135892116182575'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:03
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 20/05/2024 19:44:06
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_21:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.13641348569002723'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.7250375498058265'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '3856'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.46135892116182575'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:03
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 20/05/2024 20:31:39
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_22:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.13641348569002723'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.7250375498058265'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '3856'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.46135892116182575'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:22
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 20/05/2024 21:12:19
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_23:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.13641348569002723'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.7250375498058265'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '3856'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.46135892116182575'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:13
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 20/05/2024 21:15:56
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'
evaluation_24:
    average_num_of_predictions: '8.152934517281636'
    denovo:
        mean_db_score: '0.391845725802349'
        mean_fpsd_score_probsort: '0.25925609345001627'
        mean_fpsd_score_similsort: '0.4032522324284453'
        percentage_of_BART_wins_probsort: '0.751476987299678'
        percentage_of_BART_wins_similsort: '0.8755085435313262'
        percentage_of_ties_probsort: '0.13641348569002723'
        percentage_of_ties_similsort: '0.07231046803693353'
        ties:
            mean_tie_simils_probsort: '0.7250375498058265'
            mean_tie_simils_similsort: '0.9647049290606653'
            num_of_ties_probsort: '3856'
            num_of_ties_simils_equal_to_1_probsort: '1779'
            num_of_ties_simils_equal_to_1_similsort: '1902'
            num_of_ties_similsort: '2044'
            percentage_of_ties_simils_equal_to_1_probsort: '0.46135892116182575'
            percentage_of_ties_simils_equal_to_1_similsort: '0.9305283757338552'
    eval_config:
        do_denovo: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        on_the_fly: true
        save_best_predictions: true
        simil_function: tanimoto
        threshold: 0.85
    eval_time: 00:01:14
    formula_stats:
        num_all_correct_formulas: 69887 / 230459
        num_at_least_one_correct_formula: '23733'
        num_correct_formulas_at_best_prob: '18364'
        num_correct_formulas_at_best_simil: '21052'
        percentage_of_all_correct_formulas: '0.3032513375481105'
        percentage_of_at_least_one_correct_formula: '0.8396009481020271'
        percentage_of_correct_formulas_at_best_prob: '0.6496621502104928'
        percentage_of_correct_formulas_at_best_simil: '0.7447553684508438'
    hit_at_k_prob: '[(1, 0.40612728623483213), (2, 0.5004422117663707), (3, 0.5448756500512966),
        (4, 0.5736724802773552), (5, 0.5938373368238582), (6, 0.6072805745215268),
        (7, 0.617398379736088), (8, 0.6234832136413486), (9, 0.6267025153005271),
        (10, 0.6280822160116036)]'
    labels_path: ../data/datasets/NIST/NIST_split_filip/denovo_data/test_with_denovo_info.jsonl
    num_datapoints_tested: '28267'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28267, 28072, 27655, 26897, 25854, 24434, 22481,
        19932, 16257, 10611]'
    precise_preds_stats:
        num_precise_preds_probsort: '11003'
        num_precise_preds_similsort: '17656'
        percentage_of_precise_preds_probsort: '0.389252485230127'
        percentage_of_precise_preds_similsort: '0.6246152757632575'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 14797), (2, 1428), (3, 1012), (5, 134),
            (4, 291), (8, 13), (6, 47), (9, 7), (10, 2), (7, 23)])
        num_1_hits_as_first_probsort: '11480'
        num_1_hits_as_first_similsort: '17754'
        num_fp_simil_fail_prob: '477'
        num_fp_simil_fail_simil: '98'
        percentage_of_1_hits_as_first_probsort: '0.40612728623483213'
        percentage_of_1_hits_as_first_similsort: '0.6280822160116036'
    start_time_utc: 20/05/2024 21:22:27
    threshold_stats:
        num_better_than_threshold_probsort: '11789'
        num_better_than_threshold_similsort: '17930'
        percentage_of_better_than_threshold_probsort: '0.41705876109951534'
        percentage_of_better_than_threshold_similsort: '0.6343085576821028'
        threshold: '0.85'
    topk_probsort: '[0.6511018192523653, 0.530558224968216, 0.4849807213604347, 0.45882237384532615,
        0.4370968241913293, 0.4183018616018104, 0.3997928421782623, 0.3786214876613649,
        0.3561227651643802, 0.33264284264086164]'
    topk_similsort: '[0.7950979582307944, 0.593636343897292, 0.5158537441019437, 0.4594050986305954,
        0.4152403268154002, 0.3763881081605056, 0.3405910753434224, 0.3059912164030488,
        0.27273397560819046, 0.23961643287229908]'

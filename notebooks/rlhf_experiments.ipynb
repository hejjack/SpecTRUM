{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to run a RLHF training for BARTspectro\n",
    "Try to run a PPO training on BARTspectro. Rewards are Fingerprint similarities  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example code snippet from \n",
    "https://github.com/huggingface/trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-01 17:17:21,935] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from trl.core import respond_to_batch\n",
    "from general_utils import build_tokenizer\n",
    "from data_utils import build_single_datapipe\n",
    "from data_utils import SpectroDataCollator, SpectroDataset\n",
    "from tqdm import tqdm\n",
    "from bart_spektro.ppo_spectro_trainer import PPOSpectroTrainer \n",
    "from data_utils import SpectroDataCollator\n",
    "from bart_spektro.modeling_bart_spektro import BartSpektroForConditionalGeneration\n",
    "from metrics import compute_cos_simils\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get models\n",
    "bart_model = BartSpektroForConditionalGeneration.from_pretrained('checkpoints/finetune/fresh-blaze-258_4_8M_rassp1_neims1_224kPretrain/checkpoint-73440/')\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(bart_model)\n",
    "model_ref = create_reference_model(model)\n",
    "\n",
    "tokenizer = build_tokenizer(\"tokenizer/bbpe_tokenizer/bart_bbpe_tokenizer_1M_mf3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling data/datasets/NIST/NIST_split_filip/train.jsonl with buffer_size=1000\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_pipe = build_single_datapipe(\"data/datasets/NIST/NIST_split_filip/train.jsonl\", shuffle=True, buffer_size=1000)\n",
    "valid_pipe = build_single_datapipe(\"data/datasets/NIST/NIST_split_filip/valid.jsonl\", shuffle=False)\n",
    "\n",
    "# initialize trainer\n",
    "ppo_config = PPOConfig(\n",
    "    batch_size=8,          \n",
    "    forward_batch_size=None,  # not used\n",
    "    backward_batch_size=8, # bs per one device futher split into mini_batch_size\n",
    "    mini_batch_size=4,  # bs within backward_bs, actually used as bs in forward pass / backward pass (step of optimizer)\n",
    "    is_encoder_decoder=True,\n",
    "    log_with=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhajekad\u001b[0m (\u001b[33mmsgc_boys\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xhajek9/gc-ms_bart/wandb/run-20231101_171732-myssmaww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/msgc_boys/trl/runs/myssmaww' target=\"_blank\">revived-fog-22</a></strong> to <a href='https://wandb.ai/msgc_boys/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/msgc_boys/trl' target=\"_blank\">https://wandb.ai/msgc_boys/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/msgc_boys/trl/runs/myssmaww' target=\"_blank\">https://wandb.ai/msgc_boys/trl/runs/myssmaww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = PPOSpectroTrainer(\n",
    "    model=model,\n",
    "    config=ppo_config,\n",
    "    dataset=train_pipe,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=SpectroDataCollator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[26, 27, 29,  ...,  2,  2,  2],\n",
      "        [26, 27, 29,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [33, 34, 36,  ...,  2,  2,  2],\n",
      "        [33, 38, 39,  ...,  2,  2,  2],\n",
      "        [14, 15, 18,  ...,  2,  2,  2]], device='cuda:0'), 'position_ids': tensor([[ 0,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        [ 1,  0,  2,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
      "        [ 0,  7,  7,  ..., -1, -1, -1],\n",
      "        [ 0,  2,  0,  ..., -1, -1, -1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[1234,  224,  276,  ..., -100, -100, -100],\n",
      "        [1234,  224,  469,  ..., -100, -100, -100],\n",
      "        [1234,  224,  487,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1234,  224,  261,  ..., -100, -100, -100],\n",
      "        [1234,  224,   50,  ..., -100, -100, -100],\n",
      "        [1234,  224,  261,  ..., -100, -100, -100]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for x in trainer.dataloader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:25, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(torch\u001b[39m.\u001b[39mtensor, smiles_simils))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m#### Run PPO step\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     stats \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mstep(batch, \u001b[39mlist\u001b[39;49m(preds), scores)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     trainer\u001b[39m.\u001b[39mlog_stats(stats, batch, scores)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#### Save model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/gc-ms_bart/bart_spektro/ppo_spectro_trainer.py:355\u001b[0m, in \u001b[0;36mPPOSpectroTrainer.step\u001b[0;34m(self, batch, responses, scores, response_masks)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel):\n\u001b[1;32m    353\u001b[0m     mini_batch \u001b[39m=\u001b[39m {k: mini_batch_dict[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model_inputs_names}\n\u001b[0;32m--> 355\u001b[0m     logprobs, logits, vpreds, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatched_forward_pass(\n\u001b[1;32m    356\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    357\u001b[0m         mini_batch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mresponses\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    358\u001b[0m         mini_batch,\n\u001b[1;32m    359\u001b[0m         return_logits\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    361\u001b[0m     train_stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_minibatch(\n\u001b[1;32m    362\u001b[0m         mini_batch_dict[\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    363\u001b[0m         mini_batch_dict[\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m         mini_batch_dict[\u001b[39m\"\u001b[39m\u001b[39mreturns\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    370\u001b[0m     )\n\u001b[1;32m    371\u001b[0m     all_stats\u001b[39m.\u001b[39mappend(train_stats)\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/gc-ms_bart/bart_spektro/ppo_spectro_trainer.py:108\u001b[0m, in \u001b[0;36mPPOSpectroTrainer.batched_forward_pass\u001b[0;34m(self, model, responses, model_inputs, return_logits, response_masks)\u001b[0m\n\u001b[1;32m    103\u001b[0m logprobs \u001b[39m=\u001b[39m logprobs_from_logits(logits[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :], input_ids[:, \u001b[39m1\u001b[39m:])\n\u001b[1;32m    105\u001b[0m \u001b[39m# Adam: the original code sets MASK as intersection of decoder_attention_mask and response_mask\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m# Adam: I changed it to only response_mask (which we create here), bcs we don't want to penalize\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39m# the model for creating longer sequences than the target - if smiles is ok, it's ok. \u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39misin(response_batch, torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], device\u001b[39m=\u001b[39mresponse_batch\u001b[39m.\u001b[39;49mdevice), invert\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mint() \u001b[39m# Adam: this is the response_mask used as MASK (explained below)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(masks, (\u001b[39m0\u001b[39m, values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m masks\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \n\u001b[1;32m    110\u001b[0m \u001b[39massert\u001b[39;00m masks\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmasks and values should have the same length (\u001b[39m\u001b[39m{\u001b[39;00mmasks\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "generation_kwargs = {\"top_k\": None,\n",
    "              \"top_p\": None,\n",
    "              \"do_sample\": True,\n",
    "              \"num_beams\": 5,\n",
    "              \"temperature\": None,\n",
    "              \"penalty_alpha\": None,\n",
    "              \"num_return_sequences\": 1,\n",
    "              \"length_penalty\": 1.0}\n",
    "# training loop\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(trainer.dataloader)):\n",
    "    #### Get response from SFTModel\n",
    "    preds = trainer.generate(batch, \"cuda:0\", **generation_kwargs) # add model specific inputs and generation kwargs\n",
    "\n",
    "    #### Compute reward score\n",
    "    preds_str = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    gts_str = [tokenizer.decode((label*mask).tolist(), skip_special_tokens=True) for label, mask in zip(batch[\"labels\"], batch[\"decoder_attention_mask\"])]\n",
    "    smiles_simils, pred_mols, gt_mols = compute_cos_simils(preds_str, gts_str, return_mols=True)        \n",
    "    \n",
    "    scores = list(map(torch.tensor, smiles_simils))\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = trainer.step(batch, list(preds), scores)\n",
    "    trainer.log_stats(stats, batch, scores)\n",
    "\n",
    "#### Save model\n",
    "trainer.save_model(\"my_ppo_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.is_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_model.config.max_length-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.core import PPODecorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6,7,8])\n",
    "torch.isin(a, torch.tensor([0,1,2,3]), invert=True).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Balfa/home/xhajek9/gc-ms_bart/rlhf_experiments.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(a, (\u001b[39m0\u001b[39m, model\u001b[39m.\u001b[39mpretrained_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]), value\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpretrained_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.pad(a, (0, model.pretrained_model.config.max_length-1 - a.shape[1]), value=model.pretrained_model.config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_model.config.max_length - 1 - a.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BARTtrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

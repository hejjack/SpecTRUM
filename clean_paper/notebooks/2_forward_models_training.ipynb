{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward model training\n",
    "\n",
    "In this notebook we'll train the forward models NEIMS and RASSP that we use for fenerating syntetic datasets. In order to get through this notebook you first need to have the **python environments** set up (find more in README or the previous notebook). You also need the **NIST library** in the form of a .msp file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIST splitting\n",
    "**TODO**\n",
    "this part is done in the 3rd notebook.. Organize it better i guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_train_path = \"../data/nist/train.msp\"\n",
    "nist_test_path = \"../data/nist/test.msp\"\n",
    "nist_valid_path = \"../data/nist/valid.msp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEIMS\n",
    "\n",
    "\n",
    "### Conversion from MSP to SDF\n",
    "First we need to convert the NIST library to SDF format that is supported by the NEIMS codebase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes approximately 15 mins to run\n",
    "from utils.spectra_process_utils import msp2sdf\n",
    "\n",
    "# msp2sdf(nist_test_path)\n",
    "# msp2sdf(nist_valid_path)\n",
    "msp2sdf(nist_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232025/232025 [03:14<00:00, 1193.42it/s]\n",
      "100%|██████████| 29218/29218 [00:24<00:00, 1190.00it/s]\n",
      "100%|██████████| 29053/29053 [00:24<00:00, 1195.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# change the format of spectral information to the one expected by NEIMS\n",
    "# this function might differ in your case depending on the metadata format of your copy of NIST library\n",
    "# for us it took about 4 mins to run\n",
    "\n",
    "# load sdf files\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "def neims_mol_filter(mol,\n",
    "                     max_atoms=100,\n",
    "                     max_mass_peak_loc=1000,\n",
    "                     filter_max_mass_charge_peak_weight_cutoff=3.0):\n",
    "    \"\"\"\n",
    "    This function was altered from the NEIMS codebase to filter molecules.\n",
    "    We didn't use the original function for a lack of environment compatibility.\n",
    "\n",
    "    The filtering thresholds are set based on the NEIMS default values.\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return False\n",
    "    elif max_atoms is not None and mol.GetNumAtoms() > max_atoms:\n",
    "        return False\n",
    "    elif not mol.GetProp(\"MASS SPECTRAL PEAKS\"):\n",
    "        return False\n",
    "    elif not mol.GetProp(\"smiles\"):\n",
    "        return False\n",
    "    max_peak = float(mol.GetProp(\"MASS SPECTRAL PEAKS\").split(\"\\n\")[-2].split(\" \")[0])\n",
    "    if max_peak > max_mass_peak_loc:\n",
    "        return False\n",
    "    if max_peak / mol.GetDoubleProp(\"EXACT MASS\") > filter_max_mass_charge_peak_weight_cutoff:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def transform_to_neims_sdf_format(input_path, output_path):\n",
    "\n",
    "    nist_train_sdf = Chem.SDMolSupplier(input_path)\n",
    "    writer = Chem.SDWriter(output_path)\n",
    "    num_filtered = 0\n",
    "\n",
    "    for mol in tqdm(nist_train_sdf):\n",
    "        old_format_peaks = mol.GetProp(\"peaks_json\")\n",
    "        old_format_peaks = ast.literal_eval(old_format_peaks)\n",
    "        new_format_peaks = \"\".join([f\"{round(mz)} {round(i)}\\n\" for (mz, i) in old_format_peaks])\n",
    "        exact_mass = Descriptors.ExactMolWt(mol)\n",
    "        inchikey = mol.GetProp(\"inchikey\")\n",
    "        if not inchikey:\n",
    "            print(\"WARNING: No inchikey found for\", mol.GetProp(\"iupac_name\"))\n",
    "            inchikey = Chem.inchi.MolToInchiKey(mol)\n",
    "\n",
    "        mol.SetProp(\"MASS SPECTRAL PEAKS\", new_format_peaks)\n",
    "        mol.SetDoubleProp(\"EXACT MASS\", exact_mass)\n",
    "        mol.SetProp(\"INCHIKEY\", inchikey)\n",
    "        mol.SetProp(\"NAME\", mol.GetProp(\"iupac_name\"))\n",
    "\n",
    "        mol.ClearProp(\"peaks_json\")\n",
    "        mol.ClearProp(\"inchikey\")\n",
    "        mol.ClearProp(\"iupac_name\")\n",
    "\n",
    "        if neims_mol_filter(mol): \n",
    "            writer.write(mol)\n",
    "        else:\n",
    "            num_filtered += 1\n",
    "\n",
    "output_train = \"../data/nist/neims_training_data/train_neims.sdf\"\n",
    "output_test = \"../data/nist/neims_training_data/test_neims.sdf\"\n",
    "output_valid = \"../data/nist/neims_training_data/valid_neims.sdf\"\n",
    "\n",
    "Path(output_train).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# run the transformation\n",
    "transform_to_neims_sdf_format(nist_train_path.replace(\".msp\", \".sdf\"), \n",
    "                              output_train)\n",
    "\n",
    "transform_to_neims_sdf_format(nist_test_path.replace(\".msp\", \".sdf\"),\n",
    "                              output_test)\n",
    "\n",
    "transform_to_neims_sdf_format(nist_valid_path.replace(\".msp\", \".sdf\"),\n",
    "                              output_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract replicates\n",
    "We'll extract the replicates from the NIST library, creating two sets: one for training NEIMS model (mainlib) and one for the database retrieval testing scenario (replicates). This took about 3 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231983/231983 [00:01<00:00, 132650.67it/s]\n",
      "/home/xhajek9/miniconda3/envs/BARTtrainH100/lib/python3.8/site-packages/rdkit/Chem/PandasTools.py:371: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frame[molCol] = frame[smilesCol].map(Chem.MolFromSmiles)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from rdkit.Chem import PandasTools\n",
    "from utils.spectra_process_utils import smiles_to_inchikey\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def extract_replicates(path_sdf):\n",
    "    \"\"\"This function extracts replicates from the main library and saves them in a separate file.\n",
    "    The replicates (repeating molecules) stay in one version in the main library and all other\n",
    "    versions are moved to the replicates file.\n",
    "\n",
    "    Args:\n",
    "        path_sdf (str): path to the main library sdf file\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    df = PandasTools.LoadSDF(path_sdf)\n",
    "\n",
    "    # check all mols have inchikeys\n",
    "    df['inchikey'] = df.progress_apply(lambda row: smiles_to_inchikey(row['smiles']) if pd.isna(row['INCHIKEY']) else row['INCHIKEY'], axis=1)\n",
    "    unique_df = df.drop_duplicates(subset=['INCHIKEY'], keep='first')\n",
    "    replicates_df = df[~df.index.isin(unique_df.index)]\n",
    "    PandasTools.AddMoleculeColumnToFrame(replicates_df, smilesCol='smiles', molCol='ROMol')\n",
    "    PandasTools.AddMoleculeColumnToFrame(unique_df, smilesCol='smiles', molCol='ROMol')\n",
    "    \n",
    "    path_mainlib_sdf = path_sdf.replace(\".sdf\", \"_main.sdf\")\n",
    "    path_replicates_sdf = path_sdf.replace(\".sdf\", \"_replicates.sdf\")\n",
    "\n",
    "    PandasTools.WriteSDF(unique_df, path_mainlib_sdf, properties=list(\n",
    "        unique_df.columns))\n",
    "    PandasTools.WriteSDF(replicates_df, path_replicates_sdf, properties=list(\n",
    "        replicates_df.columns))\n",
    "\n",
    "    \n",
    "extract_replicates(output_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can delete the original intermediate sdf files and keep only the NEIMS formatted ones\n",
    "Path(\"../data/nist/train.sdf\").unlink()\n",
    "Path(\"../data/nist/test.sdf\").unlink()\n",
    "Path(\"../data/nist/valid.sdf\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split and preprocessing\n",
    "Now we can use a NEIMS script to split the data and preprocess it. Run the following bash command to do so:\n",
    "\n",
    "\n",
    "```bash\n",
    "cd deep-molecular-massspec\n",
    "TARGET_PATH_NAME=tmp/massspec_predictions\n",
    "conda activate NEIMSpy3\n",
    "\n",
    "python make_train_test_split.py --main_sdf_name=../data/nist/neims_training_data/train_neims_main.sdf \\\n",
    "                                --replicates_sdf_name=../data/nist/neims_training_data/train_neims_replicates.sdf \\\n",
    "                                --output_master_dir=$TARGET_PATH_NAME/spectra_tf_records\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "The preprocessed data is now ready for training. We'll use the following command to train the model:\n",
    "\n",
    "```bash\n",
    "python molecule_estimator.py --dataset_config_file=$TARGET_PATH_NAME/spectra_tf_records/query_replicates_val_predicted_replicates_val.json \\\n",
    "                             --train_steps=100000 \\\n",
    "                             --model_dir=$TARGET_PATH_NAME/models/output \\\n",
    "                             --hparams=make_spectra_plots=True,batch_size=100 \\\n",
    "                             --alsologtostderr\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RASSP\n",
    "\n",
    "**TODO: potrebujeme .jsonl ze splitu, ale tady je jeste nemame.**\n",
    "\n",
    "For the purpose of this work, we keep a [dedicated branch](https://github.com/ljocha/rassp-public/tree/ljocha) of our [fork](https://github.com/ljocha/rassp-public/) of the original RASSP git repository. Currently the code itself is not modified, \n",
    "\n",
    "RASSP requires quite specific environment (ancient Python and PyTorch versions) to run smoothly, therefore we provide a Docker container (cerit.io/ljocha/rassp:nvidia-2024-1) with everything prepared.\n",
    "Dockerfile we used to generate it is available in the repository (see above).\n",
    "\n",
    "### Filtering NIST for RASSP\n",
    "\n",
    "This step follows splitting and cleanup of the NIST, we expect the train and valid sets in the .jsonl format here (test set is not used).\n",
    "\n",
    "RASSP, in its published implementation, is restricted to molecules of at most 48 atoms (including hydrogens), containing H, C, N, O, F, P, S, Cl elements only, and expanding to not more than 4096 combinatorial subformulae (see https://doi.org/10.1021/acs.analchem.2c02093 for details). Filtering the NIST records and transformation to a parquet format required by RASSP training is done with:\n",
    "\n",
    "```bash\n",
    "python prepare_rassp_train.py train.jsonl train-rassp-small.pq\n",
    "python prepare_rassp_train.py valid.jsonl valid-rassp-small.pq\n",
    "```\n",
    "\n",
    "The produced .pq files should be approx. 44 and 5.5 MB.\n",
    "\n",
    "### Training RASSP\n",
    "\n",
    "Training RASSP requires a GPU with at least 8 GB memory. Calling RASSP is wrapped in the `run_train_rassp.py` script; you may want to adjust the path to the repository clone, number of OMP threads and number of dataloader workers eventually. Than, the training in the docker container and with suitable settings for GPU is run with\n",
    "\n",
    "```bash\n",
    "make run-train-nvidia\n",
    "```\n",
    "\n",
    "With common GPUs (eg. Nvidia GeForce RTX 2080) expect approx. 2 minutes per epoch. Progress of training can be observed in the `validate-small.ipynb` notebook (executed with `make run-nvidia` in the same directory). Dot product of the predicted spectra wrt. ground truth on the validation set reached almost plateau at approx. 0.85 ±0.12 at epoch #400 in our experiments while it kept improving up to 3000 epochs, which turns into several days of training.\n",
    "\n",
    "Output of the training is stored in `checkpoints/` directory. Based on the validation choose the best one and grab the corresponding `.meta` and `.model` files for the following prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

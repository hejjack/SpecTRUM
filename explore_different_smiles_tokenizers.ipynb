{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "every-samoa",
   "metadata": {},
   "source": [
    "# Explore alternative tokenizers\n",
    "Exploring possibilities of different NLP tokenizers for the BART model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "athletic-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"./data/trial_set/1K.smi\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selective-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>zinc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1nn(C)c(C)c1S(=O)(=O)N1CCN2C(=O)CN(C)C(=O)[C...</td>\n",
       "      <td>65423162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(CN1C(=O)CNC1=O)N1C[C@@H](CO)C[C@H](CN2CCOC...</td>\n",
       "      <td>91985397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(=O)Nc1ccc(O[C@@H]2O[C@H](CO)[C@H](O)[C@H](O...</td>\n",
       "      <td>239433518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)Nc1ccccc1O[C@@H]1O[C@H](CO)[C@H](O)[C@@H...</td>\n",
       "      <td>245377209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(CNS(=O)(=O)c1cccc(F)c1)N1CC(N2C(=O)CNC2=O)C1</td>\n",
       "      <td>253471034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>CN(CCO)CCC(=O)N[C@@]1(C)CS(=O)(=O)C[C@@H]1S(=O...</td>\n",
       "      <td>9307887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>OCCOCCOCCOCCNCCOCCOCCOCCO</td>\n",
       "      <td>575441396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>CC(=O)O[C@@H]1C(=O)O[C@@H]2[C@@H]1O[C@H](n1ccc...</td>\n",
       "      <td>8738368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Cn1c(CN2CCN([C@@]3(C(=O)O)CCOC3)CC2)cc(=O)n(C)...</td>\n",
       "      <td>886071806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NS(=O)(=O)c1ccc(NC(=O)C(=O)N2C[C@@H](CO)[C@H](...</td>\n",
       "      <td>1875321845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smiles     zinc_id\n",
       "0    Cc1nn(C)c(C)c1S(=O)(=O)N1CCN2C(=O)CN(C)C(=O)[C...    65423162\n",
       "1    O=C(CN1C(=O)CNC1=O)N1C[C@@H](CO)C[C@H](CN2CCOC...    91985397\n",
       "2    CC(=O)Nc1ccc(O[C@@H]2O[C@H](CO)[C@H](O)[C@H](O...   239433518\n",
       "3    CC(=O)Nc1ccccc1O[C@@H]1O[C@H](CO)[C@H](O)[C@@H...   245377209\n",
       "4     O=C(CNS(=O)(=O)c1cccc(F)c1)N1CC(N2C(=O)CNC2=O)C1   253471034\n",
       "..                                                 ...         ...\n",
       "994  CN(CCO)CCC(=O)N[C@@]1(C)CS(=O)(=O)C[C@@H]1S(=O...     9307887\n",
       "995                          OCCOCCOCCOCCNCCOCCOCCOCCO   575441396\n",
       "996  CC(=O)O[C@@H]1C(=O)O[C@@H]2[C@@H]1O[C@H](n1ccc...     8738368\n",
       "997  Cn1c(CN2CCN([C@@]3(C(=O)O)CCOC3)CC2)cc(=O)n(C)...   886071806\n",
       "998  NS(=O)(=O)c1ccc(NC(=O)C(=O)N2C[C@@H](CO)[C@H](...  1875321845\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-karen",
   "metadata": {},
   "source": [
    "## WordPiece tokenizer\n",
    "This tokenizer from the deepchem library looks to be better for anorganic molecules, has a lot of structures that are not that common in our SMILES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "significant-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'O', 'c', '1', 'c', 'c', '2', 'c', 'c', 'c', '(', '=', 'O', ')', 'o', 'c', '2', 'c', '(', 'O', '[C@@H]', '2', 'O', '[C@@H]', '(', 'C', 'O', ')', '[C@H]', '(', 'O', ')', '[C@@H]', '(', 'O', ')', '[C@@H]', '2', 'O', ')', 'c', '1', 'O', '1', '6', '2', '1', '5', '1', '3', '2']\n"
     ]
    }
   ],
   "source": [
    "from deepchem.feat.smiles_tokenizer import SmilesTokenizer\n",
    "import os\n",
    "\n",
    "vocab_path = 'wp_tokenizer/vocab.txt'\n",
    "tokenizer = SmilesTokenizer(vocab_path)\n",
    "print(tokenizer.tokenize(df.iloc[90][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dense-fleet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage-brno6/home/ahajek/Spektro/MassGenie\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-report",
   "metadata": {},
   "source": [
    "## BBPE Tokenizer\n",
    "Hopefully will learn to tokenize the SMILES into longer squences.\n",
    "\n",
    "Let's train one.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "agricultural-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SMILES file without the zinc bullshit\n",
    "with open(\"./tokenizer/training_data/1K.txt\", \"w+\") as f:\n",
    "    for smiles in df.smiles:\n",
    "        f.write(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "creative-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.normalizers import NFKC, Sequence\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "class BPE_token(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer(BPE())\n",
    "        self.tokenizer.normalizer = Sequence([\n",
    "            NFKC()\n",
    "        ])\n",
    "        self.tokenizer.pre_tokenizer = ByteLevel()\n",
    "        self.tokenizer.decoder = ByteLevelDecoder()\n",
    "\n",
    "    def bpe_train(self, path):\n",
    "        trainer = BpeTrainer(vocab_size=50257, min_frequency=3, show_progress=True, initial_alphabet=ByteLevel.alphabet(), \n",
    "                             special_tokens=[\"<eos>\", \"<ukn>\", \"<pad>\", \"<bos>\"])\n",
    "        self.tokenizer.train(path, trainer)\n",
    "\n",
    "    def save_tokenizer(self, location, prefix=None):\n",
    "        if not os.path.exists(location):\n",
    "            os.makedirs(location)\n",
    "        self.tokenizer.model.save(location, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upper-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [\"/storage/projects/msml/mg_neims_branch/MassGenie/tokenizer/training_data/1M.txt\"]\n",
    "\n",
    "tokenizer = BPE_token()\n",
    "\n",
    "# train the tokenizer model\n",
    "tokenizer.bpe_train(path)\n",
    "\n",
    "# saving the tokenized data in our specified folder\n",
    "save_path = '/storage/projects/msml/mg_neims_branch/MassGenie/tokenizer/bbpe_tokenizer/' ####\n",
    "tokenizer.save_tokenizer(save_path)\n",
    "tokenizer.tokenizer.save(save_path + \"/bart_bbpe_tokenizer_1M.model\")    #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-wales",
   "metadata": {},
   "source": [
    "### Try the BBPE out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sixth-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Initialize a tokenizer\n",
    "# vocab = \"./tokenizer/bbpe_tokenizer/vocab.json\"\n",
    "# merges = \"./tokenizer/bbpe_tokenizer//merges.txt\"\n",
    "tok = \"./tokenizer/bbpe_tokenizer/bart_bbpe_tokenizer.model\"\n",
    "tokenizer = Tokenizer.from_file(tok)\n",
    "# special_tokens_dict = {\"bos_token\": \"<bos>\", \"unk_token\": \"<unk>\", \"eos_token\": \"<eos>\", \"sep_token\": \"<sep>\"}\n",
    "# special_tokens_dict = [\"<sep>\"]\n",
    "\n",
    "\n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# And then encode:\n",
    "encoded = tokenizer.encode(df.smiles[500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "swedish-pixel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġ', 'CS', '(=', 'O', ')(=', 'O', ')', 'NCC', '(=', 'O', ')', 'N', '[', 'C', '@', 'H', ']', '1', 'COCC', '[', 'C', '@@', 'H', ']', '1', 'Oc', '1', 'ccc', '(', 'C', '(', 'N', ')=', 'O', ')', 'cc', '1']\n"
     ]
    }
   ],
   "source": [
    "print(encoded.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = tokenizer.token_to_id(\"<bos>\")\n",
    "et = tokenizer.token_to_id(\"<eos>\")\n",
    "tok_smiles = [bt] + tokenizer.encode(df.smiles[0]).ids #+ [et] + (200-2-len(tokenizer.encode(df.smiles[0]))) * [pt]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pharmaceutical-choir",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cc1nn(C)c(C)c1S(=O)(=O)N1CCN2C(=O)CN(C)C(=O)[C@H]2C1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[224,\n",
       " 278,\n",
       " 20,\n",
       " 282,\n",
       " 11,\n",
       " 38,\n",
       " 12,\n",
       " 70,\n",
       " 11,\n",
       " 38,\n",
       " 12,\n",
       " 70,\n",
       " 20,\n",
       " 54,\n",
       " 260,\n",
       " 50,\n",
       " 270,\n",
       " 50,\n",
       " 12,\n",
       " 49,\n",
       " 20,\n",
       " 267,\n",
       " 21,\n",
       " 38,\n",
       " 260,\n",
       " 50,\n",
       " 12,\n",
       " 266,\n",
       " 11,\n",
       " 38,\n",
       " 12,\n",
       " 38,\n",
       " 260,\n",
       " 50,\n",
       " 263,\n",
       " 38,\n",
       " 35,\n",
       " 43,\n",
       " 64,\n",
       " 21,\n",
       " 38,\n",
       " 20]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.smiles[0])\n",
    "tokenizer.encode(df.smiles[0]).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fallen-maintenance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destereo_smiles</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>decoder_input_ids</th>\n",
       "      <th>encoder_attention_mask</th>\n",
       "      <th>decoder_attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>position_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>COCCN1C(=O)C(=O)N(C1=O)CC(=O)c1c(N)n(C)c(=O)n(...</td>\n",
       "      <td>[15, 28, 29, 30, 31, 32, 33, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[3, 224, 325, 20, 38, 260, 50, 12, 38, 260, 50...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 325, 20, 38, 260, 50, 12, 38, 260, 50...</td>\n",
       "      <td>[3, 1, 2, 5, 5, 4, 4, 5, 6, 7, 8, 6, 7, 9, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>O=C(NC1CCS(=O)(=O)C1)CCC(=O)NC1CCS(=O)(=O)C1</td>\n",
       "      <td>[17, 18, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 272, 20, 290, 260, 50...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 272, 20, 290, 260, 50...</td>\n",
       "      <td>[1, 1, 3, 6, 6, 7, 4, 5, 2, 1, 1, 2, 4, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>CN(C(=O)c1c(C)nc2n1CCN(C2)C(=O)c1cc(=O)n(c(=O)...</td>\n",
       "      <td>[30, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[3, 224, 266, 11, 38, 260, 50, 12, 70, 20, 70,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 266, 11, 38, 260, 50, 12, 70, 20, 70,...</td>\n",
       "      <td>[2, 4, 0, 4, 7, 7, 7, 9, 7, 8, 6, 4, 4, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Cn1ncc(c1)S(=O)(=O)N1CCN(CC1)S(=O)(=O)c1cnn(c1)C</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[3, 224, 275, 20, 310, 11, 70, 20, 12, 54, 260...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 275, 20, 310, 11, 70, 20, 12, 54, 260...</td>\n",
       "      <td>[2, 3, 3, 1, 5, 6, 6, 6, 8, 6, 5, 3, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>O=C(C1CNCC(C1)C(=O)N1CCOCC1)NCCc1nncn1C</td>\n",
       "      <td>[33, 36, 39, 40, 41, 42, 43, 44, 45, 51, 52, 5...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 38, 20, 266, 261, 11,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 38, 20, 266, 261, 11,...</td>\n",
       "      <td>[4, 1, 8, 7, 9, 9, 8, 9, 2, 6, 8, 8, 8, 9, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>OCCOCCNC(=O)C1CC(C(C1)O)NC(=O)c1nsnc1C</td>\n",
       "      <td>[19, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[3, 224, 372, 291, 260, 50, 12, 38, 20, 261, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 372, 291, 260, 50, 12, 38, 20, 261, 1...</td>\n",
       "      <td>[3, 4, 3, 3, 5, 3, 4, 7, 6, 9, 9, 9, 9, 9, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>COc1ccc(cc1C(=O)NC1COC2C1OCC2O)S(=O)(=O)N</td>\n",
       "      <td>[26, 31, 33, 36, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[3, 224, 331, 20, 274, 11, 264, 20, 38, 260, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 331, 20, 274, 11, 264, 20, 38, 260, 5...</td>\n",
       "      <td>[0, 7, 2, 4, 1, 7, 4, 8, 8, 9, 8, 8, 7, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>O=C(Cn1ncn(c1=O)C)OCCCOC(=O)Cn1ncn(c1=O)C</td>\n",
       "      <td>[29, 30, 31, 39, 40, 41, 42, 43, 44, 45, 52, 5...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 275, 20, 303, 11, 70,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 275, 20, 303, 11, 70,...</td>\n",
       "      <td>[3, 1, 3, 4, 6, 4, 8, 5, 6, 0, 2, 6, 6, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>OC(=O)CN(C(=O)C)CC1OCCN(C1)C(=O)CN1CSCC1=O</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 4...</td>\n",
       "      <td>[3, 224, 280, 260, 50, 12, 266, 11, 38, 260, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 280, 260, 50, 12, 266, 11, 38, 260, 5...</td>\n",
       "      <td>[3, 0, 0, 3, 2, 1, 4, 1, 6, 6, 8, 9, 9, 9, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>O=C(N1CCN(C2C1CS(=O)(=O)C2)S(=O)(=O)C)Cc1cccnc1</td>\n",
       "      <td>[27, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 49, 20, 267, 11, 38, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 11, 49, 20, 267, 11, 38, ...</td>\n",
       "      <td>[4, 3, 1, 1, 3, 8, 6, 8, 8, 7, 5, 1, 4, 6, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       destereo_smiles  \\\n",
       "629  COCCN1C(=O)C(=O)N(C1=O)CC(=O)c1c(N)n(C)c(=O)n(...   \n",
       "338       O=C(NC1CCS(=O)(=O)C1)CCC(=O)NC1CCS(=O)(=O)C1   \n",
       "620  CN(C(=O)c1c(C)nc2n1CCN(C2)C(=O)c1cc(=O)n(c(=O)...   \n",
       "396   Cn1ncc(c1)S(=O)(=O)N1CCN(CC1)S(=O)(=O)c1cnn(c1)C   \n",
       "251            O=C(C1CNCC(C1)C(=O)N1CCOCC1)NCCc1nncn1C   \n",
       "..                                                 ...   \n",
       "308             OCCOCCNC(=O)C1CC(C(C1)O)NC(=O)c1nsnc1C   \n",
       "674          COc1ccc(cc1C(=O)NC1COC2C1OCC2O)S(=O)(=O)N   \n",
       "631          O=C(Cn1ncn(c1=O)C)OCCCOC(=O)Cn1ncn(c1=O)C   \n",
       "526         OC(=O)CN(C(=O)C)CC1OCCN(C1)C(=O)CN1CSCC1=O   \n",
       "121    O=C(N1CCN(C2C1CS(=O)(=O)C2)S(=O)(=O)C)Cc1cccnc1   \n",
       "\n",
       "                                             input_ids  \\\n",
       "629  [15, 28, 29, 30, 31, 32, 33, 39, 40, 41, 42, 4...   \n",
       "338  [17, 18, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...   \n",
       "620  [30, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "396  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "251  [33, 36, 39, 40, 41, 42, 43, 44, 45, 51, 52, 5...   \n",
       "..                                                 ...   \n",
       "308  [19, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 4...   \n",
       "674  [26, 31, 33, 36, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "631  [29, 30, 31, 39, 40, 41, 42, 43, 44, 45, 52, 5...   \n",
       "526  [30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 4...   \n",
       "121  [27, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "\n",
       "                                     decoder_input_ids  \\\n",
       "629  [3, 224, 325, 20, 38, 260, 50, 12, 38, 260, 50...   \n",
       "338  [3, 224, 50, 32, 38, 11, 272, 20, 290, 260, 50...   \n",
       "620  [3, 224, 266, 11, 38, 260, 50, 12, 70, 20, 70,...   \n",
       "396  [3, 224, 275, 20, 310, 11, 70, 20, 12, 54, 260...   \n",
       "251  [3, 224, 50, 32, 38, 11, 38, 20, 266, 261, 11,...   \n",
       "..                                                 ...   \n",
       "308  [3, 224, 372, 291, 260, 50, 12, 38, 20, 261, 1...   \n",
       "674  [3, 224, 331, 20, 274, 11, 264, 20, 38, 260, 5...   \n",
       "631  [3, 224, 50, 32, 38, 11, 275, 20, 303, 11, 70,...   \n",
       "526  [3, 224, 280, 260, 50, 12, 266, 11, 38, 260, 5...   \n",
       "121  [3, 224, 50, 32, 38, 11, 49, 20, 267, 11, 38, ...   \n",
       "\n",
       "                                encoder_attention_mask  \\\n",
       "629  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "338  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "620  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "396  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "251  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "..                                                 ...   \n",
       "308  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "631  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "526  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "121  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                decoder_attention_mask  \\\n",
       "629  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "338  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "620  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "396  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "251  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "..                                                 ...   \n",
       "308  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "631  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "526  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "121  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                labels  \\\n",
       "629  [3, 224, 325, 20, 38, 260, 50, 12, 38, 260, 50...   \n",
       "338  [3, 224, 50, 32, 38, 11, 272, 20, 290, 260, 50...   \n",
       "620  [3, 224, 266, 11, 38, 260, 50, 12, 70, 20, 70,...   \n",
       "396  [3, 224, 275, 20, 310, 11, 70, 20, 12, 54, 260...   \n",
       "251  [3, 224, 50, 32, 38, 11, 38, 20, 266, 261, 11,...   \n",
       "..                                                 ...   \n",
       "308  [3, 224, 372, 291, 260, 50, 12, 38, 20, 261, 1...   \n",
       "674  [3, 224, 331, 20, 274, 11, 264, 20, 38, 260, 5...   \n",
       "631  [3, 224, 50, 32, 38, 11, 275, 20, 303, 11, 70,...   \n",
       "526  [3, 224, 280, 260, 50, 12, 266, 11, 38, 260, 5...   \n",
       "121  [3, 224, 50, 32, 38, 11, 49, 20, 267, 11, 38, ...   \n",
       "\n",
       "                                          position_ids  \n",
       "629  [3, 1, 2, 5, 5, 4, 4, 5, 6, 7, 8, 6, 7, 9, 6, ...  \n",
       "338  [1, 1, 3, 6, 6, 7, 4, 5, 2, 1, 1, 2, 4, 7, 6, ...  \n",
       "620  [2, 4, 0, 4, 7, 7, 7, 9, 7, 8, 6, 4, 4, 6, 6, ...  \n",
       "396  [2, 3, 3, 1, 5, 6, 6, 6, 8, 6, 5, 3, 4, 4, 4, ...  \n",
       "251  [4, 1, 8, 7, 9, 9, 8, 9, 2, 6, 8, 8, 8, 9, 9, ...  \n",
       "..                                                 ...  \n",
       "308  [3, 4, 3, 3, 5, 3, 4, 7, 6, 9, 9, 9, 9, 9, 7, ...  \n",
       "674  [0, 7, 2, 4, 1, 7, 4, 8, 8, 9, 8, 8, 7, 7, 6, ...  \n",
       "631  [3, 1, 3, 4, 6, 4, 8, 5, 6, 0, 2, 6, 6, 8, 8, ...  \n",
       "526  [3, 0, 0, 3, 2, 1, 4, 1, 6, 6, 8, 9, 9, 9, 8, ...  \n",
       "121  [4, 3, 1, 1, 3, 8, 6, 8, 8, 7, 5, 1, 4, 6, 2, ...  \n",
       "\n",
       "[469 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"data/trial_set/1K_bbpe_bart_prepared_data_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

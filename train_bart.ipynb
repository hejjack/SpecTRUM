{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1043f26",
   "metadata": {},
   "source": [
    "## My train using Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49d37d",
   "metadata": {},
   "source": [
    "Training BART with a changed script from the BERT project (adding position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc3777",
   "metadata": {},
   "source": [
    "### !! PROBLEMS\n",
    "Miska call\n",
    "* chyba, ze mam jen jeden tokenizer.... PROC?\n",
    "* generate nezere position_ids \n",
    "* zkusit tomu nedavat decoder_input_ids, jenom labels (melo by si je to snad dopocitat z labels)... JO TO ASI POMOHLO\n",
    "    * prepare_decoder_input_ids_from_labels\n",
    "    * pokud nejsou shiftnuty labely doleva, vysvetluje to nizkou loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c27c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf4085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch.ssd/ahajek/tmp/.conda/envs/BARTtrain/bin/python\n",
      "/opt/conda/bin/pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561984ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/scratch.ssd/ahajek/tmp/.conda/envs/BARTtrain/bin/python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd84de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.21.0\n",
    "# !pip install ipywidgets --user\n",
    "# !pip install pandas==1.4.3\n",
    "# !pip install wandb\n",
    "# !pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e467d1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch.ssd/ahajek/tmp/.conda/envs/BARTtrain/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, BartConfig, BartForConditionalGeneration\n",
    "# from transformers.file_utils import logging\n",
    "# from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "\n",
    "# custom veci\n",
    "from dataset import SpectroDataset, SpectroDataCollator\n",
    "sys.path.append('data')\n",
    "sys.path.append('bart_spektro')\n",
    "from modeling_bart_spektro import BartSpektoForConditionalGeneration\n",
    "from configuration_bart_spektro import BartSpektroConfig\n",
    "from data_preprocess1 import print_args\n",
    "from bart_spektro_tokenizer import BartSpektroTokenizer\n",
    "from bart_spektro_trainer import BartSpectroTrainer\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# from utils import add_special_tokens, generate_sample, sample_seq, set_seed, top_k_top_p_filtering, print_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec556ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a49f88",
   "metadata": {},
   "source": [
    "#### Setting basic training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce3f85d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA: 1\n",
      "save checkpoint to: None\n"
     ]
    }
   ],
   "source": [
    "ncpus=16\n",
    "ngpus=4 #4\n",
    "bs = 32 #32 for small model, 16 or 28(slower) for 707M model\n",
    "gas = 1 # int(16/ngpus)\n",
    "print(\"GA:\", gas)\n",
    "which_bart = \"spektro\" #\"original\" # \"spektro\"\n",
    "data_type = \"30M\" # \"30M\"\n",
    "tokenizer_type = \"_bbpe_1M\" # for spektro tokenizer use \"\"\n",
    "\n",
    "\n",
    "SEQ_LEN = 200\n",
    "num_epochs = 200 # 10 (BARTy se trenovaly 10 epoch celkem) # int(os.environ[\"TOTAL_EPOCHS\"])\n",
    "debug_data_len =  None #{\"train\": 4000, \"valid\": 4000} # None for no debug   \n",
    "resume_training = False # True # bool(int(os.environ[\"RESUME_TRAINING\"]))\n",
    "resume_wandb_id = \"\" # 2yqhwcas\" # \"191h62zs\" #pass # \"\"\n",
    "eval_steps = 10000 # 6500 # 9000 # 30M steps per epoch : 87617 => 9000 steps should be roughly 8hours -> eval_steps, save_steps\n",
    "save_steps = eval_steps\n",
    "log_steps = 1 # 5\n",
    "eval_log_predictions_size = 100 # 100\n",
    "eval_subset_size = 200000 # 100000 #100k\n",
    "\n",
    "model = None # aby nebyl nedefinovany\n",
    "\n",
    "# find the last checkpoint\n",
    "# checkpoints_pth = \"./checkpoints/*\"\n",
    "# runs = sorted(glob.glob(checkpoints_pth))\n",
    "# checkpoints =  glob.glob(runs[-1]+\"/checkpoint-*\")\n",
    "# checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "# load_checkpoint = checkpoints[-1]\n",
    "# save_checkpoint = runs[-1]\n",
    "# print(f\"last checkpoint: {load_checkpoint}\")\n",
    "\n",
    "# load_checkpoint = \"./checkpoints/bart_2022-06-28-10_02_31/checkpoint-18128\"\n",
    "\n",
    "# # LOAD CHECKPOINT FROM\n",
    "# prefered_run = \"./checkpoints/bart_2022-06-28-10_02_31_bigdata/\"\n",
    "# checkpoints =  glob.glob(prefered_run+\"checkpoint-*\")\n",
    "# checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "# load_checkpoint = checkpoints[-1]\n",
    "# print(f\"last checkpoint: {load_checkpoint}\") # the newest from particular folder\n",
    "\n",
    "# # SAVE CHECKPOINTS TO  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# save_checkpoint = \"bart_2022-06-28-10_02_31_bigdata/\" # if None -> saves to newly generated folder bart_{now}\n",
    "save_checkpoint = None #\"bart_2022-06-28-10_02_31_bigdata\" # if None -> saves to newly generated folder bart_{now}\n",
    "\n",
    "print(\"save checkpoint to:\", save_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc53821",
   "metadata": {},
   "source": [
    "#### Setting all training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52216c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"PBS_NGPUS\"]\n",
    "!echo $PBS_NGPUS\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eac295a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "now = str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "now = now.replace(\":\",\"_\").replace(\" \", \"-\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n",
    "parser.add_argument(\"--gradient-accumulation-steps\",default=gas, type=int, help=\"gradient_accumulation_steps\")\n",
    "parser.add_argument(\"--batch-size\",default=bs, type=int,  help=\"batch_size\")\n",
    "parser.add_argument(\"--warmup\",default=500, type=int,  help=\"warmup steps for learning rate\")\n",
    "parser.add_argument(\"--weight-decay\",default=0.01, type=float,  help=\"weight decay rate parameter\")\n",
    "parser.add_argument(\"--n-gpu\",default=ngpus, type=int, required=False, help=\"no of gpu available\")\n",
    "parser.add_argument(\"--fairscale\",default=\"\", type=str, required=False, choices=[\"simple\", \"zero_dp_2\", \"zero_dp_3\"], help=\"GPU paralellization via Fairscale, \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--deepspeed\", default=None, type=str, required=False, help=\"GPU paralellization via Deepspeed, the value is the location of DeepSpeed json config file; \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--num-workers\",default=ncpus, type=int,  help=\"num of cpus available\")\n",
    "parser.add_argument(\"--device\",default=torch.device('cuda'), help=\"torch.device object\")\n",
    "parser.add_argument(\"--num-train-epochs\",default=num_epochs, type=int,  help=\"number of training epochs\")\n",
    "parser.add_argument(\"--output-dir\",default='./output', type=str,  help=\"Path to save evaluation results\")\n",
    "parser.add_argument(\"--save-dir\",default='./checkpoints', type=str,  help=\"Path to save trained model\")\n",
    "parser.add_argument(\"--save-name\", type=str, default=f'bart_{now}', help=\"Name of the model, used for saves\")\n",
    "parser.add_argument(\"--load-checkpoint\", type=str, default='', help=\"Path to the checkpoint to resume training\")\n",
    "parser.add_argument(\"--config-dir\",default='./configs', type=str,  help=\"Path to save config files of checkpoints\")\n",
    "parser.add_argument(\"--fp16\",default=True, type=bool, required=False, help=\"whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "parser.add_argument(\"--max-grad-norm\",default=1.0, type=float, help=\"max gradient norm.\")\n",
    "parser.add_argument(\"--train-data-path\",default=f'./data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_train.pkl', type=str, help=\"Path to jsonl train dataset\")\n",
    "parser.add_argument(\"--valid-data-path\",default=f'./data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_valid.pkl', type=str, help=\"Path to jsonl validation dataset\")\n",
    "parser.add_argument(\"--log-steps\",default=log_steps, type=int,  help=\"number of steps between logs\")\n",
    "parser.add_argument(\"--eval-steps\",default=eval_steps, type=int,  help=\"number of steps between evaluations\")\n",
    "parser.add_argument(\"--tokenizer-path\",default='/storage/brno6/home/ahajek/nic', type=str, help=\"location of the desied tokenizer (special sep token will be added))\")\n",
    "parser.add_argument(\"--model-path\",default='./checkpoints/NECO', type=str, help=\"location of the desired model to finetune\")\n",
    "parser.add_argument(\"--wandb\", action='store_true', default=True, help=\"optinal logging via Weights&Biases\")\n",
    "parser.add_argument(\"--wandb-resume\", action='store_true', default=resume_training, help=\"resume logging via wandb, needs an valid run ID set in args.wandb-id\")\n",
    "parser.add_argument(\"--wandb-id\", type=str, default=wandb.util.generate_id(), help=\"Process unique wandb ID used for resumin the training process\")\n",
    "parser.add_argument(\"--tensorboard\", action='store_true', default=False, help=\"optinal logging via TensorBoard\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# extended outputs\n",
    "# logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d555518",
   "metadata": {},
   "source": [
    "#### Loading tokenizer, data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c111107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "604d98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER\n",
    "tokenizer = Tokenizer.from_file(f\"./tokenizer/bbpe_tokenizer/bart{tokenizer_type}_tokenizer.model\")\n",
    "tokenizer.add_special_tokens([\"<neims>\", \"<nist>\", \"<rassp>\", \"<source1>\", \"<source2>\", \"<source3>\"])\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # surpressing a warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a559028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART CONIGURATION\n",
    "if which_bart == \"spektro\":\n",
    "    config = BartSpektroConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12, # 24\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,  # 24\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0,\n",
    "                                 max_log_id=9)\n",
    "\n",
    "if which_bart == \"original\":\n",
    "    config = BartConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12,\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f05b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE NAME\n",
    "args.save_name = save_checkpoint if save_checkpoint else args.save_name # change args only if user specifies different save name in the initial cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee0b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "args.train_data_path = f\"./data/trial_set/{data_type}_train.pkl\"\n",
    "args.valid_data_path = f\"./data/trial_set/{data_type}_valid.pkl\"\n",
    "\n",
    "train_data = SpectroDataset(args.train_data_path, original=which_bart==\"original\")\n",
    "valid_data = SpectroDataset(args.valid_data_path, original=which_bart==\"original\")\n",
    "\n",
    "if debug_data_len is not None:\n",
    "    train_data.data = train_data.data[:debug_data_len[\"train\"]]\n",
    "    valid_data.data = valid_data.data[:debug_data_len[\"valid\"]]\n",
    "\n",
    "# clean memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0354a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kratkej vypis :D\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "if which_bart == \"original\":\n",
    "    model = BartForConditionalGeneration(config)\n",
    "else:\n",
    "    model = BartSpektoForConditionalGeneration(config)\n",
    "# model = BartForConditionalGeneration.from_pretrained(args.model_path)\n",
    "model.to(args.device)\n",
    "\n",
    "print(\"kratkej vypis :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da335c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_bart == \"original\":\n",
    "    try:\n",
    "        train_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        train_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e6baedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>decoder_attention_mask</th>\n",
       "      <th>encoder_attention_mask</th>\n",
       "      <th>position_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CCNC(c1cnn2c1OCCC2)CC=C=C</td>\n",
       "      <td>[26, 27, 28, 30, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[1233, 224, 283, 11, 70, 20, 284, 21, 70, 20, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 6, 5, 5, 5, 9, 8, 9, 9, 7, 9, 8, 6, 3, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CCC1CN(C(=O)C)C(CN1C(=O)c1nc2ccccc2cc1Cl)CC</td>\n",
       "      <td>[36, 38, 39, 40, 41, 42, 43, 44, 49, 50, 51, 5...</td>\n",
       "      <td>[1233, 224, 276, 20, 263, 11, 38, 260, 50, 12,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 0, 6, 5, 7, 8, 8, 6, 3, 1, 5, 4, 6, 6, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>OC1CNCC1N=c1[nH]c(ncc1[N+](=O)[O-])C(C)(C)C</td>\n",
       "      <td>[30, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[1233, 224, 286, 20, 400, 20, 49, 32, 70, 20, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1, 1, 3, 3, 7, 6, 9, 9, 8, 9, 6, 5, 4, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>COC(=O)Cc1ccc(c(c1)[N+](=O)[O-])NCCc1cnc2n(c1)...</td>\n",
       "      <td>[33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[1233, 224, 285, 260, 50, 12, 279, 20, 280, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 7, 0, 6, 8, 6, 6, 6, 8, 7, 5, 4, 8, 9, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>O=C(c1ccc2c(c1)n[nH]n2)Nc1ccc(cc1)NS(=O)(=O)c1...</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[1233, 224, 50, 32, 38, 11, 70, 20, 280, 21, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 2, 2, 1, 3, 7, 5, 6, 4, 6, 6, 6, 0, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>CC(=CCNCC1(CCOCC1)NC(=O)c1c(C)nsc1C)C</td>\n",
       "      <td>[33, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 5...</td>\n",
       "      <td>[1233, 224, 261, 260, 374, 20, 11, 288, 20, 12...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 8, 7, 9, 8, 9, 8, 6, 7, 7, 8, 6, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>CN(C(C(=O)N1CCC1)C)CC1COCCN1</td>\n",
       "      <td>[15, 18, 27, 28, 32, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[1233, 224, 263, 11, 38, 11, 38, 260, 50, 12, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 0, 1, 3, 1, 1, 5, 5, 8, 8, 8, 8, 6, 4, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>COCC1(OC)CCCN(CC1)CCC(=O)C</td>\n",
       "      <td>[14, 15, 18, 26, 27, 28, 29, 30, 31, 32, 33, 3...</td>\n",
       "      <td>[1233, 224, 306, 20, 11, 286, 12, 299, 11, 261...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 4, 3, 3, 6, 6, 6, 6, 6, 3, 5, 7, 6, 9, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>O=C(c1cccc(c1)CNC(=O)c1c(C)ccnc1O)N=c1cc[nH]cc1</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[1233, 224, 50, 32, 38, 11, 70, 20, 338, 11, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 3, 3, 3, 6, 9, 7, 7, 7, 7, 8, 3, 0, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>CC(C1CC1NC(=O)c1c(Br)nc(n1C)C)C</td>\n",
       "      <td>[30, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 5...</td>\n",
       "      <td>[1233, 224, 261, 11, 38, 20, 261, 20, 265, 260...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 3, 8, 7, 9, 9, 9, 8, 6, 6, 7, 7, 7, 7, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  \\\n",
       "16                            CCNC(c1cnn2c1OCCC2)CC=C=C   \n",
       "19          CCC1CN(C(=O)C)C(CN1C(=O)c1nc2ccccc2cc1Cl)CC   \n",
       "50          OC1CNCC1N=c1[nH]c(ncc1[N+](=O)[O-])C(C)(C)C   \n",
       "59    COC(=O)Cc1ccc(c(c1)[N+](=O)[O-])NCCc1cnc2n(c1)...   \n",
       "64    O=C(c1ccc2c(c1)n[nH]n2)Nc1ccc(cc1)NS(=O)(=O)c1...   \n",
       "...                                                 ...   \n",
       "6796              CC(=CCNCC1(CCOCC1)NC(=O)c1c(C)nsc1C)C   \n",
       "6807                       CN(C(C(=O)N1CCC1)C)CC1COCCN1   \n",
       "6830                         COCC1(OC)CCCN(CC1)CCC(=O)C   \n",
       "6837    O=C(c1cccc(c1)CNC(=O)c1c(C)ccnc1O)N=c1cc[nH]cc1   \n",
       "6920                    CC(C1CC1NC(=O)c1c(Br)nc(n1C)C)C   \n",
       "\n",
       "                                              input_ids  \\\n",
       "16    [26, 27, 28, 30, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "19    [36, 38, 39, 40, 41, 42, 43, 44, 49, 50, 51, 5...   \n",
       "50    [30, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "59    [33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "64    [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "...                                                 ...   \n",
       "6796  [33, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 5...   \n",
       "6807  [15, 18, 27, 28, 32, 38, 39, 40, 41, 42, 43, 4...   \n",
       "6830  [14, 15, 18, 26, 27, 28, 29, 30, 31, 32, 33, 3...   \n",
       "6837  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "6920  [30, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 5...   \n",
       "\n",
       "                                                 labels  \\\n",
       "16    [1233, 224, 283, 11, 70, 20, 284, 21, 70, 20, ...   \n",
       "19    [1233, 224, 276, 20, 263, 11, 38, 260, 50, 12,...   \n",
       "50    [1233, 224, 286, 20, 400, 20, 49, 32, 70, 20, ...   \n",
       "59    [1233, 224, 285, 260, 50, 12, 279, 20, 280, 11...   \n",
       "64    [1233, 224, 50, 32, 38, 11, 70, 20, 280, 21, 7...   \n",
       "...                                                 ...   \n",
       "6796  [1233, 224, 261, 260, 374, 20, 11, 288, 20, 12...   \n",
       "6807  [1233, 224, 263, 11, 38, 11, 38, 260, 50, 12, ...   \n",
       "6830  [1233, 224, 306, 20, 11, 286, 12, 299, 11, 261...   \n",
       "6837  [1233, 224, 50, 32, 38, 11, 70, 20, 338, 11, 7...   \n",
       "6920  [1233, 224, 261, 11, 38, 20, 261, 20, 265, 260...   \n",
       "\n",
       "                                 decoder_attention_mask  \\\n",
       "16    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "50    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "59    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "64    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "6796  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6807  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6830  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6837  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6920  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                 encoder_attention_mask  \\\n",
       "16    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "50    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "59    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "64    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "6796  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6807  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6830  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6837  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6920  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           position_ids  \n",
       "16    [3, 6, 5, 5, 5, 9, 8, 9, 9, 7, 9, 8, 6, 3, 7, ...  \n",
       "19    [3, 0, 6, 5, 7, 8, 8, 6, 3, 1, 5, 4, 6, 6, 5, ...  \n",
       "50    [5, 1, 1, 3, 3, 7, 6, 9, 9, 8, 9, 6, 5, 4, 7, ...  \n",
       "59    [3, 7, 0, 6, 8, 6, 6, 6, 8, 7, 5, 4, 8, 9, 9, ...  \n",
       "64    [3, 2, 2, 1, 3, 7, 5, 6, 4, 6, 6, 6, 0, 2, 4, ...  \n",
       "...                                                 ...  \n",
       "6796  [5, 8, 7, 9, 8, 9, 8, 6, 7, 7, 8, 6, 8, 8, 8, ...  \n",
       "6807  [2, 0, 1, 3, 1, 1, 5, 5, 8, 8, 8, 8, 6, 4, 1, ...  \n",
       "6830  [0, 4, 3, 3, 6, 6, 6, 6, 6, 3, 5, 7, 6, 9, 9, ...  \n",
       "6837  [5, 3, 3, 3, 6, 9, 7, 7, 7, 7, 8, 3, 0, 8, 8, ...  \n",
       "6920  [5, 3, 8, 7, 9, 9, 9, 8, 6, 6, 7, 7, 7, 7, 8, ...  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.data.shape)\n",
    "train_data.data.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e0426e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 354206720\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192219e6",
   "metadata": {},
   "source": [
    "#### Setting run resuming and WandB logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b903a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhajekad\u001b[0m (\u001b[33mmsgc_boys\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhajekad\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch.ssd/ahajek/tmp/zia_training_stuff/wandb/run-20230407_181742-taha2v2e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hajekad/BART_for_gcms/runs/taha2v2e' target=\"_blank\">fine-spaceship-144</a></strong> to <a href='https://wandb.ai/hajekad/BART_for_gcms' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hajekad/BART_for_gcms' target=\"_blank\">https://wandb.ai/hajekad/BART_for_gcms</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hajekad/BART_for_gcms/runs/taha2v2e' target=\"_blank\">https://wandb.ai/hajekad/BART_for_gcms/runs/taha2v2e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resume training\n",
    "if resume_training:\n",
    "    args.load_checkpoint = load_checkpoint\n",
    "    if args.wandb_resume:\n",
    "        args.wandb_id = resume_wandb_id\n",
    "\n",
    "# Init wandb\n",
    "if args.wandb:\n",
    "    wandb.login()\n",
    "    run = wandb.init(id=args.wandb_id, resume=\"allow\", entity=\"hajekad\", project=\"BART_for_gcms\")\n",
    "    wandb.run.name = args.save_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544dea1",
   "metadata": {},
   "source": [
    "#### Setting training arguments (according to args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcfd2e0d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=args.save_dir+\"/\"+args.save_name,         # output directory\n",
    "    num_train_epochs=args.num_train_epochs,              # total # of training epochs\n",
    "    per_device_train_batch_size=args.batch_size,         # batch size per device during training\n",
    "    per_device_eval_batch_size=args.batch_size,          # batch size for evaluation\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    warmup_steps=args.warmup,                                    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=args.weight_decay,                                   # strength of weight decay\n",
    "    logging_dir=args.save_dir + './logs',                # directory for storing logs\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=args.save_name,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=log_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_steps,\n",
    "    fp16=args.fp16,\n",
    "    dataloader_drop_last=False,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=args.num_workers,\n",
    "    sharded_ddp=args.fairscale,\n",
    "    deepspeed=args.deepspeed,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "### custom BartSpectroTrainer arguments\n",
    "# new things: eval_subset_size, generate_kwargs, eval_log_predictions_size, eval_tokenizer\n",
    "# change: evaluation_strategy: , eval_steps, logging_steps, save_strategy, save_steps\n",
    "\n",
    "trainer = BartSpectroTrainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=valid_data,             # evaluation dataset\n",
    "    data_collator = SpectroDataCollator(original=(which_bart==\"original\")),\n",
    "    eval_subset_size = eval_subset_size,\n",
    "    generate_kwargs = {\"num_return_sequences\": 1, \"top_p\": 0.8, \"do_sample\": True, \"num_beams\": 1},\n",
    "    eval_log_predictions_size = eval_log_predictions_size,\n",
    "    eval_tokenizer = tokenizer,\n",
    "    w_run = run # wandb run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6e165",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1211cb1c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments:\n",
      "  lr ........................... 5e-05\n",
      "  seed ......................... 42\n",
      "  gradient_accumulation_steps .. 1\n",
      "  batch_size ................... 32\n",
      "  warmup ....................... 500\n",
      "  weight_decay ................. 0.01\n",
      "  n_gpu ........................ 4\n",
      "  fairscale .................... \n",
      "  deepspeed .................... None\n",
      "  num_workers .................. 16\n",
      "  device ....................... cuda\n",
      "  num_train_epochs ............. 200\n",
      "  output_dir ................... ./output\n",
      "  save_dir ..................... ./checkpoints\n",
      "  save_name .................... bart_2023-04-07-18_17_32\n",
      "  load_checkpoint .............. \n",
      "  config_dir ................... ./configs\n",
      "  fp16 ......................... True\n",
      "  max_grad_norm ................ 1.0\n",
      "  train_data_path .............. ./data/trial_set/DEBUG_train.pkl\n",
      "  valid_data_path .............. ./data/trial_set/DEBUG_valid.pkl\n",
      "  log_steps .................... 1\n",
      "  eval_steps ................... 1000\n",
      "  tokenizer_path ............... /storage/brno6/home/ahajek/nic\n",
      "  model_path ................... ./checkpoints/NECO\n",
      "  wandb ........................ True\n",
      "  wandb_resume ................. False\n",
      "  wandb_id ..................... taha2v2e\n",
      "  tensorboard .................. False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch.ssd/ahajek/tmp/.local-PyTorch:22.04-py3.SIF/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5000\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/scratch.ssd/ahajek/tmp/.conda/envs/BARTtrain/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 105/8000 00:47 < 1:01:00, 2.16 it/s, Epoch 2.60/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# log args to \"args\" file in args.save_dir (right before the training starts, to be the latest)\n",
    "Path(f'{args.save_dir}/{args.save_name}').mkdir(exist_ok=True)\n",
    "arg_log = print_args(args)\n",
    "with open(f'{args.save_dir}/{args.save_name}/args', 'w+') as output_file:\n",
    "    output_file.write(arg_log)\n",
    "\n",
    "if args.load_checkpoint:\n",
    "    trainer.train(args.load_checkpoint)\n",
    "else:\n",
    "    #trainer.evaluate()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "trainer.model.config.max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1541aa",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# tokenizer = BartSpektroTokenizer().init_tokenizer()\n",
    "tok = \"./tokenizer/bbpe_tokenizer/bart_bbpe_1M_tokenizer.model\"\n",
    "tokenizer = Tokenizer.from_file(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1984854",
   "metadata": {},
   "source": [
    "#### Generate and display SMILES from valid data and show the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import glob \n",
    "\n",
    "# load model if not defined\n",
    "model=None     # force the model loading\n",
    "if not model:\n",
    "    checkpoints_pth = \"./checkpoints/*\"\n",
    "    runs = glob.glob(checkpoints_pth)\n",
    "    print(runs)\n",
    "    checkpoints =  glob.glob(sorted(runs)[-3]+\"/checkpoint-*\")\n",
    "    checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    print(checkpoints)\n",
    "    load_checkpoint = checkpoints[-1]\n",
    "    print(f\"last checkpoint: {load_checkpoint}\")\n",
    "    model = BartSpektoForConditionalGeneration.from_pretrained(load_checkpoint)\n",
    "    model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acef529",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = valid_data[500] # 489\n",
    "    outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "    generated = model.generate(\n",
    "               input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "               bos_token_id=503,\n",
    "               forced_bos_token_id=503,\n",
    "               top_p=0.5,\n",
    "               top_k=50,\n",
    "               min_length=30,\n",
    "               do_sample=True,\n",
    "               temperature=0.7\n",
    "               ).tolist()[0],\n",
    "               \n",
    "\n",
    "\n",
    "# print(\"ground truth:\", tokenizer.ids_to_smiles(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "# print(\"ground truth:\", tokenizer.decode(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "print(\"ground truth ids:\", tokenizer.decode(np.array(inputs[\"labels\"].tolist())*np.array(inputs[\"decoder_attention_mask\"].tolist())), \"\\n\\n\")\n",
    "print(\"mask:\", inputs[\"decoder_attention_mask\"].tolist(), \"\\n\\n\")\n",
    "print(\"generated:\", generated, \"\\n\")\n",
    "# print(\"generated:\", tokenizer.ids_to_smiles(generated[0]), \"\\n\")\n",
    "print(\"generated:\", tokenizer.decode(generated[0]), \"\\n\")\n",
    "print(f\"loss: {outputs.loss}\")\n",
    "print(f\"logit bos: {outputs.logits[0][68][503].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ca0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "x = outputs.logits[0][10].cpu().numpy()\n",
    "top_k = np.partition(x, -k)[-k:]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909396a4",
   "metadata": {},
   "source": [
    "### Run evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =torch.ones(3,4).tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# own evaluation \n",
    "model.eval()\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1000)):#tqdm(range(valid_data.len)):\n",
    "        inputs = valid_data[i]\n",
    "        outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "        losses.append(outputs.loss.item())\n",
    "print(f\"my evaluation loss: {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07b399",
   "metadata": {},
   "source": [
    "### Debugging tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37aa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokenizer(t):\n",
    "    print(f\"tok to id: {t.tok_to_id.items()}\\n\")\n",
    "    print(f\"id to tok: {t.id_to_tok.items()}\\n\")\n",
    "    print(f\"tl to tok: {t.tl_to_tok.items()}\\n\")\n",
    "    print(f\"tok to tl: {t.tok_to_tl.items()}\\n\")\n",
    "\n",
    "    print(f\"unk_tok: {t.unk_tok}\")\n",
    "    print(f\"pad_tok: {t.pad_tok}\")\n",
    "    print(f\"eos_tok: {t.eos_tok}\")\n",
    "    print(f\"bos_tok: {t.bos_tok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb2b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ad72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.ids_to_smiles([501])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe688a4c",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89011668",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "420b63a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db05a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BARTtrain",
   "language": "python",
   "name": "barttrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

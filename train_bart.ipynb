{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precise-montreal",
   "metadata": {},
   "source": [
    "## My train using Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-spectacular",
   "metadata": {},
   "source": [
    "Training BART with a changed script from the BERT project (adding position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-underwear",
   "metadata": {},
   "source": [
    "### !! PROBLEMS\n",
    "Miska call\n",
    "* chyba, ze mam jen jeden tokenizer.... PROC?\n",
    "* generate nezere position_ids \n",
    "* zkusit tomu nedavat decoder_input_ids, jenom labels (melo by si je to snad dopocitat z labels)... JO TO ASI POMOHLO\n",
    "    * prepare_decoder_input_ids_from_labels\n",
    "    * pokud nejsou shiftnuty labely doleva, vysvetluje to nizkou loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-implementation",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:07:46.747895Z",
     "iopub.status.busy": "2021-10-06T23:07:46.747279Z",
     "iopub.status.idle": "2021-10-06T23:07:53.596818Z",
     "shell.execute_reply": "2021-10-06T23:07:53.596057Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, BartConfig, BartForConditionalGeneration\n",
    "from transformers.file_utils import logging\n",
    "# from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "\n",
    "# custom veci\n",
    "from dataset import SpectroDataset, SpectroDataCollator\n",
    "sys.path.append('data')\n",
    "sys.path.append('bart_spektro')\n",
    "from modeling_bart_spektro import BartSpektoForConditionalGeneration\n",
    "from configuration_bart_spektro import BartSpektroConfig\n",
    "from data_preprocess1 import print_args\n",
    "from bart_spektro_tokenizer import BartSpektroTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# from utils import add_special_tokens, generate_sample, sample_seq, set_seed, top_k_top_p_filtering, print_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-button",
   "metadata": {},
   "source": [
    "#### Setting basic training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hollow-confirmation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T23:07:54.418555Z",
     "iopub.status.busy": "2021-10-06T23:07:54.417700Z",
     "iopub.status.idle": "2021-10-06T23:07:54.575791Z",
     "shell.execute_reply": "2021-10-06T23:07:54.575082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage-brno6/home/ahajek/Spektro/MassGenie\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dietary-atlantic",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:07:54.583315Z",
     "iopub.status.busy": "2021-10-06T23:07:54.582456Z",
     "iopub.status.idle": "2021-10-06T23:07:54.748691Z",
     "shell.execute_reply": "2021-10-06T23:07:54.749203Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "bs = 32 #4\n",
    "gas = 16/int(os.environ[\"PBS_NGPUS\"]) #16\n",
    "print(\"GA:\", gas)\n",
    "which_bart = \"spektro\" #\"original\" # \"spektro\"\n",
    "data_type = \"8M\"\n",
    "tokenizer_type = \"_bbpe_1M\" # for spektro tokenizer use \"\"\n",
    "tokenizer = Tokenizer.from_file(f\"./tokenizer/bbpe_tokenizer/bart{tokenizer_type}_tokenizer.model\")\n",
    "\n",
    "SEQ_LEN = 200\n",
    "num_epochs = 100 # 10 (BARTy se trenovaly 10 epoch celkem) # int(os.environ[\"TOTAL_EPOCHS\"])\n",
    "resume_training = False # bool(int(os.environ[\"RESUME_TRAINING\"]))\n",
    "resume_wandb_id = \"\" # \"1l7305qk\" #pass # \"\"\n",
    "\n",
    "model = None # aby nebyl nedefinovany\n",
    "\n",
    "# find the last checkpoint\n",
    "\n",
    "# models_pth = \"/storage/projects/msml/mg_neims_branch/models/bart_trial\"\n",
    "# runs = glob.glob(models_pth)\n",
    "# checkpoints =  glob.glob(runs[-1]+\"/checkpoint-*\")\n",
    "# checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "# load_checkpoint = checkpoints[-1]\n",
    "# print(f\"last checkpoint: {load_checkpoint}\")\n",
    "\n",
    "# load_checkpoint = \"./models/bart_2022-06-01-04_30_20/checkpoint-4152/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-designer",
   "metadata": {},
   "source": [
    "#### Setting all training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bronze-gathering",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PBS_NGPUS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4c5bb974939f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PBS_NGPUS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PBS_NGPUS'"
     ]
    }
   ],
   "source": [
    "os.environ[\"PBS_NGPUS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personal-thermal",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:07:54.770335Z",
     "iopub.status.busy": "2021-10-06T23:07:54.769438Z",
     "iopub.status.idle": "2021-10-06T23:07:54.790933Z",
     "shell.execute_reply": "2021-10-06T23:07:54.790013Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments:\n",
      "  lr ........................... 5e-05\n",
      "  seed ......................... 42\n",
      "  gradient_accumulation_steps .. 16\n",
      "  batch_size ................... 32\n",
      "  warmup ....................... 500\n",
      "  weight_decay ................. 0.01\n",
      "  n_gpu ........................ 1\n",
      "  fairscale .................... \n",
      "  deepspeed .................... None\n",
      "  num_workers .................. 5\n",
      "  device ....................... cuda\n",
      "  num_train_epochs ............. 10\n",
      "  output_dir ................... /storage/projects/msml/mg_neims_branch/MassGenie/output\n",
      "  save_dir ..................... /storage/projects/msml/mg_neims_branch/MassGenie/models\n",
      "  save_name .................... bart_2022-06-27-18_17_59\n",
      "  load_checkpoint .............. \n",
      "  config_dir ................... /storage/projects/msml/mg_neims_branch/MassGenie/configs\n",
      "  fp16 ......................... True\n",
      "  max_grad_norm ................ 1.0\n",
      "  train_data_path .............. /storage/projects/msml/mg_neims_branch/MassGenie/data/trial_set/8M_bbpe_1M_bart_prepared_data_train.pkl\n",
      "  valid_data_path .............. /storage/projects/msml/mg_neims_branch/MassGenie/data/trial_set/8M_bbpe_1M_bart_prepared_data_valid.pkl\n",
      "  log_steps .................... 50\n",
      "  eval_steps ................... 7142\n",
      "  tokenizer_path ............... /storage/brno6/home/ahajek/nic\n",
      "  model_path ................... /storage/projects/msml/mg_neims_branch/MassGenie/models/NECO\n",
      "  wandb ........................ True\n",
      "  wandb_resume ................. False\n",
      "  wandb_id ..................... 21jbc692\n",
      "  tensorboard .................. False\n"
     ]
    }
   ],
   "source": [
    "now = str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "now = now.replace(\":\",\"_\").replace(\" \", \"-\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n",
    "parser.add_argument(\"--gradient-accumulation-steps\",default=gas, type=int, help=\"gradient_accumulation_steps\")\n",
    "parser.add_argument(\"--batch-size\",default=bs, type=int,  help=\"batch_size\")\n",
    "parser.add_argument(\"--warmup\",default=500, type=int,  help=\"warmup steps for learning rate\")\n",
    "parser.add_argument(\"--weight-decay\",default=0.01, type=float,  help=\"weight decay rate parameter\")\n",
    "parser.add_argument(\"--n-gpu\",default=os.environ[\"PBS_NGPUS\"], type=int, required=False, help=\"no of gpu available\")\n",
    "parser.add_argument(\"--fairscale\",default=\"\", type=str, required=False, choices=[\"simple\", \"zero_dp_2\", \"zero_dp_3\"], help=\"GPU paralellization via Fairscale, \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--deepspeed\", default=None, type=str, required=False, help=\"GPU paralellization via Deepspeed, the value is the location of DeepSpeed json config file; \" +\n",
    "                    \"more info in HuggingFace's Trainer docs\")\n",
    "parser.add_argument(\"--num-workers\",default=os.environ[\"PBS_NCPUS\"], type=int,  help=\"num of cpus available\")\n",
    "parser.add_argument(\"--device\",default=torch.device('cuda'), help=\"torch.device object\")\n",
    "parser.add_argument(\"--num-train-epochs\",default=num_epochs, type=int,  help=\"number of training epochs\")\n",
    "parser.add_argument(\"--output-dir\",default='/storage/projects/msml/mg_neims_branch/MassGenie/output', type=str,  help=\"Path to save evaluation results\")\n",
    "parser.add_argument(\"--save-dir\",default='/storage/projects/msml/mg_neims_branch/MassGenie/models', type=str,  help=\"Path to save trained model\")\n",
    "parser.add_argument(\"--save-name\", type=str, default=f'bart_{now}', help=\"Name of the model, used for saves\")\n",
    "parser.add_argument(\"--load-checkpoint\", type=str, default='', help=\"Path to the checkpoint to resume training\")\n",
    "parser.add_argument(\"--config-dir\",default='/storage/projects/msml/mg_neims_branch/MassGenie/configs', type=str,  help=\"Path to save config files of models\")\n",
    "parser.add_argument(\"--fp16\",default=True, type=bool, required=False, help=\"whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "parser.add_argument(\"--max-grad-norm\",default=1.0, type=float, help=\"max gradient norm.\")\n",
    "parser.add_argument(\"--train-data-path\",default=f'/storage/projects/msml/mg_neims_branch/MassGenie/data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_train.pkl', type=str, help=\"Path to jsonl train dataset\")\n",
    "parser.add_argument(\"--valid-data-path\",default=f'/storage/projects/msml/mg_neims_branch/MassGenie/data/trial_set/{data_type}{tokenizer_type}_bart_prepared_data_valid.pkl', type=str, help=\"Path to jsonl validation dataset\")\n",
    "parser.add_argument(\"--log-steps\",default=50, type=int,  help=\"number of steps between logs\")\n",
    "parser.add_argument(\"--eval-steps\",default=7142, type=int,  help=\"number of steps between evaluations\")\n",
    "parser.add_argument(\"--tokenizer-path\",default='/storage/brno6/home/ahajek/nic', type=str, help=\"location of the desied tokenizer (special sep token will be added))\")\n",
    "parser.add_argument(\"--model-path\",default='/storage/projects/msml/mg_neims_branch/MassGenie/models/NECO', type=str, help=\"location of the desired model to finetune\")\n",
    "parser.add_argument(\"--wandb\", action='store_true', default=True, help=\"optinal logging via Weights&Biases\")\n",
    "parser.add_argument(\"--wandb-resume\", action='store_true', default=resume_training, help=\"resume logging via wandb, needs an valid run ID set in args.wandb-id\")\n",
    "parser.add_argument(\"--wandb-id\", type=str, default=wandb.util.generate_id(), help=\"Process unique wandb ID used for resumin the training process\")\n",
    "parser.add_argument(\"--tensorboard\", action='store_true', default=False, help=\"optinal logging via TensorBoard\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "arg_log = print_args(args)\n",
    "\n",
    "# extended outputs\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-spelling",
   "metadata": {},
   "source": [
    "#### Loading data, tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "individual-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART CONIGURATION\n",
    "if which_bart == \"spektro\":\n",
    "    config = BartSpektroConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12,\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0,\n",
    "                                 max_log_id=9)\n",
    "\n",
    "if which_bart == \"original\":\n",
    "    config = BartConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                                 max_position_embeddings = SEQ_LEN,\n",
    "                                 max_length = SEQ_LEN,\n",
    "                                 min_len = 0,\n",
    "                                 encoder_layers = 12,\n",
    "                                 encoder_ffn_dim = 4096,\n",
    "                                 encoder_attention_heads = 16,\n",
    "                                 decoder_layers = 12,\n",
    "                                 decoder_ffn_dim = 4096,\n",
    "                                 decoder_attention_heads = 16,\n",
    "                                 encoder_layerdrop = 0.0,\n",
    "                                 decoder_layerdrop = 0.0,\n",
    "                                 activation_function = 'gelu',\n",
    "                                 d_model = 1024,\n",
    "                                 dropout = 0.2,\n",
    "                                 attention_dropout = 0.0,\n",
    "                                 activation_dropout = 0.0,\n",
    "                                 init_std = 0.02,\n",
    "                                 classifier_dropout = 0.0,\n",
    "                                 scale_embedding = False,\n",
    "                                 use_cache = True,\n",
    "                                 pad_token_id = 2,\n",
    "                                 bos_token_id = 3,\n",
    "                                 eos_token_id = 0,\n",
    "                                 is_encoder_decoder = True,\n",
    "                                 decoder_start_token_id = 3,\n",
    "                                 forced_eos_token_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interracial-rental",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T23:07:54.795676Z",
     "iopub.status.busy": "2021-10-06T23:07:54.795243Z",
     "iopub.status.idle": "2021-10-06T23:08:20.068457Z",
     "shell.execute_reply": "2021-10-06T23:08:20.067778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kratkej vypis :D\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "train_data = SpectroDataset(args.train_data_path, original=which_bart==\"original\")\n",
    "valid_data = SpectroDataset(args.valid_data_path, original=which_bart==\"original\")\n",
    "\n",
    "# clean memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# TOKENIZER\n",
    "# tokenizer = add_special_tokens(args.tokenizer_path)\n",
    "\n",
    "# MODEL\n",
    "if which_bart == \"original\":\n",
    "    model = BartForConditionalGeneration(config)\n",
    "else:\n",
    "    model = BartSpektoForConditionalGeneration(config)\n",
    "# model = BartForConditionalGeneration.from_pretrained(args.model_path)\n",
    "model.to(args.device)\n",
    "\n",
    "print(\"kratkej vypis :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governing-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 1M dataset\n",
    "# train_data.data.rename(columns={\"lm_labels\":\"labels\"}, inplace=True)\n",
    "# valid_data.data.rename(columns={\"lm_labels\":\"labels\"}, inplace=True)\n",
    "if which_bart == \"original\":\n",
    "    try:\n",
    "        train_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"position_ids\"], inplace=True)\n",
    "        train_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "        valid_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prostate-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destereo_smiles</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>decoder_input_ids</th>\n",
       "      <th>encoder_attention_mask</th>\n",
       "      <th>decoder_attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>position_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(cc1)CNN=Nc1ccccc1</td>\n",
       "      <td>[14, 15, 26, 27, 28, 29, 30, 32, 33, 37, 38, 3...</td>\n",
       "      <td>[3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...</td>\n",
       "      <td>[2, 0, 3, 5, 6, 3, 5, 1, 2, 3, 5, 8, 6, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C1CCC2C(C3C1C3(C)C)C(CC2)(C)O</td>\n",
       "      <td>[26, 27, 28, 29, 30, 31, 37, 38, 39, 40, 41, 4...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...</td>\n",
       "      <td>[5, 8, 6, 8, 5, 6, 1, 5, 8, 7, 9, 7, 9, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC(=S)C1(CCC1)COc1ccccc1</td>\n",
       "      <td>[14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30, 3...</td>\n",
       "      <td>[3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...</td>\n",
       "      <td>[1, 3, 2, 3, 3, 1, 5, 7, 6, 6, 4, 4, 2, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cccc2c1n(CC(=O)C)c(cc2=O)C</td>\n",
       "      <td>[14, 15, 26, 27, 29, 31, 33, 37, 38, 39, 40, 4...</td>\n",
       "      <td>[3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...</td>\n",
       "      <td>[0, 2, 1, 1, 3, 1, 3, 4, 6, 7, 6, 7, 7, 9, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clc1cccc(c1)n1c(=O)cc([nH]c1=O)C(=O)O</td>\n",
       "      <td>[25, 26, 29, 33, 34, 35, 36, 37, 38, 39, 40, 4...</td>\n",
       "      <td>[3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...</td>\n",
       "      <td>[1, 2, 0, 1, 3, 6, 7, 7, 8, 8, 8, 8, 8, 7, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641073</th>\n",
       "      <td>Oc1ccc(cc1)C1CCN(CC1)C(=O)c1ccco1</td>\n",
       "      <td>[33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...</td>\n",
       "      <td>[3, 3, 4, 6, 8, 6, 7, 7, 6, 6, 4, 3, 5, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641074</th>\n",
       "      <td>CC(=O)Nc1ccc(cc1)C(c1ccc(cc1)C)(C)C</td>\n",
       "      <td>[33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 50, 5...</td>\n",
       "      <td>[3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...</td>\n",
       "      <td>[2, 2, 3, 7, 6, 8, 5, 9, 5, 2, 6, 7, 6, 7, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641075</th>\n",
       "      <td>Brc1ccc(cc1)C(c1ccncc1)N</td>\n",
       "      <td>[14, 15, 17, 18, 25, 26, 27, 28, 29, 30, 34, 3...</td>\n",
       "      <td>[3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...</td>\n",
       "      <td>[0, 2, 2, 1, 1, 5, 5, 6, 4, 3, 1, 3, 6, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641076</th>\n",
       "      <td>OC(=O)c1cc(nc2c1c(C)no2)c1ccccc1F</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...</td>\n",
       "      <td>[6, 3, 5, 6, 7, 9, 8, 8, 8, 8, 9, 9, 6, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641077</th>\n",
       "      <td>CCN(C(=O)C1CC(CN1C(=O)c1n[nH]c2c1CCC2)N)CC</td>\n",
       "      <td>[31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...</td>\n",
       "      <td>[3, 5, 4, 4, 3, 5, 8, 7, 9, 9, 7, 9, 7, 6, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4641078 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    destereo_smiles  \\\n",
       "0                           c1ccc(cc1)CNN=Nc1ccccc1   \n",
       "1                   O=C1CCC2C(C3C1C3(C)C)C(CC2)(C)O   \n",
       "2                          NC(=S)C1(CCC1)COc1ccccc1   \n",
       "3                    COc1cccc2c1n(CC(=O)C)c(cc2=O)C   \n",
       "4             Clc1cccc(c1)n1c(=O)cc([nH]c1=O)C(=O)O   \n",
       "...                                             ...   \n",
       "4641073           Oc1ccc(cc1)C1CCN(CC1)C(=O)c1ccco1   \n",
       "4641074         CC(=O)Nc1ccc(cc1)C(c1ccc(cc1)C)(C)C   \n",
       "4641075                    Brc1ccc(cc1)C(c1ccncc1)N   \n",
       "4641076           OC(=O)c1cc(nc2c1c(C)no2)c1ccccc1F   \n",
       "4641077  CCN(C(=O)C1CC(CN1C(=O)c1n[nH]c2c1CCC2)N)CC   \n",
       "\n",
       "                                                 input_ids  \\\n",
       "0        [14, 15, 26, 27, 28, 29, 30, 32, 33, 37, 38, 3...   \n",
       "1        [26, 27, 28, 29, 30, 31, 37, 38, 39, 40, 41, 4...   \n",
       "2        [14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30, 3...   \n",
       "3        [14, 15, 26, 27, 29, 31, 33, 37, 38, 39, 40, 4...   \n",
       "4        [25, 26, 29, 33, 34, 35, 36, 37, 38, 39, 40, 4...   \n",
       "...                                                    ...   \n",
       "4641073  [33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "4641074  [33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 50, 5...   \n",
       "4641075  [14, 15, 17, 18, 25, 26, 27, 28, 29, 30, 34, 3...   \n",
       "4641076  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "4641077  [31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...   \n",
       "\n",
       "                                         decoder_input_ids  \\\n",
       "0        [3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...   \n",
       "1        [3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...   \n",
       "2        [3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...   \n",
       "3        [3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...   \n",
       "4        [3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...   \n",
       "...                                                    ...   \n",
       "4641073  [3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...   \n",
       "4641074  [3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...   \n",
       "4641075  [3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...   \n",
       "4641076  [3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...   \n",
       "4641077  [3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...   \n",
       "\n",
       "                                    encoder_attention_mask  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                    ...   \n",
       "4641073  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641074  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641075  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641076  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641077  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                    decoder_attention_mask  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                    ...   \n",
       "4641073  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641074  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641075  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641076  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4641077  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                    labels  \\\n",
       "0        [3, 224, 70, 20, 280, 11, 266, 20, 12, 679, 32...   \n",
       "1        [3, 224, 50, 32, 38, 20, 276, 21, 38, 11, 38, ...   \n",
       "2        [3, 224, 265, 260, 54, 12, 38, 20, 11, 276, 20...   \n",
       "3        [3, 224, 327, 20, 338, 21, 70, 20, 81, 11, 261...   \n",
       "4        [3, 224, 364, 70, 20, 338, 11, 70, 20, 12, 81,...   \n",
       "...                                                    ...   \n",
       "4641073  [3, 224, 469, 20, 280, 11, 266, 20, 12, 38, 20...   \n",
       "4641074  [3, 224, 261, 260, 50, 12, 329, 20, 280, 11, 2...   \n",
       "4641075  [3, 224, 466, 70, 20, 280, 11, 266, 20, 12, 38...   \n",
       "4641076  [3, 224, 286, 260, 50, 12, 70, 20, 266, 11, 27...   \n",
       "4641077  [3, 224, 269, 11, 38, 260, 50, 12, 38, 20, 261...   \n",
       "\n",
       "                                              position_ids  \n",
       "0        [2, 0, 3, 5, 6, 3, 5, 1, 2, 3, 5, 8, 6, 7, 6, ...  \n",
       "1        [5, 8, 6, 8, 5, 6, 1, 5, 8, 7, 9, 7, 9, 6, 6, ...  \n",
       "2        [1, 3, 2, 3, 3, 1, 5, 7, 6, 6, 4, 4, 2, 4, 4, ...  \n",
       "3        [0, 2, 1, 1, 3, 1, 3, 4, 6, 7, 6, 7, 7, 9, 7, ...  \n",
       "4        [1, 2, 0, 1, 3, 6, 7, 7, 8, 8, 8, 8, 8, 7, 9, ...  \n",
       "...                                                    ...  \n",
       "4641073  [3, 3, 4, 6, 8, 6, 7, 7, 6, 6, 4, 3, 5, 7, 6, ...  \n",
       "4641074  [2, 2, 3, 7, 6, 8, 5, 9, 5, 2, 6, 7, 6, 7, 3, ...  \n",
       "4641075  [0, 2, 2, 1, 1, 5, 5, 6, 4, 3, 1, 3, 6, 7, 7, ...  \n",
       "4641076  [6, 3, 5, 6, 7, 9, 8, 8, 8, 8, 9, 9, 6, 3, 0, ...  \n",
       "4641077  [3, 5, 4, 4, 3, 5, 8, 7, 9, 9, 7, 9, 7, 6, 2, ...  \n",
       "\n",
       "[4641078 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.input_ids])\n",
    "# assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.decoder_input_ids])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.encoder_attention_mask])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.decoder_attention_mask])\n",
    "assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.labels])\n",
    "if which_bart == \"spektro\":\n",
    "    assert 0 == sum([len(x) != SEQ_LEN for x in train_data.data.position_ids])\n",
    "    \n",
    "# NA TOTO BACHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA  POZOOOOOOOOOOOOOOOOOR POZOROROROROROROROROROORORORORORKVOKVOEK    \n",
    "# train_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "# valid_data.data.drop(columns=[\"decoder_input_ids\"], inplace=True)\n",
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacterial-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair type at position_ids\n",
    "\n",
    "#for x in train_data.data.position_ids:\n",
    "# #     print(x.dtype)\n",
    "#     if x.dtype != np.dtype('int32'):\n",
    "#         print(x)\n",
    "# train_data.data.position_ids[0].dtype == np.dtype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "japanese-packaging",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:08:20.072079Z",
     "iopub.status.busy": "2021-10-06T23:08:20.071355Z",
     "iopub.status.idle": "2021-10-06T23:08:20.073798Z",
     "shell.execute_reply": "2021-10-06T23:08:20.073140Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 354200576\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-costs",
   "metadata": {},
   "source": [
    "#### Setting run resuming and WandB logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "successful-habitat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T23:08:20.081323Z",
     "iopub.status.busy": "2021-10-06T23:08:20.080892Z",
     "iopub.status.idle": "2021-10-06T23:08:25.559006Z",
     "shell.execute_reply": "2021-10-06T23:08:25.559590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmsgc_boys\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">snowy-snowflake-63</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hajekad/BART_for_gcms\" target=\"_blank\">https://wandb.ai/hajekad/BART_for_gcms</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hajekad/BART_for_gcms/runs/21jbc692\" target=\"_blank\">https://wandb.ai/hajekad/BART_for_gcms/runs/21jbc692</a><br/>\n",
       "                Run data is saved locally in <code>/auto/brno6/home/ahajek/Spektro/MassGenie/wandb/run-20220627_182428-21jbc692</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resume training\n",
    "if resume_training:\n",
    "    args.load_checkpoint = load_checkpoint\n",
    "    if args.wandb_resume:\n",
    "        args.wandb_id = resume_wandb_id\n",
    "\n",
    "# Init wandb\n",
    "if args.wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(id=args.wandb_id, resume=\"allow\", entity=\"hajekad\", project=\"BART_for_gcms\")\n",
    "    wandb.run.name = args.save_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-variable",
   "metadata": {},
   "source": [
    "#### Setting training arguments (according to args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "secondary-premium",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:08:25.568722Z",
     "iopub.status.busy": "2021-10-06T23:08:25.568091Z",
     "iopub.status.idle": "2021-10-06T23:08:26.169291Z",
     "shell.execute_reply": "2021-10-06T23:08:26.169886Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=args.save_dir+\"/\"+args.save_name,         # output directory\n",
    "    num_train_epochs=args.num_train_epochs,              # total # of training epochs\n",
    "    per_device_train_batch_size=args.batch_size,         # batch size per device during training\n",
    "    per_device_eval_batch_size=args.batch_size,          # batch size for evaluation\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    warmup_steps=args.warmup,                                    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=args.weight_decay,                                   # strength of weight decay\n",
    "    logging_dir=args.save_dir + './logs',                # directory for storing logs\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=args.save_name,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "#     eval_steps=args.eval_steps,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1, # args.log_steps,\n",
    "    save_strategy=\"epoch\",\n",
    "#     save_steps=1000,\n",
    "    fp16=args.fp16,\n",
    "    dataloader_drop_last=True,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=args.num_workers,\n",
    "    sharded_ddp=args.fairscale,\n",
    "    deepspeed=args.deepspeed,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=valid_data,             # evaluation dataset\n",
    "    data_collator = SpectroDataCollator(original=(which_bart==\"original\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-tobago",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-permission",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-10-06T23:08:26.173100Z",
     "iopub.status.busy": "2021-10-06T23:08:26.172359Z",
     "iopub.status.idle": "2021-10-07T19:20:14.222372Z",
     "shell.execute_reply": "2021-10-07T19:20:14.223148Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/brno6/home/ahajek/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4641078\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 90640\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:752: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:787: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='239' max='90640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  239/90640 29:27 < 187:13:28, 0.13 it/s, Epoch 0.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log args to \"args\" file in args.save_dir (right before the training starts, to be the latest)\n",
    "Path(f'{args.save_dir}/{args.save_name}').mkdir(exist_ok=True)\n",
    "with open(f'{args.save_dir}/{args.save_name}/args', 'w+') as output_file:\n",
    "    output_file.write(arg_log)\n",
    "\n",
    "if args.load_checkpoint:\n",
    "    trainer.train(args.load_checkpoint)\n",
    "else:\n",
    "    #trainer.evaluate()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-atmosphere",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wicked-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# tokenizer = BartSpektroTokenizer().init_tokenizer()\n",
    "tok = \"./tokenizer/bbpe_tokenizer/bart_bbpe_1M_tokenizer.model\"\n",
    "tokenizer = Tokenizer.from_file(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-aurora",
   "metadata": {},
   "source": [
    "#### Generate and display SMILES from valid data and show the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fewer-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6920/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"BartSpektoForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 503,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 502,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 502,\n",
      "  \"forced_eos_token_id\": 502,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_log_id\": 9,\n",
      "  \"max_position_embeddings\": 200,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 501,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 600\n",
      "}\n",
      "\n",
      "loading weights file /storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6920/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-11-14_44_04_NO_P_IDs', '/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-06-01-09_52_21_bbpe1M_IDs', '/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-06-01-14_50_36', '/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs', '/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-10-16_06_04_P_IDs']\n",
      "['/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6228', '/storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6920']\n",
      "last checkpoint: /storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BartSpektoForConditionalGeneration.\n",
      "\n",
      "All the weights of BartSpektoForConditionalGeneration were initialized from the model checkpoint at /storage/projects/msml/mg_neims_branch/MassGenie/models/bart_2022-05-31-11_53_31_bbpe1K_IDs/checkpoint-6920.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartSpektoForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "import glob \n",
    "\n",
    "# load model if not defined\n",
    "model=None     # force the model loading\n",
    "if not model:\n",
    "    models_pth = \"/storage/projects/msml/mg_neims_branch/MassGenie/models/*\"\n",
    "    runs = glob.glob(models_pth)\n",
    "    print(runs)\n",
    "    checkpoints =  glob.glob(sorted(runs)[-3]+\"/checkpoint-*\")\n",
    "    checkpoints.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    print(checkpoints)\n",
    "    load_checkpoint = checkpoints[-1]\n",
    "    print(f\"last checkpoint: {load_checkpoint}\")\n",
    "    model = BartSpektoForConditionalGeneration.from_pretrained(load_checkpoint)\n",
    "    model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "assured-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[502,\n",
       " 503,\n",
       " 224,\n",
       " 437,\n",
       " 260,\n",
       " 50,\n",
       " 12,\n",
       " 263,\n",
       " 20,\n",
       " 269,\n",
       " 11,\n",
       " 261,\n",
       " 20,\n",
       " 12,\n",
       " 38,\n",
       " 260,\n",
       " 50,\n",
       " 12,\n",
       " 38,\n",
       " 502]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "confident-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth ids:  COc1cccc(c1)CC(=O)NC1CN(CC1O)C(=O)C(NC(=O)N)C \n",
      "\n",
      "\n",
      "mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "\n",
      "generated: ([502, 503, 224, 331, 20, 323, 11, 70, 20, 12, 261, 260, 50, 12, 272, 20, 266, 11, 261, 502],) \n",
      "\n",
      "generated: COCCCSNCCOCCO OCCO1ccnc(c1)CC(=O)CCO1cc(CCCOCCCS \n",
      "\n",
      "loss: 4.943031311035156\n",
      "logit bos: 0.5182749629020691\n"
     ]
    }
   ],
   "source": [
    "torch.seed()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = valid_data[500] # 489\n",
    "    outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "    generated = model.generate(\n",
    "               input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "               bos_token_id=503,\n",
    "               forced_bos_token_id=503,\n",
    "               top_p=0.5,\n",
    "               top_k=50,\n",
    "               min_length=30,\n",
    "               do_sample=True,\n",
    "               temperature=0.7\n",
    "               ).tolist()[0],\n",
    "               \n",
    "\n",
    "\n",
    "# print(\"ground truth:\", tokenizer.ids_to_smiles(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "# print(\"ground truth:\", tokenizer.decode(inputs[\"labels\"].tolist()), \"\\n\\n\")\n",
    "print(\"ground truth ids:\", tokenizer.decode(np.array(inputs[\"labels\"].tolist())*np.array(inputs[\"decoder_attention_mask\"].tolist())), \"\\n\\n\")\n",
    "print(\"mask:\", inputs[\"decoder_attention_mask\"].tolist(), \"\\n\\n\")\n",
    "print(\"generated:\", generated, \"\\n\")\n",
    "# print(\"generated:\", tokenizer.ids_to_smiles(generated[0]), \"\\n\")\n",
    "print(\"generated:\", tokenizer.decode(generated[0]), \"\\n\")\n",
    "print(f\"loss: {outputs.loss}\")\n",
    "print(f\"logit bos: {outputs.logits[0][68][503].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "                    position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                    labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "considered-welcome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0152, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "worth-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(3.0152, device='cuda:0'), logits=tensor([[[-0.0170, -0.3663, -0.1512,  ..., -0.6392, -1.5668, -0.9503],\n",
       "         [ 0.5132, -1.0161,  0.2738,  ...,  0.1879, -1.1371, -0.7397],\n",
       "         [ 0.4215, -2.6604, -2.6799,  ..., -2.3999, -2.8463, -2.9328],\n",
       "         ...,\n",
       "         [12.8004, -0.0289,  0.2292,  ...,  0.1463, -0.3587, -0.5953],\n",
       "         [12.8562,  0.0174,  0.2741,  ...,  0.1814, -0.3457, -0.5184],\n",
       "         [13.1502,  0.0494,  0.3001,  ...,  0.1577, -0.2962, -0.5157]]],\n",
       "       device='cuda:0'), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.7694, -0.9320, -1.0044,  ...,  0.3718,  0.7595,  0.8037],\n",
       "         [-0.7321, -0.9464, -0.9625,  ...,  0.3598,  0.7415,  0.7888],\n",
       "         [ 0.8197,  0.9224, -0.6806,  ...,  0.7534, -0.3882,  1.7202],\n",
       "         ...,\n",
       "         [ 0.0690,  0.5991, -1.3737,  ...,  0.0799, -0.0585,  1.4387],\n",
       "         [ 0.0690,  0.5991, -1.3737,  ...,  0.0799, -0.0585,  1.4387],\n",
       "         [ 0.0690,  0.5991, -1.3737,  ...,  0.0799, -0.0585,  1.4387]]],\n",
       "       device='cuda:0'), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "x = outputs.logits[0][10].cpu().numpy()\n",
    "top_k = np.partition(x, -k)[-k:]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-worthy",
   "metadata": {},
   "source": [
    "### Run evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "third-delivery",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destereo_smiles</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>decoder_input_ids</th>\n",
       "      <th>encoder_attention_mask</th>\n",
       "      <th>decoder_attention_mask</th>\n",
       "      <th>lm_labels</th>\n",
       "      <th>position_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OCC1OC(Oc2ccccc2C(=O)OC)C(C(C1O)O)NC(=O)C</td>\n",
       "      <td>[14, 15, 16, 17, 18, 19, 26, 27, 28, 29, 30, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[2, 6, 1, 4, 5, 5, 3, 6, 6, 6, 5, 8, 5, 3, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OC(=O)C(CSCC1OC(C(C1O)O)n1cnc2c1ncnc2N)N</td>\n",
       "      <td>[16, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 3...</td>\n",
       "      <td>[503, 542, 531, 506, 510, 542, 507, 531, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 506, 510, 542, 507, 531, 506, ...</td>\n",
       "      <td>[1, 1, 3, 0, 1, 1, 4, 5, 5, 4, 0, 1, 2, 2, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OCC1OC(SC2OC(CO)C(C(C2O)O)O)C(C(C1O)O)O</td>\n",
       "      <td>[14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 545, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 545, ...</td>\n",
       "      <td>[3, 4, 3, 4, 6, 4, 4, 6, 7, 6, 8, 6, 8, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>O=C1NC(C(=O)N1)CC(=O)N1CCN(CC1)CC(=O)N1CCCCC1</td>\n",
       "      <td>[28, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 541, 531, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 541, 531, 506, 531, ...</td>\n",
       "      <td>[3, 4, 3, 6, 4, 6, 7, 7, 8, 9, 8, 9, 6, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>COC(=O)C(CC(=O)OC)NCCCNC(C(=O)OC)CC(=O)OC</td>\n",
       "      <td>[15, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 3...</td>\n",
       "      <td>[503, 531, 542, 531, 506, 510, 542, 507, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 506, 510, 542, 507, 531, ...</td>\n",
       "      <td>[6, 1, 5, 6, 7, 6, 4, 6, 3, 6, 1, 6, 6, 8, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>O=c1cc(N2CCC(C2)NS(=O)(=O)N2CCCC2)n(c(=O)n1C)C</td>\n",
       "      <td>[27, 28, 33, 34, 36, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 541, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 541, ...</td>\n",
       "      <td>[0, 2, 4, 3, 1, 3, 7, 6, 8, 9, 8, 7, 6, 5, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1cnn(c1)C</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[4, 1, 1, 5, 6, 7, 8, 9, 8, 8, 8, 4, 1, 6, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>OCC(NC(=O)CC1C(=O)NCCN1Cc1ccc(cc1)C)(CO)CO</td>\n",
       "      <td>[14, 15, 17, 18, 19, 25, 26, 27, 28, 29, 30, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 541, 531, 506, 510, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 541, 531, 506, 510, ...</td>\n",
       "      <td>[3, 5, 4, 5, 0, 3, 5, 7, 8, 7, 6, 7, 6, 5, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>O=C(CNC(=O)c1ccccc1)NCC(=O)NC1CCS(=O)(=O)C1</td>\n",
       "      <td>[16, 17, 18, 28, 29, 30, 32, 33, 36, 37, 38, 3...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 531, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 531, 506, ...</td>\n",
       "      <td>[0, 2, 3, 4, 4, 6, 3, 0, 0, 1, 3, 5, 4, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Cn1ncc(c1)N1CC(CCC1=O)C(=O)N1CCNS(=O)(=O)CC1</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 531, 565, 520, 565, 555, 555, 506, 555, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 565, 520, 565, 555, 555, 506, 555, ...</td>\n",
       "      <td>[3, 1, 0, 4, 7, 6, 8, 9, 8, 8, 7, 1, 1, 3, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>OCC(NC(=O)CC1N(CCNC1=O)Cc1ccc(o1)C)(CO)CO</td>\n",
       "      <td>[17, 18, 26, 27, 28, 30, 31, 32, 33, 36, 38, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 541, 531, 506, 510, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 541, 531, 506, 510, ...</td>\n",
       "      <td>[1, 3, 1, 0, 5, 1, 6, 5, 5, 0, 3, 7, 6, 8, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>O=c1n(C)cc(c(=O)n1C)S(=O)(=O)NCC1CCn2c(C1)ncc2</td>\n",
       "      <td>[33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 48, 5...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 565, 506, 531, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 565, 506, 531, 507, ...</td>\n",
       "      <td>[4, 3, 3, 8, 7, 9, 9, 8, 7, 6, 6, 4, 6, 7, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CC1CC(CN1C(=O)Cn1nnc(=N)[nH]1)NC(=O)c1cnn2c1CCC2</td>\n",
       "      <td>[33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 531, 531, 520, 531, 531, 506, 531, 541, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 531, 520, 531, 531, 506, 531, 541, ...</td>\n",
       "      <td>[1, 3, 1, 4, 7, 7, 9, 9, 8, 8, 6, 4, 3, 6, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Cc1cc(C)n(c(=O)n1)CC(=O)N1CC(C(C1)O)CS(=O)(=O)...</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 531, 555, 520, 555, 555, 506, 531, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 555, 520, 555, 555, 506, 531, 507, ...</td>\n",
       "      <td>[4, 2, 3, 4, 5, 8, 7, 8, 9, 8, 9, 7, 6, 2, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>OC1CN(CC1CS(=O)(=O)N(C)C)c1nc(N)c2c(n1)n(C)nc2</td>\n",
       "      <td>[15, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 4...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 541, 506, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 541, 506, 531, 531, ...</td>\n",
       "      <td>[3, 2, 3, 1, 4, 2, 4, 3, 7, 7, 7, 9, 9, 9, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>COCCOCC(=O)N1CCN(C2C1CS(=O)(=O)C2)c1ncccn1</td>\n",
       "      <td>[15, 26, 27, 28, 29, 30, 31, 33, 39, 40, 41, 4...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 542, 531, 531, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 542, 531, 531, 506, ...</td>\n",
       "      <td>[1, 4, 7, 6, 7, 4, 7, 4, 7, 6, 9, 9, 8, 7, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>CC(CC(C(=O)NCCCCNC(=N)N)NC(=O)C1OC1C(=O)O)C</td>\n",
       "      <td>[14, 16, 17, 18, 25, 26, 27, 28, 29, 30, 31, 3...</td>\n",
       "      <td>[503, 531, 531, 506, 531, 531, 506, 531, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 531, 506, 531, 531, 506, 531, 506, ...</td>\n",
       "      <td>[2, 4, 4, 3, 0, 2, 6, 5, 4, 7, 1, 3, 2, 1, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1cnccn1</td>\n",
       "      <td>[26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 3...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[3, 6, 4, 4, 3, 4, 3, 1, 4, 0, 5, 8, 7, 9, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>OCC1OC(OC2OC=C(C3C2C(=CC3)CO)C(=O)O)C(C(C1O)O)O</td>\n",
       "      <td>[14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[3, 4, 1, 5, 5, 4, 4, 6, 7, 6, 8, 6, 8, 4, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Cn1ncc(c1)C(C(=O)N1CCN(CC1)CC(=O)N1CCOCC1)O</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 531, 565, 520, 565, 555, 555, 506, 555, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 565, 520, 565, 555, 555, 506, 555, ...</td>\n",
       "      <td>[4, 3, 5, 4, 6, 8, 7, 8, 9, 8, 8, 7, 5, 6, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>OCC1OC(O)C(C(C1O)OC1OC(C)C(C(C1O)O)O)NC(=O)C</td>\n",
       "      <td>[14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[3, 4, 2, 3, 4, 4, 3, 4, 3, 5, 5, 6, 6, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>CCS(=O)(=O)N1CCN(CC1)S(=O)(=O)C1CCS(=O)(=O)C1</td>\n",
       "      <td>[27, 29, 34, 39, 40, 41, 42, 43, 44, 45, 46, 4...</td>\n",
       "      <td>[503, 531, 531, 545, 506, 510, 542, 507, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 531, 545, 506, 510, 542, 507, 506, ...</td>\n",
       "      <td>[4, 4, 0, 5, 4, 7, 9, 7, 3, 5, 4, 2, 6, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>O=c1n(C)c2n(cnc2c(=O)n1C)CN1CCN(CC1)S(=O)(=O)C</td>\n",
       "      <td>[33, 34, 39, 40, 41, 42, 43, 44, 45, 46, 47, 4...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 565, 506, 531, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 565, 506, 531, 507, ...</td>\n",
       "      <td>[3, 3, 6, 6, 7, 9, 6, 7, 6, 5, 2, 6, 5, 6, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>O=C1CC2C(N1CCOc1nonc1C)CCN2C(=O)Cn1cnnn1</td>\n",
       "      <td>[33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 531, 531, 521, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 531, 531, 521, 531, ...</td>\n",
       "      <td>[3, 1, 3, 4, 7, 6, 8, 9, 8, 7, 5, 0, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>CNC(=O)CN(c1nccc(n1)N1CCNC2C1CS(=O)(=O)C2)C</td>\n",
       "      <td>[41, 42, 43, 44, 52, 53, 54, 55, 56, 57, 58, 5...</td>\n",
       "      <td>[503, 531, 541, 531, 506, 510, 542, 507, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 531, 506, 510, 542, 507, 531, ...</td>\n",
       "      <td>[6, 9, 8, 7, 6, 5, 7, 5, 8, 6, 9, 7, 4, 4, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>OC1CN(CCC1NC(=O)c1ccc(cc1)n1cnnn1)CC(=O)N(C)C</td>\n",
       "      <td>[33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 541, 506, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 541, 506, 531, 531, ...</td>\n",
       "      <td>[3, 0, 3, 6, 8, 7, 8, 9, 7, 9, 6, 5, 7, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>O=C1NCC(N1)C(=O)N1CC(C(C1)(C)C)NC(=O)c1cc(n(n1...</td>\n",
       "      <td>[33, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 5...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 541, 531, 531, 506, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 541, 531, 531, 506, ...</td>\n",
       "      <td>[1, 1, 7, 6, 9, 8, 8, 9, 3, 1, 4, 5, 6, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>CN1CCN(CC1)S(=O)(=O)N1CCN(CC1)CC1CCC(=O)N(C1)C</td>\n",
       "      <td>[27, 28, 29, 30, 32, 36, 38, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[3, 3, 2, 4, 2, 0, 3, 4, 3, 5, 8, 8, 8, 6, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>O=C(N1CCN(CC1)c1ccc(nn1)n1cncn1)Cn1ncccc1=O</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[4, 1, 1, 3, 6, 8, 7, 7, 9, 8, 7, 6, 4, 6, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>O=C(c1nn2c(n1)nccc2)NC1COCC1CS(=O)(=O)N(C)C</td>\n",
       "      <td>[39, 40, 41, 42, 43, 44, 45, 48, 51, 52, 53, 5...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[7, 4, 7, 7, 7, 8, 1, 4, 2, 6, 7, 7, 7, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>O=c1cc(C(=O)N2CCOCC(C2)(O)CN2CCCC2)n(c(=O)n1C)C</td>\n",
       "      <td>[14, 15, 16, 17, 18, 26, 27, 28, 29, 30, 33, 3...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 531, ...</td>\n",
       "      <td>[1, 3, 0, 1, 4, 3, 5, 6, 4, 6, 2, 0, 3, 4, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>OCCOC1CC(C21CCN(CC2)C(=O)Cn1cc(C)c(=O)[nH]c1=O)O</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 531, 531, 542, 531, 520, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 542, 531, 520, 531, 531, ...</td>\n",
       "      <td>[5, 3, 1, 0, 4, 8, 7, 9, 9, 9, 9, 9, 7, 6, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>O=C(N1CCN(CC1)S(=O)(=O)C)CN1C(=O)NC2(C1=O)CCCC2</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[4, 2, 2, 4, 7, 6, 8, 9, 8, 8, 5, 3, 1, 6, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>O=C(N1CCN(C2C1CS(=O)(=O)C2)S(=O)(=O)C)c1cccnc1</td>\n",
       "      <td>[26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[1, 6, 4, 3, 4, 1, 2, 1, 3, 4, 8, 7, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>CN1CCN(CC1)S(=O)(=O)N1CCN(CC1)C(=O)Cn1cccn1</td>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[3, 1, 2, 3, 0, 3, 5, 5, 6, 8, 8, 8, 5, 1, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>O=C1CC2C(N1CCN1CCN(C1=O)C)CCN2C(=O)Cn1cnnn1</td>\n",
       "      <td>[30, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 531, 531, 521, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 520, 531, 531, 521, 531, ...</td>\n",
       "      <td>[1, 4, 0, 1, 2, 6, 6, 8, 9, 8, 7, 5, 1, 3, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>O=C(c1nnn(c1)CCN1CCNCC1)NCCSc1ncn[nH]1</td>\n",
       "      <td>[33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[2, 2, 3, 4, 3, 7, 8, 7, 8, 6, 5, 4, 3, 1, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>O=C(CN1C(=O)NC(C1=O)(C)C1CC1)NC(=O)NC1CCS(=O)(...</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 520, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 520, 531, ...</td>\n",
       "      <td>[4, 3, 4, 4, 8, 7, 9, 9, 8, 9, 6, 3, 1, 6, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>CC(C(=O)N1CCN(CC1)CC(=O)c1c(N)n(C)c(=O)n(c1=O)C)C</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 5...</td>\n",
       "      <td>[503, 531, 531, 506, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 531, 506, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[5, 4, 0, 3, 7, 7, 8, 9, 9, 8, 6, 5, 6, 7, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>O=C(c1nnn(c1)CC1CCCNC1)N1CCN(CC1)S(=O)(=O)N</td>\n",
       "      <td>[28, 30, 33, 36, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 565, 565, ...</td>\n",
       "      <td>[4, 3, 2, 4, 3, 6, 6, 8, 9, 9, 9, 6, 3, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1ccnn1C</td>\n",
       "      <td>[28, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[3, 0, 3, 2, 4, 0, 6, 7, 7, 9, 9, 9, 8, 8, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>CNC(=O)c1scc(c1)S(=O)(=O)N(C1CS(=O)(=O)CC1O)C</td>\n",
       "      <td>[31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[503, 531, 541, 531, 506, 510, 542, 507, 555, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 531, 506, 510, 542, 507, 555, ...</td>\n",
       "      <td>[2, 6, 5, 6, 6, 5, 6, 6, 7, 8, 9, 6, 9, 9, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>O=C(CN1C(=O)NC(C1=O)(C)C)NC1CCN(CC1O)c1nccnc1</td>\n",
       "      <td>[38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 5...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 520, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 531, 541, 520, 531, ...</td>\n",
       "      <td>[2, 8, 6, 8, 8, 8, 7, 5, 0, 5, 6, 7, 7, 7, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>COCCn1nnc2c1CCN(C2)S(=O)(=O)c1cn(C)c(=O)nc1O</td>\n",
       "      <td>[33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 4...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 565, 520, 565, 565, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 531, 565, 520, 565, 565, ...</td>\n",
       "      <td>[4, 3, 3, 5, 6, 8, 9, 8, 8, 9, 6, 5, 5, 3, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>OCC=Cc1cc(OC)c(c(c1)OC)OC1OC(CO)C(C(C1O)O)O</td>\n",
       "      <td>[17, 18, 26, 27, 28, 29, 30, 31, 32, 33, 38, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 510, 531, 555, 520, 555, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 510, 531, 555, 520, 555, ...</td>\n",
       "      <td>[3, 3, 1, 4, 3, 4, 3, 6, 1, 1, 1, 5, 2, 6, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>O=c1[nH]c(=O)[nH]cc1S(=O)(=O)N1CCCCC1CN1CCOCC1</td>\n",
       "      <td>[33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 504, 565, 536, 505, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 504, 565, 536, 505, ...</td>\n",
       "      <td>[3, 2, 3, 1, 5, 5, 8, 8, 6, 6, 4, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>CN1CCN(CC1)c1nccc(n1)N1CCNC2C1CS(=O)(=O)C2</td>\n",
       "      <td>[15, 26, 27, 28, 29, 30, 38, 39, 40, 41, 42, 4...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[5, 4, 6, 7, 7, 4, 4, 6, 5, 7, 9, 8, 7, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>OC(=O)CN1C(=O)NC2C1OC(O2)C1OC2C(O1)N(C(=O)N2)C...</td>\n",
       "      <td>[16, 17, 18, 19, 26, 27, 28, 29, 30, 31, 33, 3...</td>\n",
       "      <td>[503, 542, 531, 506, 510, 542, 507, 531, 541, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 506, 510, 542, 507, 531, 541, ...</td>\n",
       "      <td>[2, 3, 3, 1, 4, 6, 7, 7, 6, 7, 2, 4, 1, 5, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>O=C(c1c[nH]nc1n1cnnn1)NCc1ncnc(c1)N1CCOCC1</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 555, 504, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 555, 520, 555, 504, ...</td>\n",
       "      <td>[6, 3, 3, 4, 6, 9, 8, 9, 9, 9, 9, 8, 6, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>CN(CC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)C1C2C1CNC2)C</td>\n",
       "      <td>[30, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5...</td>\n",
       "      <td>[503, 531, 541, 506, 531, 531, 506, 510, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 541, 506, 531, 531, 506, 510, 542, ...</td>\n",
       "      <td>[3, 0, 1, 6, 5, 8, 9, 8, 9, 6, 3, 3, 4, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>OCCN1CCCC2(C1=O)CCN(C2)C(=O)Cn1cc(C)c(=O)[nH]c1=O</td>\n",
       "      <td>[30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[503, 542, 531, 531, 541, 520, 531, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 541, 520, 531, 531, 531, ...</td>\n",
       "      <td>[4, 4, 2, 3, 2, 5, 8, 7, 9, 9, 8, 8, 7, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>OCC(C(=O)N1CCc2c(C1)cc(cc2)S(=O)(=O)N1CCOCC1)N</td>\n",
       "      <td>[33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 5...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 531, 506, 510, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 506, 531, 506, 510, 542, ...</td>\n",
       "      <td>[2, 0, 1, 5, 4, 6, 7, 7, 6, 6, 4, 5, 6, 6, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>OCC1OC(OC2OC=C(C3C2C(C)CC3)C(=O)O)C(C(C1O)O)O</td>\n",
       "      <td>[14, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 3...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 531, 520, 542, 531, 506, 542, ...</td>\n",
       "      <td>[1, 4, 5, 2, 2, 4, 5, 4, 6, 4, 7, 1, 3, 3, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>CCNC(=O)C1CC(CN1C(=O)COC)NC(=O)c1cnc([nH]c1=O)C</td>\n",
       "      <td>[33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 4...</td>\n",
       "      <td>[503, 531, 531, 541, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 531, 541, 531, 506, 510, 542, 507, ...</td>\n",
       "      <td>[3, 7, 6, 9, 9, 8, 9, 9, 8, 7, 3, 7, 7, 8, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>OC1CCN(CC1)CCCNC(=O)C(=O)NCCCN1CCC(CC1)O</td>\n",
       "      <td>[33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 4...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 531, 520, 531, 531, 541, 506, 531, ...</td>\n",
       "      <td>[2, 1, 1, 6, 8, 9, 9, 9, 7, 3, 0, 1, 3, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>COc1ccnc(n1)N1CCN(CC1)C(=O)Cc1c[nH]c(=O)n(c1=O)C</td>\n",
       "      <td>[26, 27, 28, 30, 33, 38, 39, 40, 41, 42, 43, 4...</td>\n",
       "      <td>[503, 531, 542, 555, 520, 555, 555, 565, 555, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 555, 520, 555, 555, 565, 555, ...</td>\n",
       "      <td>[0, 0, 4, 2, 3, 1, 6, 5, 7, 8, 7, 6, 5, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>COC1C(O)C(OC1n1cnc2c1nc(NC(=O)C(C)C)[nH]c2=O)CO</td>\n",
       "      <td>[31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
       "      <td>[503, 531, 542, 531, 520, 531, 506, 542, 507, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 531, 542, 531, 520, 531, 506, 542, 507, ...</td>\n",
       "      <td>[2, 4, 0, 0, 5, 5, 8, 8, 9, 8, 8, 6, 6, 4, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>O=c1cc(C(=O)NCCN2CCN(CC2)c2ncccn2)n(c(=O)n1C)C</td>\n",
       "      <td>[39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 5...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 555, 520, 555, 555, 506, 531, ...</td>\n",
       "      <td>[5, 1, 6, 8, 4, 6, 4, 0, 2, 4, 6, 7, 7, 7, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>O=C(N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1ccc[nH]c1=O)...</td>\n",
       "      <td>[33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[503, 542, 510, 531, 506, 541, 520, 531, 531, ...</td>\n",
       "      <td>[5, 4, 4, 3, 6, 8, 8, 9, 9, 9, 9, 8, 5, 2, 5, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       destereo_smiles  \\\n",
       "9            OCC1OC(Oc2ccccc2C(=O)OC)C(C(C1O)O)NC(=O)C   \n",
       "15            OC(=O)C(CSCC1OC(C(C1O)O)n1cnc2c1ncnc2N)N   \n",
       "16             OCC1OC(SC2OC(CO)C(C(C2O)O)O)C(C(C1O)O)O   \n",
       "31       O=C1NC(C(=O)N1)CC(=O)N1CCN(CC1)CC(=O)N1CCCCC1   \n",
       "41           COC(=O)C(CC(=O)OC)NCCCNC(C(=O)OC)CC(=O)OC   \n",
       "75      O=c1cc(N2CCC(C2)NS(=O)(=O)N2CCCC2)n(c(=O)n1C)C   \n",
       "76      COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1cnn(c1)C   \n",
       "99          OCC(NC(=O)CC1C(=O)NCCN1Cc1ccc(cc1)C)(CO)CO   \n",
       "119        O=C(CNC(=O)c1ccccc1)NCC(=O)NC1CCS(=O)(=O)C1   \n",
       "120       Cn1ncc(c1)N1CC(CCC1=O)C(=O)N1CCNS(=O)(=O)CC1   \n",
       "128          OCC(NC(=O)CC1N(CCNC1=O)Cc1ccc(o1)C)(CO)CO   \n",
       "147     O=c1n(C)cc(c(=O)n1C)S(=O)(=O)NCC1CCn2c(C1)ncc2   \n",
       "161   CC1CC(CN1C(=O)Cn1nnc(=N)[nH]1)NC(=O)c1cnn2c1CCC2   \n",
       "193  Cc1cc(C)n(c(=O)n1)CC(=O)N1CC(C(C1)O)CS(=O)(=O)...   \n",
       "227     OC1CN(CC1CS(=O)(=O)N(C)C)c1nc(N)c2c(n1)n(C)nc2   \n",
       "229         COCCOCC(=O)N1CCN(C2C1CS(=O)(=O)C2)c1ncccn1   \n",
       "241        CC(CC(C(=O)NCCCCNC(=N)N)NC(=O)C1OC1C(=O)O)C   \n",
       "260       COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1cnccn1   \n",
       "278    OCC1OC(OC2OC=C(C3C2C(=CC3)CO)C(=O)O)C(C(C1O)O)O   \n",
       "289        Cn1ncc(c1)C(C(=O)N1CCN(CC1)CC(=O)N1CCOCC1)O   \n",
       "291       OCC1OC(O)C(C(C1O)OC1OC(C)C(C(C1O)O)O)NC(=O)C   \n",
       "302      CCS(=O)(=O)N1CCN(CC1)S(=O)(=O)C1CCS(=O)(=O)C1   \n",
       "304     O=c1n(C)c2n(cnc2c(=O)n1C)CN1CCN(CC1)S(=O)(=O)C   \n",
       "320           O=C1CC2C(N1CCOc1nonc1C)CCN2C(=O)Cn1cnnn1   \n",
       "326        CNC(=O)CN(c1nccc(n1)N1CCNC2C1CS(=O)(=O)C2)C   \n",
       "329      OC1CN(CCC1NC(=O)c1ccc(cc1)n1cnnn1)CC(=O)N(C)C   \n",
       "343  O=C1NCC(N1)C(=O)N1CC(C(C1)(C)C)NC(=O)c1cc(n(n1...   \n",
       "347     CN1CCN(CC1)S(=O)(=O)N1CCN(CC1)CC1CCC(=O)N(C1)C   \n",
       "350        O=C(N1CCN(CC1)c1ccc(nn1)n1cncn1)Cn1ncccc1=O   \n",
       "366        O=C(c1nn2c(n1)nccc2)NC1COCC1CS(=O)(=O)N(C)C   \n",
       "413    O=c1cc(C(=O)N2CCOCC(C2)(O)CN2CCCC2)n(c(=O)n1C)C   \n",
       "436   OCCOC1CC(C21CCN(CC2)C(=O)Cn1cc(C)c(=O)[nH]c1=O)O   \n",
       "444    O=C(N1CCN(CC1)S(=O)(=O)C)CN1C(=O)NC2(C1=O)CCCC2   \n",
       "459     O=C(N1CCN(C2C1CS(=O)(=O)C2)S(=O)(=O)C)c1cccnc1   \n",
       "465        CN1CCN(CC1)S(=O)(=O)N1CCN(CC1)C(=O)Cn1cccn1   \n",
       "471        O=C1CC2C(N1CCN1CCN(C1=O)C)CCN2C(=O)Cn1cnnn1   \n",
       "474             O=C(c1nnn(c1)CCN1CCNCC1)NCCSc1ncn[nH]1   \n",
       "506  O=C(CN1C(=O)NC(C1=O)(C)C1CC1)NC(=O)NC1CCS(=O)(...   \n",
       "507  CC(C(=O)N1CCN(CC1)CC(=O)c1c(N)n(C)c(=O)n(c1=O)C)C   \n",
       "521        O=C(c1nnn(c1)CC1CCCNC1)N1CCN(CC1)S(=O)(=O)N   \n",
       "545       COCC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1ccnn1C   \n",
       "551      CNC(=O)c1scc(c1)S(=O)(=O)N(C1CS(=O)(=O)CC1O)C   \n",
       "552      O=C(CN1C(=O)NC(C1=O)(C)C)NC1CCN(CC1O)c1nccnc1   \n",
       "555       COCCn1nnc2c1CCN(C2)S(=O)(=O)c1cn(C)c(=O)nc1O   \n",
       "563        OCC=Cc1cc(OC)c(c(c1)OC)OC1OC(CO)C(C(C1O)O)O   \n",
       "572     O=c1[nH]c(=O)[nH]cc1S(=O)(=O)N1CCCCC1CN1CCOCC1   \n",
       "575         CN1CCN(CC1)c1nccc(n1)N1CCNC2C1CS(=O)(=O)C2   \n",
       "576  OC(=O)CN1C(=O)NC2C1OC(O2)C1OC2C(O1)N(C(=O)N2)C...   \n",
       "577         O=C(c1c[nH]nc1n1cnnn1)NCc1ncnc(c1)N1CCOCC1   \n",
       "593  CN(CC(=O)N1CCN(C2C1CS(=O)(=O)C2)C(=O)C1C2C1CNC2)C   \n",
       "595  OCCN1CCCC2(C1=O)CCN(C2)C(=O)Cn1cc(C)c(=O)[nH]c1=O   \n",
       "612     OCC(C(=O)N1CCc2c(C1)cc(cc2)S(=O)(=O)N1CCOCC1)N   \n",
       "617      OCC1OC(OC2OC=C(C3C2C(C)CC3)C(=O)O)C(C(C1O)O)O   \n",
       "619    CCNC(=O)C1CC(CN1C(=O)COC)NC(=O)c1cnc([nH]c1=O)C   \n",
       "621           OC1CCN(CC1)CCCNC(=O)C(=O)NCCCN1CCC(CC1)O   \n",
       "647   COc1ccnc(n1)N1CCN(CC1)C(=O)Cc1c[nH]c(=O)n(c1=O)C   \n",
       "695    COC1C(O)C(OC1n1cnc2c1nc(NC(=O)C(C)C)[nH]c2=O)CO   \n",
       "697     O=c1cc(C(=O)NCCN2CCN(CC2)c2ncccn2)n(c(=O)n1C)C   \n",
       "712  O=C(N1CCN(C2C1CS(=O)(=O)C2)C(=O)c1ccc[nH]c1=O)...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "9    [14, 15, 16, 17, 18, 19, 26, 27, 28, 29, 30, 3...   \n",
       "15   [16, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 3...   \n",
       "16   [14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...   \n",
       "31   [28, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...   \n",
       "41   [15, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 3...   \n",
       "75   [27, 28, 33, 34, 36, 38, 39, 40, 41, 42, 43, 4...   \n",
       "76   [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "99   [14, 15, 17, 18, 19, 25, 26, 27, 28, 29, 30, 3...   \n",
       "119  [16, 17, 18, 28, 29, 30, 32, 33, 36, 37, 38, 3...   \n",
       "120  [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "128  [17, 18, 26, 27, 28, 30, 31, 32, 33, 36, 38, 3...   \n",
       "147  [33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 48, 5...   \n",
       "161  [33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "193  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "227  [15, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 4...   \n",
       "229  [15, 26, 27, 28, 29, 30, 31, 33, 39, 40, 41, 4...   \n",
       "241  [14, 16, 17, 18, 25, 26, 27, 28, 29, 30, 31, 3...   \n",
       "260  [26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 3...   \n",
       "278  [14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...   \n",
       "289  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "291  [14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 3...   \n",
       "302  [27, 29, 34, 39, 40, 41, 42, 43, 44, 45, 46, 4...   \n",
       "304  [33, 34, 39, 40, 41, 42, 43, 44, 45, 46, 47, 4...   \n",
       "320  [33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "326  [41, 42, 43, 44, 52, 53, 54, 55, 56, 57, 58, 5...   \n",
       "329  [33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "343  [33, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 5...   \n",
       "347  [27, 28, 29, 30, 32, 36, 38, 39, 40, 41, 42, 4...   \n",
       "350  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "366  [39, 40, 41, 42, 43, 44, 45, 48, 51, 52, 53, 5...   \n",
       "413  [14, 15, 16, 17, 18, 26, 27, 28, 29, 30, 33, 3...   \n",
       "436  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "444  [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "459  [26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 4...   \n",
       "465  [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 4...   \n",
       "471  [30, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "474  [33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 4...   \n",
       "506  [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "507  [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 5...   \n",
       "521  [28, 30, 33, 36, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "545  [28, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 4...   \n",
       "551  [31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 4...   \n",
       "552  [38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 5...   \n",
       "555  [33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 4...   \n",
       "563  [17, 18, 26, 27, 28, 29, 30, 31, 32, 33, 38, 3...   \n",
       "572  [33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "575  [15, 26, 27, 28, 29, 30, 38, 39, 40, 41, 42, 4...   \n",
       "576  [16, 17, 18, 19, 26, 27, 28, 29, 30, 31, 33, 3...   \n",
       "577  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "593  [30, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5...   \n",
       "595  [30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 4...   \n",
       "612  [33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 5...   \n",
       "617  [14, 17, 18, 19, 25, 26, 27, 28, 29, 30, 31, 3...   \n",
       "619  [33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 4...   \n",
       "621  [33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 4...   \n",
       "647  [26, 27, 28, 30, 33, 38, 39, 40, 41, 42, 43, 4...   \n",
       "695  [31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 4...   \n",
       "697  [39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 5...   \n",
       "712  [33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 4...   \n",
       "\n",
       "                                     decoder_input_ids  \\\n",
       "9    [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "15   [503, 542, 531, 506, 510, 542, 507, 531, 506, ...   \n",
       "16   [503, 542, 531, 531, 520, 542, 531, 506, 545, ...   \n",
       "31   [503, 542, 510, 531, 520, 541, 531, 506, 531, ...   \n",
       "41   [503, 531, 542, 531, 506, 510, 542, 507, 531, ...   \n",
       "75   [503, 542, 510, 555, 520, 555, 555, 506, 541, ...   \n",
       "76   [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "99   [503, 542, 531, 531, 506, 541, 531, 506, 510, ...   \n",
       "119  [503, 542, 510, 531, 506, 531, 541, 531, 506, ...   \n",
       "120  [503, 531, 565, 520, 565, 555, 555, 506, 555, ...   \n",
       "128  [503, 542, 531, 531, 506, 541, 531, 506, 510, ...   \n",
       "147  [503, 542, 510, 555, 520, 565, 506, 531, 507, ...   \n",
       "161  [503, 531, 531, 520, 531, 531, 506, 531, 541, ...   \n",
       "193  [503, 531, 555, 520, 555, 555, 506, 531, 507, ...   \n",
       "227  [503, 542, 531, 520, 531, 541, 506, 531, 531, ...   \n",
       "229  [503, 531, 542, 531, 531, 542, 531, 531, 506, ...   \n",
       "241  [503, 531, 531, 506, 531, 531, 506, 531, 506, ...   \n",
       "260  [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "278  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "289  [503, 531, 565, 520, 565, 555, 555, 506, 555, ...   \n",
       "291  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "302  [503, 531, 531, 545, 506, 510, 542, 507, 506, ...   \n",
       "304  [503, 542, 510, 555, 520, 565, 506, 531, 507, ...   \n",
       "320  [503, 542, 510, 531, 520, 531, 531, 521, 531, ...   \n",
       "326  [503, 531, 541, 531, 506, 510, 542, 507, 531, ...   \n",
       "329  [503, 542, 531, 520, 531, 541, 506, 531, 531, ...   \n",
       "343  [503, 542, 510, 531, 520, 541, 531, 531, 506, ...   \n",
       "347  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "350  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "366  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "413  [503, 542, 510, 555, 520, 555, 555, 506, 531, ...   \n",
       "436  [503, 542, 531, 531, 542, 531, 520, 531, 531, ...   \n",
       "444  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "459  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "465  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "471  [503, 542, 510, 531, 520, 531, 531, 521, 531, ...   \n",
       "474  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "506  [503, 542, 510, 531, 506, 531, 541, 520, 531, ...   \n",
       "507  [503, 531, 531, 506, 531, 506, 510, 542, 507, ...   \n",
       "521  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "545  [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "551  [503, 531, 541, 531, 506, 510, 542, 507, 555, ...   \n",
       "552  [503, 542, 510, 531, 506, 531, 541, 520, 531, ...   \n",
       "555  [503, 531, 542, 531, 531, 565, 520, 565, 565, ...   \n",
       "563  [503, 542, 531, 531, 510, 531, 555, 520, 555, ...   \n",
       "572  [503, 542, 510, 555, 520, 504, 565, 536, 505, ...   \n",
       "575  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "576  [503, 542, 531, 506, 510, 542, 507, 531, 541, ...   \n",
       "577  [503, 542, 510, 531, 506, 555, 520, 555, 504, ...   \n",
       "593  [503, 531, 541, 506, 531, 531, 506, 510, 542, ...   \n",
       "595  [503, 542, 531, 531, 541, 520, 531, 531, 531, ...   \n",
       "612  [503, 542, 531, 531, 506, 531, 506, 510, 542, ...   \n",
       "617  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "619  [503, 531, 531, 541, 531, 506, 510, 542, 507, ...   \n",
       "621  [503, 542, 531, 520, 531, 531, 541, 506, 531, ...   \n",
       "647  [503, 531, 542, 555, 520, 555, 555, 565, 555, ...   \n",
       "695  [503, 531, 542, 531, 520, 531, 506, 542, 507, ...   \n",
       "697  [503, 542, 510, 555, 520, 555, 555, 506, 531, ...   \n",
       "712  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "\n",
       "                                encoder_attention_mask  \\\n",
       "9    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "31   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "41   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "75   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "76   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "99   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "119  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "128  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "147  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "161  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "193  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "227  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "229  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "241  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "260  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "278  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "289  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "291  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "302  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "304  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "320  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "326  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "329  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "343  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "347  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "350  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "366  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "413  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "436  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "444  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "459  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "465  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "471  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "474  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "506  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "507  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "521  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "545  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "551  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "552  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "555  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "563  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "572  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "575  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "576  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "577  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "593  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "595  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "612  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "617  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "619  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "621  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "647  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "695  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "697  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "712  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                decoder_attention_mask  \\\n",
       "9    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "31   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "41   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "75   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "76   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "99   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "119  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "128  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "147  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "161  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "193  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "227  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "229  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "241  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "260  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "278  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "289  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "291  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "302  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "304  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "320  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "326  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "329  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "343  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "347  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "350  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "366  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "413  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "436  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "444  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "459  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "465  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "471  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "474  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "506  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "507  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "521  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "545  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "551  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "552  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "555  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "563  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "572  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "575  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "576  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "577  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "593  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "595  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "612  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "617  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "619  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "621  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "647  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "695  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "697  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "712  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                             lm_labels  \\\n",
       "9    [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "15   [503, 542, 531, 506, 510, 542, 507, 531, 506, ...   \n",
       "16   [503, 542, 531, 531, 520, 542, 531, 506, 545, ...   \n",
       "31   [503, 542, 510, 531, 520, 541, 531, 506, 531, ...   \n",
       "41   [503, 531, 542, 531, 506, 510, 542, 507, 531, ...   \n",
       "75   [503, 542, 510, 555, 520, 555, 555, 506, 541, ...   \n",
       "76   [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "99   [503, 542, 531, 531, 506, 541, 531, 506, 510, ...   \n",
       "119  [503, 542, 510, 531, 506, 531, 541, 531, 506, ...   \n",
       "120  [503, 531, 565, 520, 565, 555, 555, 506, 555, ...   \n",
       "128  [503, 542, 531, 531, 506, 541, 531, 506, 510, ...   \n",
       "147  [503, 542, 510, 555, 520, 565, 506, 531, 507, ...   \n",
       "161  [503, 531, 531, 520, 531, 531, 506, 531, 541, ...   \n",
       "193  [503, 531, 555, 520, 555, 555, 506, 531, 507, ...   \n",
       "227  [503, 542, 531, 520, 531, 541, 506, 531, 531, ...   \n",
       "229  [503, 531, 542, 531, 531, 542, 531, 531, 506, ...   \n",
       "241  [503, 531, 531, 506, 531, 531, 506, 531, 506, ...   \n",
       "260  [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "278  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "289  [503, 531, 565, 520, 565, 555, 555, 506, 555, ...   \n",
       "291  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "302  [503, 531, 531, 545, 506, 510, 542, 507, 506, ...   \n",
       "304  [503, 542, 510, 555, 520, 565, 506, 531, 507, ...   \n",
       "320  [503, 542, 510, 531, 520, 531, 531, 521, 531, ...   \n",
       "326  [503, 531, 541, 531, 506, 510, 542, 507, 531, ...   \n",
       "329  [503, 542, 531, 520, 531, 541, 506, 531, 531, ...   \n",
       "343  [503, 542, 510, 531, 520, 541, 531, 531, 506, ...   \n",
       "347  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "350  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "366  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "413  [503, 542, 510, 555, 520, 555, 555, 506, 531, ...   \n",
       "436  [503, 542, 531, 531, 542, 531, 520, 531, 531, ...   \n",
       "444  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "459  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "465  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "471  [503, 542, 510, 531, 520, 531, 531, 521, 531, ...   \n",
       "474  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "506  [503, 542, 510, 531, 506, 531, 541, 520, 531, ...   \n",
       "507  [503, 531, 531, 506, 531, 506, 510, 542, 507, ...   \n",
       "521  [503, 542, 510, 531, 506, 555, 520, 565, 565, ...   \n",
       "545  [503, 531, 542, 531, 531, 506, 510, 542, 507, ...   \n",
       "551  [503, 531, 541, 531, 506, 510, 542, 507, 555, ...   \n",
       "552  [503, 542, 510, 531, 506, 531, 541, 520, 531, ...   \n",
       "555  [503, 531, 542, 531, 531, 565, 520, 565, 565, ...   \n",
       "563  [503, 542, 531, 531, 510, 531, 555, 520, 555, ...   \n",
       "572  [503, 542, 510, 555, 520, 504, 565, 536, 505, ...   \n",
       "575  [503, 531, 541, 520, 531, 531, 541, 506, 531, ...   \n",
       "576  [503, 542, 531, 506, 510, 542, 507, 531, 541, ...   \n",
       "577  [503, 542, 510, 531, 506, 555, 520, 555, 504, ...   \n",
       "593  [503, 531, 541, 506, 531, 531, 506, 510, 542, ...   \n",
       "595  [503, 542, 531, 531, 541, 520, 531, 531, 531, ...   \n",
       "612  [503, 542, 531, 531, 506, 531, 506, 510, 542, ...   \n",
       "617  [503, 542, 531, 531, 520, 542, 531, 506, 542, ...   \n",
       "619  [503, 531, 531, 541, 531, 506, 510, 542, 507, ...   \n",
       "621  [503, 542, 531, 520, 531, 531, 541, 506, 531, ...   \n",
       "647  [503, 531, 542, 555, 520, 555, 555, 565, 555, ...   \n",
       "695  [503, 531, 542, 531, 520, 531, 506, 542, 507, ...   \n",
       "697  [503, 542, 510, 555, 520, 555, 555, 506, 531, ...   \n",
       "712  [503, 542, 510, 531, 506, 541, 520, 531, 531, ...   \n",
       "\n",
       "                                          position_ids  \n",
       "9    [2, 6, 1, 4, 5, 5, 3, 6, 6, 6, 5, 8, 5, 3, 6, ...  \n",
       "15   [1, 1, 3, 0, 1, 1, 4, 5, 5, 4, 0, 1, 2, 2, 6, ...  \n",
       "16   [3, 4, 3, 4, 6, 4, 4, 6, 7, 6, 8, 6, 8, 5, 4, ...  \n",
       "31   [3, 4, 3, 6, 4, 6, 7, 7, 8, 9, 8, 9, 6, 1, 2, ...  \n",
       "41   [6, 1, 5, 6, 7, 6, 4, 6, 3, 6, 1, 6, 6, 8, 9, ...  \n",
       "75   [0, 2, 4, 3, 1, 3, 7, 6, 8, 9, 8, 7, 6, 5, 3, ...  \n",
       "76   [4, 1, 1, 5, 6, 7, 8, 9, 8, 8, 8, 4, 1, 6, 5, ...  \n",
       "99   [3, 5, 4, 5, 0, 3, 5, 7, 8, 7, 6, 7, 6, 5, 2, ...  \n",
       "119  [0, 2, 3, 4, 4, 6, 3, 0, 0, 1, 3, 5, 4, 6, 6, ...  \n",
       "120  [3, 1, 0, 4, 7, 6, 8, 9, 8, 8, 7, 1, 1, 3, 6, ...  \n",
       "128  [1, 3, 1, 0, 5, 1, 6, 5, 5, 0, 3, 7, 6, 8, 9, ...  \n",
       "147  [4, 3, 3, 8, 7, 9, 9, 8, 7, 6, 6, 4, 6, 7, 8, ...  \n",
       "161  [1, 3, 1, 4, 7, 7, 9, 9, 8, 8, 6, 4, 3, 6, 7, ...  \n",
       "193  [4, 2, 3, 4, 5, 8, 7, 8, 9, 8, 9, 7, 6, 2, 5, ...  \n",
       "227  [3, 2, 3, 1, 4, 2, 4, 3, 7, 7, 7, 9, 9, 9, 7, ...  \n",
       "229  [1, 4, 7, 6, 7, 4, 7, 4, 7, 6, 9, 9, 8, 7, 9, ...  \n",
       "241  [2, 4, 4, 3, 0, 2, 6, 5, 4, 7, 1, 3, 2, 1, 4, ...  \n",
       "260  [3, 6, 4, 4, 3, 4, 3, 1, 4, 0, 5, 8, 7, 9, 9, ...  \n",
       "278  [3, 4, 1, 5, 5, 4, 4, 6, 7, 6, 8, 6, 8, 4, 3, ...  \n",
       "289  [4, 3, 5, 4, 6, 8, 7, 8, 9, 8, 8, 7, 5, 6, 7, ...  \n",
       "291  [3, 4, 2, 3, 4, 4, 3, 4, 3, 5, 5, 6, 6, 3, 4, ...  \n",
       "302  [4, 4, 0, 5, 4, 7, 9, 7, 3, 5, 4, 2, 6, 2, 0, ...  \n",
       "304  [3, 3, 6, 6, 7, 9, 6, 7, 6, 5, 2, 6, 5, 6, 7, ...  \n",
       "320  [3, 1, 3, 4, 7, 6, 8, 9, 8, 7, 5, 0, 2, 2, 2, ...  \n",
       "326  [6, 9, 8, 7, 6, 5, 7, 5, 8, 6, 9, 7, 4, 4, 7, ...  \n",
       "329  [3, 0, 3, 6, 8, 7, 8, 9, 7, 9, 6, 5, 7, 7, 6, ...  \n",
       "343  [1, 1, 7, 6, 9, 8, 8, 9, 3, 1, 4, 5, 6, 7, 7, ...  \n",
       "347  [3, 3, 2, 4, 2, 0, 3, 4, 3, 5, 8, 8, 8, 6, 3, ...  \n",
       "350  [4, 1, 1, 3, 6, 8, 7, 7, 9, 8, 7, 6, 4, 6, 8, ...  \n",
       "366  [7, 4, 7, 7, 7, 8, 1, 4, 2, 6, 7, 7, 7, 8, 8, ...  \n",
       "413  [1, 3, 0, 1, 4, 3, 5, 6, 4, 6, 2, 0, 3, 4, 6, ...  \n",
       "436  [5, 3, 1, 0, 4, 8, 7, 9, 9, 9, 9, 9, 7, 6, 0, ...  \n",
       "444  [4, 2, 2, 4, 7, 6, 8, 9, 8, 8, 5, 3, 1, 6, 1, ...  \n",
       "459  [1, 6, 4, 3, 4, 1, 2, 1, 3, 4, 8, 7, 8, 8, 8, ...  \n",
       "465  [3, 1, 2, 3, 0, 3, 5, 5, 6, 8, 8, 8, 5, 1, 5, ...  \n",
       "471  [1, 4, 0, 1, 2, 6, 6, 8, 9, 8, 7, 5, 1, 3, 5, ...  \n",
       "474  [2, 2, 3, 4, 3, 7, 8, 7, 8, 6, 5, 4, 3, 1, 4, ...  \n",
       "506  [4, 3, 4, 4, 8, 7, 9, 9, 8, 9, 6, 3, 1, 6, 1, ...  \n",
       "507  [5, 4, 0, 3, 7, 7, 8, 9, 9, 8, 6, 5, 6, 7, 8, ...  \n",
       "521  [4, 3, 2, 4, 3, 6, 6, 8, 9, 9, 9, 6, 3, 4, 4, ...  \n",
       "545  [3, 0, 3, 2, 4, 0, 6, 7, 7, 9, 9, 9, 8, 8, 5, ...  \n",
       "551  [2, 6, 5, 6, 6, 5, 6, 6, 7, 8, 9, 6, 9, 9, 7, ...  \n",
       "552  [2, 8, 6, 8, 8, 8, 7, 5, 0, 5, 6, 7, 7, 7, 9, ...  \n",
       "555  [4, 3, 3, 5, 6, 8, 9, 8, 8, 9, 6, 5, 5, 3, 6, ...  \n",
       "563  [3, 3, 1, 4, 3, 4, 3, 6, 1, 1, 1, 5, 2, 6, 4, ...  \n",
       "572  [3, 2, 3, 1, 5, 5, 8, 8, 6, 6, 4, 3, 3, 3, 3, ...  \n",
       "575  [5, 4, 6, 7, 7, 4, 4, 6, 5, 7, 9, 8, 7, 2, 3, ...  \n",
       "576  [2, 3, 3, 1, 4, 6, 7, 7, 6, 7, 2, 4, 1, 5, 7, ...  \n",
       "577  [6, 3, 3, 4, 6, 9, 8, 9, 9, 9, 9, 8, 6, 3, 2, ...  \n",
       "593  [3, 0, 1, 6, 5, 8, 9, 8, 9, 6, 3, 3, 4, 6, 6, ...  \n",
       "595  [4, 4, 2, 3, 2, 5, 8, 7, 9, 9, 8, 8, 7, 4, 4, ...  \n",
       "612  [2, 0, 1, 5, 4, 6, 7, 7, 6, 6, 4, 5, 6, 6, 4, ...  \n",
       "617  [1, 4, 5, 2, 2, 4, 5, 4, 6, 4, 7, 1, 3, 3, 1, ...  \n",
       "619  [3, 7, 6, 9, 9, 8, 9, 9, 8, 7, 3, 7, 7, 8, 7, ...  \n",
       "621  [2, 1, 1, 6, 8, 9, 9, 9, 7, 3, 0, 1, 3, 1, 2, ...  \n",
       "647  [0, 0, 4, 2, 3, 1, 6, 5, 7, 8, 7, 6, 5, 2, 3, ...  \n",
       "695  [2, 4, 0, 0, 5, 5, 8, 8, 9, 8, 8, 6, 6, 4, 3, ...  \n",
       "697  [5, 1, 6, 8, 4, 6, 4, 0, 2, 4, 6, 7, 7, 7, 9, ...  \n",
       "712  [5, 4, 4, 3, 6, 8, 8, 9, 9, 9, 9, 8, 5, 2, 5, ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "suburban-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=valid_data,             # evaluation dataset\n",
    "    data_collator = SpectroDataCollator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broken-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 44346\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1385' max='1385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1385/1385 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14979185163974762,\n",
       " 'eval_runtime': 123.3335,\n",
       " 'eval_samples_per_second': 359.562,\n",
       " 'eval_steps_per_second': 11.238,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "experimental-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1000 [00:01<00:24, 38.45it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c7b282a4afdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#tqdm(range(valid_data.len)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device),\n\u001b[0m\u001b[1;32m      8\u001b[0m                         \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"position_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno6/home/ahajek/Spektro/MassGenie/bart_spektro/modeling_bart_spektro.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, position_ids)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 )\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno6/home/ahajek/Spektro/MassGenie/bart_spektro/modeling_bart_spektro.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, position_ids)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         attention_mask = self._prepare_decoder_attention_mask(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         )\n",
      "\u001b[0;32m~/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36m_prepare_decoder_attention_mask\u001b[0;34m(self, attention_mask, input_shape, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mcombined_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             combined_attention_mask = _make_causal_mask(\n\u001b[0m\u001b[1;32m    891\u001b[0m                 \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             ).to(self.device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# own evaluation \n",
    "model.eval()\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1000)):#tqdm(range(valid_data.len)):\n",
    "        inputs = valid_data[i]\n",
    "        outputs = model(input_ids = inputs[\"input_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        position_ids = inputs[\"position_ids\"].unsqueeze(0).to(device=args.device),\n",
    "                        labels = inputs[\"labels\"].unsqueeze(0).to(device=args.device))\n",
    "        losses.append(outputs.loss.item())\n",
    "print(f\"my evaluation loss: {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-trout",
   "metadata": {},
   "source": [
    "### Debugging tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "personalized-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokenizer(t):\n",
    "    print(f\"tok to id: {t.tok_to_id.items()}\\n\")\n",
    "    print(f\"id to tok: {t.id_to_tok.items()}\\n\")\n",
    "    print(f\"tl to tok: {t.tl_to_tok.items()}\\n\")\n",
    "    print(f\"tok to tl: {t.tok_to_tl.items()}\\n\")\n",
    "\n",
    "    print(f\"unk_tok: {t.unk_tok}\")\n",
    "    print(f\"pad_tok: {t.pad_tok}\")\n",
    "    print(f\"eos_tok: {t.eos_tok}\")\n",
    "    print(f\"bos_tok: {t.bos_tok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-charter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "owned-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[502,\n",
       " 3,\n",
       " 224,\n",
       " 300,\n",
       " 20,\n",
       " 280,\n",
       " 11,\n",
       " 280,\n",
       " 21,\n",
       " 280,\n",
       " 32,\n",
       " 38,\n",
       " 11,\n",
       " 38,\n",
       " 22,\n",
       " 38,\n",
       " 21,\n",
       " 280,\n",
       " 22,\n",
       " 502]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(input_ids=inputs[\"input_ids\"].unsqueeze(0).to(device=args.device), \n",
    "               position_ids=inputs[\"position_ids\"].unsqueeze(0).to(device=args.device)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acoustic-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_smiles([501])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-camel",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "welcome-gabriel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainerState(epoch=29.857142857142858, global_step=90, max_steps=90, num_train_epochs=30, total_flos=5661560773017600.0, log_history=[{'loss': 6.4515, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.29, 'step': 1}, {'loss': 6.4546, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.57, 'step': 2}, {'loss': 6.4316, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.86, 'step': 3}, {'eval_loss': 6.329980373382568, 'eval_runtime': 0.2536, 'eval_samples_per_second': 232.646, 'eval_steps_per_second': 7.886, 'epoch': 0.86, 'step': 3}, {'loss': 9.5658, 'learning_rate': 4.0000000000000003e-07, 'epoch': 1.29, 'step': 4}, {'loss': 6.3142, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.57, 'step': 5}, {'loss': 6.2257, 'learning_rate': 6.000000000000001e-07, 'epoch': 1.86, 'step': 6}, {'eval_loss': 5.930425643920898, 'eval_runtime': 0.2661, 'eval_samples_per_second': 221.705, 'eval_steps_per_second': 7.515, 'epoch': 1.86, 'step': 6}, {'loss': 9.1558, 'learning_rate': 7.000000000000001e-07, 'epoch': 2.29, 'step': 7}, {'loss': 5.9743, 'learning_rate': 8.000000000000001e-07, 'epoch': 2.57, 'step': 8}, {'loss': 5.823, 'learning_rate': 9e-07, 'epoch': 2.86, 'step': 9}, {'eval_loss': 5.2774200439453125, 'eval_runtime': 0.2391, 'eval_samples_per_second': 246.717, 'eval_steps_per_second': 8.363, 'epoch': 2.86, 'step': 9}, {'loss': 8.4639, 'learning_rate': 1.0000000000000002e-06, 'epoch': 3.29, 'step': 10}, {'loss': 5.4665, 'learning_rate': 1.1e-06, 'epoch': 3.57, 'step': 11}, {'loss': 5.2781, 'learning_rate': 1.2000000000000002e-06, 'epoch': 3.86, 'step': 12}, {'eval_loss': 4.53634786605835, 'eval_runtime': 0.2435, 'eval_samples_per_second': 242.332, 'eval_steps_per_second': 8.215, 'epoch': 3.86, 'step': 12}, {'loss': 7.5895, 'learning_rate': 1.3e-06, 'epoch': 4.29, 'step': 13}, {'loss': 4.8939, 'learning_rate': 1.4000000000000001e-06, 'epoch': 4.57, 'step': 14}, {'loss': 4.6669, 'learning_rate': 1.5e-06, 'epoch': 4.86, 'step': 15}, {'eval_loss': 3.961162805557251, 'eval_runtime': 0.2958, 'eval_samples_per_second': 199.452, 'eval_steps_per_second': 6.761, 'epoch': 4.86, 'step': 15}, {'loss': 6.7529, 'learning_rate': 1.6000000000000001e-06, 'epoch': 5.29, 'step': 16}, {'loss': 4.3364, 'learning_rate': 1.7000000000000002e-06, 'epoch': 5.57, 'step': 17}, {'loss': 4.1884, 'learning_rate': 1.8e-06, 'epoch': 5.86, 'step': 18}, {'eval_loss': 3.616708517074585, 'eval_runtime': 0.25, 'eval_samples_per_second': 235.983, 'eval_steps_per_second': 7.999, 'epoch': 5.86, 'step': 18}, {'loss': 6.0664, 'learning_rate': 1.9e-06, 'epoch': 6.29, 'step': 19}, {'loss': 3.8853, 'learning_rate': 2.0000000000000003e-06, 'epoch': 6.57, 'step': 20}, {'loss': 3.8109, 'learning_rate': 2.1000000000000002e-06, 'epoch': 6.86, 'step': 21}, {'eval_loss': 3.299652099609375, 'eval_runtime': 0.3032, 'eval_samples_per_second': 194.599, 'eval_steps_per_second': 6.597, 'epoch': 6.86, 'step': 21}, {'loss': 5.484, 'learning_rate': 2.2e-06, 'epoch': 7.29, 'step': 22}, {'loss': 3.5659, 'learning_rate': 2.3e-06, 'epoch': 7.57, 'step': 23}, {'loss': 3.4758, 'learning_rate': 2.4000000000000003e-06, 'epoch': 7.86, 'step': 24}, {'eval_loss': 3.005798816680908, 'eval_runtime': 0.2724, 'eval_samples_per_second': 216.586, 'eval_steps_per_second': 7.342, 'epoch': 7.86, 'step': 24}, {'loss': 5.0837, 'learning_rate': 2.5e-06, 'epoch': 8.29, 'step': 25}, {'loss': 3.3377, 'learning_rate': 2.6e-06, 'epoch': 8.57, 'step': 26}, {'loss': 3.2231, 'learning_rate': 2.7e-06, 'epoch': 8.86, 'step': 27}, {'eval_loss': 2.810262441635132, 'eval_runtime': 0.2903, 'eval_samples_per_second': 203.206, 'eval_steps_per_second': 6.888, 'epoch': 8.86, 'step': 27}, {'loss': 4.7145, 'learning_rate': 2.8000000000000003e-06, 'epoch': 9.29, 'step': 28}, {'loss': 3.0928, 'learning_rate': 2.9e-06, 'epoch': 9.57, 'step': 29}, {'loss': 3.0327, 'learning_rate': 3e-06, 'epoch': 9.86, 'step': 30}, {'eval_loss': 2.683417558670044, 'eval_runtime': 0.2881, 'eval_samples_per_second': 204.773, 'eval_steps_per_second': 6.941, 'epoch': 9.86, 'step': 30}, {'loss': 4.4803, 'learning_rate': 3.1e-06, 'epoch': 10.29, 'step': 31}, {'loss': 2.9524, 'learning_rate': 3.2000000000000003e-06, 'epoch': 10.57, 'step': 32}, {'loss': 2.888, 'learning_rate': 3.3e-06, 'epoch': 10.86, 'step': 33}, {'eval_loss': 2.561307907104492, 'eval_runtime': 0.2883, 'eval_samples_per_second': 204.677, 'eval_steps_per_second': 6.938, 'epoch': 10.86, 'step': 33}, {'loss': 4.2413, 'learning_rate': 3.4000000000000005e-06, 'epoch': 11.29, 'step': 34}, {'loss': 2.8062, 'learning_rate': 3.5000000000000004e-06, 'epoch': 11.57, 'step': 35}, {'loss': 2.7716, 'learning_rate': 3.6e-06, 'epoch': 11.86, 'step': 36}, {'eval_loss': 2.464712619781494, 'eval_runtime': 0.2851, 'eval_samples_per_second': 206.947, 'eval_steps_per_second': 7.015, 'epoch': 11.86, 'step': 36}, {'loss': 4.1074, 'learning_rate': 3.7e-06, 'epoch': 12.29, 'step': 37}, {'loss': 2.6743, 'learning_rate': 3.8e-06, 'epoch': 12.57, 'step': 38}, {'loss': 2.6742, 'learning_rate': 3.9e-06, 'epoch': 12.86, 'step': 39}, {'eval_loss': 2.375380516052246, 'eval_runtime': 0.2419, 'eval_samples_per_second': 243.888, 'eval_steps_per_second': 8.267, 'epoch': 12.86, 'step': 39}, {'loss': 3.9589, 'learning_rate': 4.000000000000001e-06, 'epoch': 13.29, 'step': 40}, {'loss': 2.5737, 'learning_rate': 4.1000000000000006e-06, 'epoch': 13.57, 'step': 41}, {'loss': 2.5675, 'learning_rate': 4.2000000000000004e-06, 'epoch': 13.86, 'step': 42}, {'eval_loss': 2.2773149013519287, 'eval_runtime': 0.296, 'eval_samples_per_second': 199.327, 'eval_steps_per_second': 6.757, 'epoch': 13.86, 'step': 42}, {'loss': 3.831, 'learning_rate': 4.2999999999999995e-06, 'epoch': 14.29, 'step': 43}, {'loss': 2.496, 'learning_rate': 4.4e-06, 'epoch': 14.57, 'step': 44}, {'loss': 2.4552, 'learning_rate': 4.5e-06, 'epoch': 14.86, 'step': 45}, {'eval_loss': 2.1265153884887695, 'eval_runtime': 0.2692, 'eval_samples_per_second': 219.141, 'eval_steps_per_second': 7.428, 'epoch': 14.86, 'step': 45}, {'loss': 3.6315, 'learning_rate': 4.6e-06, 'epoch': 15.29, 'step': 46}, {'loss': 2.3879, 'learning_rate': 4.7e-06, 'epoch': 15.57, 'step': 47}, {'loss': 2.3218, 'learning_rate': 4.800000000000001e-06, 'epoch': 15.86, 'step': 48}, {'eval_loss': 1.96336030960083, 'eval_runtime': 0.2521, 'eval_samples_per_second': 233.991, 'eval_steps_per_second': 7.932, 'epoch': 15.86, 'step': 48}, {'loss': 3.4551, 'learning_rate': 4.9000000000000005e-06, 'epoch': 16.29, 'step': 49}, {'loss': 2.249, 'learning_rate': 5e-06, 'epoch': 16.57, 'step': 50}, {'loss': 2.1951, 'learning_rate': 5.1e-06, 'epoch': 16.86, 'step': 51}, {'eval_loss': 1.8629060983657837, 'eval_runtime': 0.2614, 'eval_samples_per_second': 225.68, 'eval_steps_per_second': 7.65, 'epoch': 16.86, 'step': 51}, {'loss': 3.2071, 'learning_rate': 5.2e-06, 'epoch': 17.29, 'step': 52}, {'loss': 2.0878, 'learning_rate': 5.3e-06, 'epoch': 17.57, 'step': 53}, {'loss': 2.1238, 'learning_rate': 5.4e-06, 'epoch': 17.86, 'step': 54}, {'eval_loss': 1.8144493103027344, 'eval_runtime': 0.2899, 'eval_samples_per_second': 203.492, 'eval_steps_per_second': 6.898, 'epoch': 17.86, 'step': 54}, {'loss': 3.0246, 'learning_rate': 5.500000000000001e-06, 'epoch': 18.29, 'step': 55}, {'loss': 2.0333, 'learning_rate': 5.600000000000001e-06, 'epoch': 18.57, 'step': 56}, {'loss': 1.9512, 'learning_rate': 5.7000000000000005e-06, 'epoch': 18.86, 'step': 57}, {'eval_loss': 1.7707387208938599, 'eval_runtime': 0.2656, 'eval_samples_per_second': 222.172, 'eval_steps_per_second': 7.531, 'epoch': 18.86, 'step': 57}, {'loss': 2.9419, 'learning_rate': 5.8e-06, 'epoch': 19.29, 'step': 58}, {'loss': 1.8946, 'learning_rate': 5.9e-06, 'epoch': 19.57, 'step': 59}, {'loss': 1.8892, 'learning_rate': 6e-06, 'epoch': 19.86, 'step': 60}, {'eval_loss': 1.7209945917129517, 'eval_runtime': 0.2427, 'eval_samples_per_second': 243.141, 'eval_steps_per_second': 8.242, 'epoch': 19.86, 'step': 60}, {'loss': 2.7795, 'learning_rate': 6.1e-06, 'epoch': 20.29, 'step': 61}, {'loss': 1.8301, 'learning_rate': 6.2e-06, 'epoch': 20.57, 'step': 62}, {'loss': 1.8512, 'learning_rate': 6.300000000000001e-06, 'epoch': 20.86, 'step': 63}, {'eval_loss': 1.67131769657135, 'eval_runtime': 0.2643, 'eval_samples_per_second': 223.268, 'eval_steps_per_second': 7.568, 'epoch': 20.86, 'step': 63}, {'loss': 2.623, 'learning_rate': 6.4000000000000006e-06, 'epoch': 21.29, 'step': 64}, {'loss': 1.7779, 'learning_rate': 6.5000000000000004e-06, 'epoch': 21.57, 'step': 65}, {'loss': 1.7676, 'learning_rate': 6.6e-06, 'epoch': 21.86, 'step': 66}, {'eval_loss': 1.6052824258804321, 'eval_runtime': 0.2705, 'eval_samples_per_second': 218.129, 'eval_steps_per_second': 7.394, 'epoch': 21.86, 'step': 66}, {'loss': 2.6045, 'learning_rate': 6.700000000000001e-06, 'epoch': 22.29, 'step': 67}, {'loss': 1.6783, 'learning_rate': 6.800000000000001e-06, 'epoch': 22.57, 'step': 68}, {'loss': 1.6879, 'learning_rate': 6.900000000000001e-06, 'epoch': 22.86, 'step': 69}, {'eval_loss': 1.5717790126800537, 'eval_runtime': 0.2637, 'eval_samples_per_second': 223.705, 'eval_steps_per_second': 7.583, 'epoch': 22.86, 'step': 69}, {'loss': 2.5362, 'learning_rate': 7.000000000000001e-06, 'epoch': 23.29, 'step': 70}, {'loss': 1.6538, 'learning_rate': 7.1e-06, 'epoch': 23.57, 'step': 71}, {'loss': 1.6346, 'learning_rate': 7.2e-06, 'epoch': 23.86, 'step': 72}, {'eval_loss': 1.5637421607971191, 'eval_runtime': 0.2435, 'eval_samples_per_second': 242.279, 'eval_steps_per_second': 8.213, 'epoch': 23.86, 'step': 72}, {'loss': 2.5067, 'learning_rate': 7.2999999999999996e-06, 'epoch': 24.29, 'step': 73}, {'loss': 1.6332, 'learning_rate': 7.4e-06, 'epoch': 24.57, 'step': 74}, {'loss': 1.6103, 'learning_rate': 7.5e-06, 'epoch': 24.86, 'step': 75}, {'eval_loss': 1.4998036623001099, 'eval_runtime': 0.2948, 'eval_samples_per_second': 200.142, 'eval_steps_per_second': 6.784, 'epoch': 24.86, 'step': 75}, {'loss': 2.412, 'learning_rate': 7.6e-06, 'epoch': 25.29, 'step': 76}, {'loss': 1.5844, 'learning_rate': 7.7e-06, 'epoch': 25.57, 'step': 77}, {'loss': 1.5753, 'learning_rate': 7.8e-06, 'epoch': 25.86, 'step': 78}, {'eval_loss': 1.489051342010498, 'eval_runtime': 0.26, 'eval_samples_per_second': 226.95, 'eval_steps_per_second': 7.693, 'epoch': 25.86, 'step': 78}, {'loss': 2.3716, 'learning_rate': 7.9e-06, 'epoch': 26.29, 'step': 79}, {'loss': 1.6029, 'learning_rate': 8.000000000000001e-06, 'epoch': 26.57, 'step': 80}, {'loss': 1.5624, 'learning_rate': 8.1e-06, 'epoch': 26.86, 'step': 81}, {'eval_loss': 1.486578345298767, 'eval_runtime': 0.2653, 'eval_samples_per_second': 222.386, 'eval_steps_per_second': 7.538, 'epoch': 26.86, 'step': 81}, {'loss': 2.3415, 'learning_rate': 8.200000000000001e-06, 'epoch': 27.29, 'step': 82}, {'loss': 1.5867, 'learning_rate': 8.3e-06, 'epoch': 27.57, 'step': 83}, {'loss': 1.5615, 'learning_rate': 8.400000000000001e-06, 'epoch': 27.86, 'step': 84}, {'eval_loss': 1.4669324159622192, 'eval_runtime': 0.2857, 'eval_samples_per_second': 206.505, 'eval_steps_per_second': 7.0, 'epoch': 27.86, 'step': 84}, {'loss': 2.2756, 'learning_rate': 8.500000000000002e-06, 'epoch': 28.29, 'step': 85}, {'loss': 1.5291, 'learning_rate': 8.599999999999999e-06, 'epoch': 28.57, 'step': 86}, {'loss': 1.5453, 'learning_rate': 8.7e-06, 'epoch': 28.86, 'step': 87}, {'eval_loss': 1.4421793222427368, 'eval_runtime': 0.2731, 'eval_samples_per_second': 216.026, 'eval_steps_per_second': 7.323, 'epoch': 28.86, 'step': 87}, {'loss': 2.2874, 'learning_rate': 8.8e-06, 'epoch': 29.29, 'step': 88}, {'loss': 1.493, 'learning_rate': 8.9e-06, 'epoch': 29.57, 'step': 89}, {'loss': 1.5066, 'learning_rate': 9e-06, 'epoch': 29.86, 'step': 90}, {'eval_loss': 1.4262853860855103, 'eval_runtime': 0.2694, 'eval_samples_per_second': 219.002, 'eval_steps_per_second': 7.424, 'epoch': 29.86, 'step': 90}, {'train_runtime': 537.5184, 'train_samples_per_second': 26.176, 'train_steps_per_second': 0.167, 'total_flos': 5661560773017600.0, 'train_loss': 3.3898678872320387, 'epoch': 29.86, 'step': 90}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "allied-intention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage-brno6/home/ahajek/Spektro/MassGenie\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-arkansas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "import transformers\n",
    "from bart_spektro.modeling_bart_spektro import BartSpektroForConditionalGeneration\n",
    "from bart_spektro.configuration_bart_spektro import BartSpektroConfig\n",
    "from dataset import SpectroDataCollator, SpectroDataset\n",
    "import torch\n",
    "import inspect\n",
    "from metrics import compute_cos_simils, SpectroMetrics\n",
    "from train_bart import build_tokenizer\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(tokenizer_path: str) -> transformers.PreTrainedTokenizerFast:\n",
    "    bpe_tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "\n",
    "    tokenizer = transformers.PreTrainedTokenizerFast(tokenizer_object=bpe_tokenizer,\n",
    "                                        bos_token=\"<bos>\",\n",
    "                                        eos_token=\"<eos>\",\n",
    "                                        unk_token=\"<ukn>\",\n",
    "                                        pad_token=\"<pad>\",\n",
    "                                        is_split_into_words=False)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"tokenizer/bbpe_tokenizer/bart_bbpe_1M_tokenizer.model\"\n",
    "bpe_tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "tokenizer = build_tokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 1234,\n",
       " 1233,\n",
       " 224,\n",
       " 327,\n",
       " 20,\n",
       " 266,\n",
       " 11,\n",
       " 38,\n",
       " 12,\n",
       " 70,\n",
       " 11,\n",
       " 266,\n",
       " 20,\n",
       " 286,\n",
       " 12,\n",
       " 364,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<bos><nist><neims> COc1cc(C)c(cc1OC)Cl<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Clc1ccc(c(c1)Cl)c1ccc(cc1)OC(=O)c1sccc1S(=O)(=O)N(C)C',\n",
       " ' Cc1cc2c(c(=S)[nH]1)C(=O)OC2=Cc1ccc(Cl)c(Cl)c1')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_smiles = \"<bos><nist> Clc1ccc(c(c1)Cl)c1ccc(cc1)OC(=O)c1sccc1S(=O)(=O)N(C)C<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\n",
    "gt_smiles = \"<nist> Cc1cc2c(c(=S)[nH]1)C(=O)OC2=Cc1ccc(Cl)c(Cl)c1<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\"\n",
    "\n",
    "pred_ids = tokenizer.encode(pred_smiles)\n",
    "gt_ids = tokenizer.encode(gt_smiles)\n",
    "pred_smiles, gt_smiles = tokenizer.decode(pred_ids, skip_special_tokens=True), tokenizer.decode(gt_ids, skip_special_tokens=True)\n",
    "pred_smiles, gt_smiles\n",
    "\n",
    "\n",
    "# pred_ids = torch.tensor(pred_ids).unsqueeze(0)\n",
    "# gt_ids = torch.tensor(gt_ids).unsqueeze(0)\n",
    "\n",
    "# pred_ids, gt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = [' CC1CCN(CC1N)Cc1ccns1)CC(C)C']\n",
    "pred_ids = [' CC1CCN(CC1N)Cc1ccns1)CC(C)C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:20:13] SMILES Parse Error: extra close parentheses while parsing: CC1CCN(CC1N)Cc1ccns1)CC(C)C\n",
      "[22:20:13] SMILES Parse Error: Failed parsing SMILES ' CC1CCN(CC1N)Cc1ccns1)CC(C)C' for input: ' CC1CCN(CC1N)Cc1ccns1)CC(C)C'\n",
      "[22:20:13] SMILES Parse Error: extra close parentheses while parsing: CC1CCN(CC1N)Cc1ccns1)CC(C)C\n",
      "[22:20:13] SMILES Parse Error: Failed parsing SMILES ' CC1CCN(CC1N)Cc1ccns1)CC(C)C' for input: ' CC1CCN(CC1N)Cc1ccns1)CC(C)C'\n",
      "ic| pred: ' CC1CCN(CC1N)Cc1ccns1)CC(C)C'\n",
      "    true: ' CC1CCN(CC1N)Cc1ccns1)CC(C)C'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = SpectroMetrics(tokenizer)\n",
    "prediction = transformers.EvalPrediction(predictions=pred_ids, label_ids=gt_ids)\n",
    "compute_cos_simils(label_ids, pred_ids)\n",
    "# metric(prediction, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:29:48] SMILES Parse Error: syntax error while parsing: <neims>\n",
      "[22:29:48] SMILES Parse Error: Failed parsing SMILES '<neims>' for input: '<neims>'\n",
      "ic| pred: ' Clc1ccc(c(c1)Cl)c1ccc(cc1)OC(=O)c1sccc1S(=O)(=O)N(C)C'\n",
      "    true: '<neims> Cc1cc2c(c(=S)[nH]1)C(=O)OC2=Cc1ccc(Cl)c(Cl)c1'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "simil1 = \" Clc1ccc(c(c1)Cl)c1ccc(cc1)OC(=O)c1sccc1S(=O)(=O)N(C)C\"\n",
    "simil2 = \"Cc1cc2c(c(=S)[nH]1)C(=O)OC2=Cc1ccc(Cl)c(Cl)c1\"\n",
    "a,b,c = compute_cos_simils([simil1], [simil2], tokenizer)\n",
    "display(b[0])\n",
    "display(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[39m=\u001b[39m BartSpektroConfig(vocab_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mget_vocab()), max_log_id\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m BartSpektroForConditionalGeneration(config)\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mcheckpoints/bart_2023-04-07-18_27_23_30Mneims/checkpoint-1670000/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gc-ms_bart/bart_spektro/modeling_bart_spektro.py:386\u001b[0m, in \u001b[0;36mBartSpektroForConditionalGeneration.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: BartSpektroConfig):\n\u001b[1;32m    385\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m BartSpektroModel(config)\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_buffer(\u001b[39m\"\u001b[39m\u001b[39mfinal_logits_bias\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings)))\n\u001b[1;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/gc-ms_bart/bart_spektro/modeling_bart_spektro.py:270\u001b[0m, in \u001b[0;36mBartSpektroModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(vocab_size, config\u001b[39m.\u001b[39md_model, padding_idx)\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m BartSpektroEncoder(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared)\n\u001b[0;32m--> 270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m BartDecoder(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshared)\n\u001b[1;32m    272\u001b[0m \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:911\u001b[0m, in \u001b[0;36mBartDecoder.__init__\u001b[0;34m(self, config, embed_tokens)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m embed_tokens\u001b[39m.\u001b[39mweight\n\u001b[1;32m    907\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions \u001b[39m=\u001b[39m BartLearnedPositionalEmbedding(\n\u001b[1;32m    908\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings,\n\u001b[1;32m    909\u001b[0m     config\u001b[39m.\u001b[39md_model,\n\u001b[1;32m    910\u001b[0m )\n\u001b[0;32m--> 911\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BartDecoderLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mdecoder_layers)])\n\u001b[1;32m    912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n\u001b[1;32m    914\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:911\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m embed_tokens\u001b[39m.\u001b[39mweight\n\u001b[1;32m    907\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions \u001b[39m=\u001b[39m BartLearnedPositionalEmbedding(\n\u001b[1;32m    908\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings,\n\u001b[1;32m    909\u001b[0m     config\u001b[39m.\u001b[39md_model,\n\u001b[1;32m    910\u001b[0m )\n\u001b[0;32m--> 911\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BartDecoderLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mdecoder_layers)])\n\u001b[1;32m    912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n\u001b[1;32m    914\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:388\u001b[0m, in \u001b[0;36mBartDecoderLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_attn_layer_norm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim)\n\u001b[1;32m    387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, config\u001b[39m.\u001b[39mdecoder_ffn_dim)\n\u001b[0;32m--> 388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(config\u001b[39m.\u001b[39;49mdecoder_ffn_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim)\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer_norm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim)\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/torch/nn/modules/linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/torch/nn/modules/linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[39m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     init\u001b[39m.\u001b[39;49mkaiming_uniform_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, a\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49msqrt(\u001b[39m5\u001b[39;49m))\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         fan_in, _ \u001b[39m=\u001b[39m init\u001b[39m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/torch/nn/init.py:412\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m bound \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m) \u001b[39m*\u001b[39m std  \u001b[39m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49muniform_(\u001b[39m-\u001b[39;49mbound, bound)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = BartSpektroConfig(vocab_size=len(tokenizer.get_vocab()), max_log_id=9)\n",
    "model = BartSpektroForConditionalGeneration(config)\n",
    "model.from_pretrained(\"checkpoints/bart_2023-04-07-18_27_23_30Mneims/checkpoint-1670000/\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpectroDataset(\"data/datasets/DEBUG/DEBUG_valid.jsonl\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=SpectroDataCollator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    preds = model.generate(input_ids=batch[\"input_ids\"],\n",
    "                           position_ids=batch[\"position_ids\"],\n",
    "                           attention_mask=batch[\"attention_mask\"],\n",
    "                           max_length=100,\n",
    "                           num_gen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>NCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCCOCOCCOCCOCOCCOCCOCOCCOCCOCOCCOCCOCOCCOCCOCOCCOCCOCOCCOCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCCNCCCOCC<pad>',\n",
       " '<pad>FCCOCCNC23232323232323232323\\x1aFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNCFCCOCCNC<pad>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_batch(preds.tolist(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>',\n",
       " '<eos>',\n",
       " '<source3>',\n",
       " '<pad>',\n",
       " '<trafo>',\n",
       " '<nist>',\n",
       " '<ukn>',\n",
       " '<source2>',\n",
       " '<',\n",
       " '<rassp>',\n",
       " '<source1>',\n",
       " '<neims>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x.startswith(\"<\"), list(tokenizer.get_vocab().keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens([\"<trafo>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer/bbpe_tokenizer/bart_bbpe_1M_tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/datasets/DEBUG/DEBUG_train.jsonl',\n",
       "  StreamWrapper<<_io.BufferedReader name='data/datasets/DEBUG/DEBUG_train.jsonl'>>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchdata.datapipes.iter import IterableWrapper, FileOpener, JsonParser\n",
    "import os\n",
    "\n",
    "json_files = [\"data/datasets/DEBUG/DEBUG_train.jsonl\"] \n",
    "datapipe1 = IterableWrapper(json_files)\n",
    "datapipe2 = FileOpener(datapipe1, mode=\"b\")\n",
    "\n",
    "list(datapipe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = IterableWrapper(range(10))\n",
    "list(dp)\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/datasets/DEBUG/DEBUG_train.jsonl',\n",
       "  StreamWrapper<<_io.BufferedReader name='data/datasets/DEBUG/DEBUG_train.jsonl'>>),\n",
       " ('data/datasets/DEBUG/DEBUG_valid.jsonl',\n",
       "  StreamWrapper<<_io.BufferedReader name='data/datasets/DEBUG/DEBUG_valid.jsonl'>>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(datapipe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAPIPES DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def generate_csv(file_label, num_rows: int = 5000, num_features: int = 20) -> None:\n",
    "    fieldnames = ['label'] + [f'c{i}' for i in range(num_features)]\n",
    "    writer = csv.DictWriter(open(f\"sample_data{file_label}.csv\", \"w\", newline=''), fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(num_rows):\n",
    "        row_data = {col: random.random() for col in fieldnames}\n",
    "        row_data['label'] = random.randint(0, 9)\n",
    "        writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchdata.datapipes as dp\n",
    "\n",
    "def filter_for_data(filename):\n",
    "    return \"sample_data\" in filename and filename.endswith(\".csv\")\n",
    "\n",
    "def row_processor(row):\n",
    "    return {\"label\": np.array(row[0], np.int32), \"data\": np.array(row[1:], dtype=np.float64)}\n",
    "\n",
    "def build_datapipes(root_dir=\".\"):\n",
    "    datapipe = dp.iter.FileLister(root_dir)\n",
    "    datapipe = datapipe.filter(filter_fn=filter_for_data)\n",
    "    datapipe = datapipe.open_files(mode='rt')\n",
    "    datapipe = datapipe.parse_csv(delimiter=\",\", skip_lines=1)\n",
    "    # Shuffle will happen as long as you do NOT set `shuffle=False` later in the DataLoader\n",
    "    datapipe = datapipe.shuffle()\n",
    "    datapipe = datapipe.sharding_filter()  # !!! AFTER SHUFFLE, BEFORE EXPENSIVE OPERATIONS !!!\n",
    "    datapipe = datapipe.map(row_processor)\n",
    "    return datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels batch shape: torch.Size([5])\n",
      "Feature batch shape: torch.Size([5, 3])\n",
      "labels = tensor([2, 3, 9, 7, 8], dtype=torch.int32)\n",
      "features = tensor([[0.4408, 0.9905, 0.0471],\n",
      "        [0.5507, 0.3512, 0.5192],\n",
      "        [0.9291, 0.2817, 0.8013],\n",
      "        [0.2765, 0.6562, 0.9340],\n",
      "        [0.6604, 0.9201, 0.0606]], dtype=torch.float64)\n",
      "n_sample = 6\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_files_to_generate = 3\n",
    "    for i in range(num_files_to_generate):\n",
    "        generate_csv(file_label=i, num_rows=10, num_features=3)\n",
    "    datapipe = build_datapipes()\n",
    "    dl = DataLoader(dataset=datapipe, batch_size=5, num_workers=2)\n",
    "    first = next(iter(dl))\n",
    "    labels, features = first['label'], first['data']\n",
    "    print(f\"Labels batch shape: {labels.size()}\")\n",
    "    print(f\"Feature batch shape: {features.size()}\")\n",
    "    print(f\"{labels = }\\n{features = }\")\n",
    "    n_sample = 0\n",
    "    for row in iter(dl):\n",
    "        n_sample += 1\n",
    "    print(f\"{n_sample = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My DATAPIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SpectroDataCollator, SpectroDataset, load_all_datapipes\n",
    "import yaml\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': SampleMultiplexerDataPipe,\n",
       " 'valid': {'debug1': MapperIterDataPipe, 'debug2': MapperIterDataPipe},\n",
       " 'example': {'debug1': MapperIterDataPipe, 'debug2': MapperIterDataPipe}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY IT OUT\n",
    "with open(\"configs/train_config.yaml\", \"r\") as f:\n",
    "    try:\n",
    "        config = yaml.safe_load(f)\n",
    "    except yaml.YAMLError as exc:\n",
    "        raise ValueError(\"Error in configuration file:\", exc) from exc\n",
    "\n",
    "collate_fn = SpectroDataCollator()\n",
    "datapipes = load_all_datapipes(config[\"data_args\"])\n",
    "datapipes\n",
    "\n",
    "# dl = DataLoader(dataset=datapipe, batch_size=1, num_workers=1, collate_fn=collate_fn)\n",
    "# first = next(iter(dl))\n",
    "# n_sample = 0\n",
    "# for row in iter(dl):\n",
    "#     print(row)\n",
    "#     n_sample += 1\n",
    "#     if n_sample == 20:\n",
    "#         break\n",
    "# print(f\"{n_sample = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/datasets/DEBUG/DEBUG_valid.jsonl', '{\"smiles\":\"CCNC(c1cnn2c1OCCC2)CC=C=C\",\"input_ids\":[26,27,28,30,38,39,40,41,42,43,44,45,46,50,51,52,53,54,55,56,58,59,60,63,64,65,66,67,68,69,70,72,75,77,78,79,80,81,82,83,87,89,90,91,92,93,94,95,104,105,106,107,108,109,110,116,117,118,119,120,121,122,129,131,132,133,136,145,146,147,148,149,150,159,160,161,162,163,164,165,166,173,174,175,176,177,188,189,190,200,204,205,206,218,219,232,233,234,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2],\"labels\":[1233,224,283,11,70,20,284,21,70,20,378,21,12,261,32,38,32,38,0,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100],\"decoder_attention_mask\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"attention_mask\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"position_ids\":[3,6,5,5,5,9,8,9,9,7,9,8,6,3,7,7,9,8,8,8,8,7,6,6,7,8,8,9,8,1,7,8,5,7,7,7,7,7,8,6,2,5,3,5,5,6,4,5,6,8,9,8,7,5,0,7,7,7,6,6,6,1,6,8,8,8,1,6,6,8,8,7,6,6,7,8,7,4,6,5,6,4,8,6,6,0,9,9,7,6,8,7,3,9,7,4,9,7,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1]}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(iter(datapipes[\"example\"][\"debug2\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m SequentialSampler\n\u001b[0;32m----> 4\u001b[0m pipe \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39miter\u001b[39m.\u001b[39mSampler(datapipe)\n\u001b[1;32m      5\u001b[0m \u001b[39m# len(list(iter(pipe)))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datapipe' is not defined"
     ]
    }
   ],
   "source": [
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "pipe = dp.iter.Sampler(datapipe)\n",
    "# len(list(iter(pipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_all_datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args ={\n",
    "    \"buffer_size\": 1000, # for shuffling in dataloader\n",
    "    \"datasets\": \n",
    "        {\"30M_rassp\": \n",
    "            {\"train_path\": \"data/datasets/30M_rassp/30M_rassp_train.jsonl\",\n",
    "            \"valid_path\": \"data/datasets/30M_rassp/30M_rassp_valid.jsonl\",\n",
    "            \"weight\": 1.0,\n",
    "            \"limit_val_split\": 1000,\n",
    "            \"limit_example_split\": 100},\n",
    "        \"nist\":\n",
    "            {\"train_path\": \"data/datasets/NIST/NIST_split_filip/train_<nist>.jsonl\",\n",
    "            \"valid_path\": \"data/datasets/NIST/NIST_split_filip/valid_<nist>.jsonl\",\n",
    "            \"weight\": 1.0,\n",
    "            \"limit_val_split\": 1000,\n",
    "            \"limit_example_split\": 100}\n",
    "        }\n",
    "}\n",
    "\n",
    "datapipes = load_all_datapipes(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[17, 18, 26,  ...,  2,  2,  2],\n",
      "        [30, 33, 34,  ...,  2,  2,  2],\n",
      "        [28, 33, 34,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [25, 26, 27,  ...,  2,  2,  2],\n",
      "        [37, 38, 39,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 3,  4,  4,  ..., -1, -1, -1],\n",
      "        [ 4,  2,  2,  ..., -1, -1, -1],\n",
      "        [ 2,  2,  3,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 0,  2,  6,  ..., -1, -1, -1],\n",
      "        [ 0,  5,  8,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  3,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,  495,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,   38,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  299,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[26, 27, 28,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2],\n",
      "        [38, 39, 40,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [30, 33, 39,  ...,  2,  2,  2],\n",
      "        [14, 15, 17,  ...,  2,  2,  2],\n",
      "        [28, 29, 30,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 5,  8,  7,  ..., -1, -1, -1],\n",
      "        [ 3,  1,  5,  ..., -1, -1, -1],\n",
      "        [ 1,  8,  7,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  1,  8,  ..., -1, -1, -1],\n",
      "        [ 0,  4,  2,  ..., -1, -1, -1],\n",
      "        [ 3,  2,  6,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  469,  ..., -100, -100, -100],\n",
      "        [1233,  224,  276,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  285,  ..., -100, -100, -100],\n",
      "        [1233,  224,  286,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[33, 34, 39,  ...,  2,  2,  2],\n",
      "        [17, 27, 28,  ...,  2,  2,  2],\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        [16, 17, 18,  ...,  2,  2,  2],\n",
      "        [27, 29, 33,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 3,  1,  7,  ..., -1, -1, -1],\n",
      "        [ 2,  4,  4,  ..., -1, -1, -1],\n",
      "        [ 0,  3,  6,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 7,  1,  8,  ..., -1, -1, -1],\n",
      "        [ 0,  2,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  2,  4,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  404,  ..., -100, -100, -100],\n",
      "        [1233,  224,  327,  ..., -100, -100, -100],\n",
      "        [1233,  224,  292,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  286,  ..., -100, -100, -100],\n",
      "        [1233,  224,  378,  ..., -100, -100, -100],\n",
      "        [1233,  224,  469,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[15, 26, 28,  ...,  2,  2,  2],\n",
      "        [14, 15, 16,  ...,  2,  2,  2],\n",
      "        [26, 27, 28,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [26, 27, 28,  ...,  2,  2,  2],\n",
      "        [34, 39, 40,  ...,  2,  2,  2],\n",
      "        [27, 29, 30,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 4,  0,  3,  ..., -1, -1, -1],\n",
      "        [ 2,  5,  1,  ..., -1, -1, -1],\n",
      "        [ 2,  5,  4,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 4,  7,  6,  ..., -1, -1, -1],\n",
      "        [ 1,  6,  5,  ..., -1, -1, -1],\n",
      "        [ 1,  0,  0,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  286,  ..., -100, -100, -100],\n",
      "        [1233,  224,  404,  ..., -100, -100, -100],\n",
      "        [1233,  224,  306,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[15, 28, 30,  ...,  2,  2,  2],\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        [30, 33, 36,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [27, 30, 33,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  4,  4,  ..., -1, -1, -1],\n",
      "        [ 1,  2,  6,  ..., -1, -1, -1],\n",
      "        [ 3,  2,  3,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 2,  3,  0,  ..., -1, -1, -1],\n",
      "        [ 6,  5,  9,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  6,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,   38,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  495,  ..., -100, -100, -100],\n",
      "        [1233,  224,  276,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[14, 15, 16,  ...,  2,  2,  2],\n",
      "        [16, 17, 18,  ...,  2,  2,  2],\n",
      "        [26, 27, 29,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [28, 29, 30,  ...,  2,  2,  2],\n",
      "        [28, 33, 37,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  5,  3,  ..., -1, -1, -1],\n",
      "        [ 0,  2,  2,  ..., -1, -1, -1],\n",
      "        [ 0,  0,  4,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 5,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 6,  4,  5,  ..., -1, -1, -1],\n",
      "        [ 7,  5,  9,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  281,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,   50,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[33, 34, 39,  ...,  2,  2,  2],\n",
      "        [28, 29, 30,  ...,  2,  2,  2],\n",
      "        [33, 38, 39,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [15, 17, 18,  ...,  2,  2,  2],\n",
      "        [15, 16, 26,  ...,  2,  2,  2],\n",
      "        [15, 17, 18,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  0,  8,  ..., -1, -1, -1],\n",
      "        [ 2,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 0,  3,  8,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  1,  3,  ..., -1, -1, -1],\n",
      "        [ 3,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 3,  1,  2,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  538,  ..., -100, -100, -100],\n",
      "        [1233,  224,  303,  ..., -100, -100, -100],\n",
      "        [1233,  224,  404,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  471,  ..., -100, -100, -100],\n",
      "        [1233,  224,  327,  ..., -100, -100, -100],\n",
      "        [1233,  224,  407,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[27, 29, 30,  ...,  2,  2,  2],\n",
      "        [33, 34, 37,  ...,  2,  2,  2],\n",
      "        [30, 32, 33,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [29, 32, 33,  ...,  2,  2,  2],\n",
      "        [15, 16, 17,  ...,  2,  2,  2],\n",
      "        [33, 34, 36,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 3,  5,  3,  ..., -1, -1, -1],\n",
      "        [ 5,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 4,  2,  3,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 2,  1,  0,  ..., -1, -1, -1],\n",
      "        [ 1,  2,  3,  ..., -1, -1, -1],\n",
      "        [ 5,  3,  2,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  281,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  404,  ..., -100, -100, -100],\n",
      "        [1233,  224,  281,  ..., -100, -100, -100],\n",
      "        [1233,  224,  285,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[26, 27, 28,  ...,  2,  2,  2],\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [14, 15, 16,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2],\n",
      "        [27, 29, 30,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 4,  7,  6,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  4,  ..., -1, -1, -1],\n",
      "        [ 4,  2,  7,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 5,  6,  3,  ..., -1, -1, -1],\n",
      "        [ 0,  4,  6,  ..., -1, -1, -1],\n",
      "        [ 2,  5,  8,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  275,  ..., -100, -100, -100],\n",
      "        [1233,  224,   38,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  297,  ..., -100, -100, -100],\n",
      "        [1233,  224,  263,  ..., -100, -100, -100],\n",
      "        [1233,  224,  281,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[28, 33, 34,  ...,  2,  2,  2],\n",
      "        [33, 34, 35,  ...,  2,  2,  2],\n",
      "        [26, 27, 28,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        [33, 34, 37,  ...,  2,  2,  2],\n",
      "        [29, 30, 33,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 3,  2,  3,  ..., -1, -1, -1],\n",
      "        [ 3,  5,  4,  ..., -1, -1, -1],\n",
      "        [ 4,  7,  5,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 3,  0,  4,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  3,  ..., -1, -1, -1],\n",
      "        [ 5,  6,  0,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  276,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  295,  ..., -100, -100, -100],\n",
      "        [1233,  224,   50,  ..., -100, -100, -100],\n",
      "        [1233,  224,  275,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[14, 16, 17,  ...,  2,  2,  2],\n",
      "        [33, 34, 35,  ...,  2,  2,  2],\n",
      "        [15, 17, 18,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [28, 29, 30,  ...,  2,  2,  2],\n",
      "        [30, 33, 34,  ...,  2,  2,  2],\n",
      "        [19, 26, 27,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 2,  1,  0,  ..., -1, -1, -1],\n",
      "        [ 2,  1,  2,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  2,  6,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  0,  ..., -1, -1, -1],\n",
      "        [ 0,  1,  6,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  364,  ..., -100, -100, -100],\n",
      "        [1233,  224,  285,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  285,  ..., -100, -100, -100],\n",
      "        [1233,  224,  265,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[33, 34, 37,  ...,  2,  2,  2],\n",
      "        [29, 33, 34,  ...,  2,  2,  2],\n",
      "        [28, 30, 33,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [27, 29, 33,  ...,  2,  2,  2],\n",
      "        [15, 16, 17,  ...,  2,  2,  2],\n",
      "        [33, 39, 40,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 3,  2,  0,  ..., -1, -1, -1],\n",
      "        [ 5,  2,  0,  ..., -1, -1, -1],\n",
      "        [ 3,  7,  4,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 3,  3,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  0,  2,  ..., -1, -1, -1],\n",
      "        [ 5,  8,  7,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  469,  ..., -100, -100, -100],\n",
      "        [1233,  224,  283,  ..., -100, -100, -100],\n",
      "        [1233,  224,  478,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  278,  ..., -100, -100, -100],\n",
      "        [1233,  224,  295,  ..., -100, -100, -100],\n",
      "        [1233,  224,  445,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[ 26,  27,  28,  ...,   2,   2,   2],\n",
      "        [ 15,  29,  30,  ...,   2,   2,   2],\n",
      "        [ 27,  28,  36,  ...,   2,   2,   2],\n",
      "        ...,\n",
      "        [ 27,  29,  30,  ...,   2,   2,   2],\n",
      "        [ 33,  36,  38,  ..., 297, 298,   2],\n",
      "        [ 26,  27,  28,  ...,   2,   2,   2]]), 'position_ids': tensor([[ 2,  4,  2,  ..., -1, -1, -1],\n",
      "        [ 0,  4,  4,  ..., -1, -1, -1],\n",
      "        [ 5,  6,  1,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 2,  1,  7,  ..., -1, -1, -1],\n",
      "        [ 3,  2,  4,  ...,  6,  2, -1],\n",
      "        [ 3,  7,  2,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  286,  ..., -100, -100, -100],\n",
      "        [1233,  224,  263,  ..., -100, -100, -100],\n",
      "        [1233,  224,  279,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  295,  ..., -100, -100, -100],\n",
      "        [1233,  224,   41,  ..., -100, -100, -100],\n",
      "        [1233,  224,   50,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[39, 40, 41,  ...,  2,  2,  2],\n",
      "        [33, 34, 37,  ...,  2,  2,  2],\n",
      "        [18, 26, 27,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [15, 16, 17,  ...,  2,  2,  2],\n",
      "        [19, 26, 27,  ...,  2,  2,  2],\n",
      "        [14, 15, 26,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 6,  4,  9,  ..., -1, -1, -1],\n",
      "        [ 2,  1,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  6,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 2,  0,  1,  ..., -1, -1, -1],\n",
      "        [ 2,  3,  6,  ..., -1, -1, -1],\n",
      "        [ 0,  2,  1,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  263,  ..., -100, -100, -100],\n",
      "        [1233,  224,   70,  ..., -100, -100, -100],\n",
      "        [1233,  224,  327,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  495,  ..., -100, -100, -100],\n",
      "        [1233,  224,  286,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[28, 29, 30,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        [33, 36, 37,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        [17, 18, 26,  ...,  2,  2,  2],\n",
      "        [14, 15, 26,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  5,  7,  ..., -1, -1, -1],\n",
      "        [ 6,  5,  8,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  3,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  3,  6,  ..., -1, -1, -1],\n",
      "        [ 2,  0,  3,  ..., -1, -1, -1],\n",
      "        [ 0,  4,  5,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  400,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  327,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,  297,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[16, 17, 18,  ...,  2,  2,  2],\n",
      "        [27, 29, 31,  ...,  2,  2,  2],\n",
      "        [28, 31, 33,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [33, 34, 38,  ...,  2,  2,  2],\n",
      "        [33, 36, 37,  ...,  2,  2,  2],\n",
      "        [15, 19, 26,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 0,  3,  3,  ..., -1, -1, -1],\n",
      "        [ 0,  3,  5,  ..., -1, -1, -1],\n",
      "        [ 1,  3,  5,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 4,  2,  3,  ..., -1, -1, -1],\n",
      "        [ 1,  5,  1,  ..., -1, -1, -1],\n",
      "        [ 1,  1,  2,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  438,  ..., -100, -100, -100],\n",
      "        [1233,  224,  295,  ..., -100, -100, -100],\n",
      "        [1233,  224,  495,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  327,  ..., -100, -100, -100],\n",
      "        [1233,  224,  364,  ..., -100, -100, -100],\n",
      "        [1233,  224,  407,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[39, 40, 41,  ...,  2,  2,  2],\n",
      "        [15, 26, 28,  ...,  2,  2,  2],\n",
      "        [15, 26, 27,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [33, 34, 36,  ...,  2,  2,  2],\n",
      "        [33, 34, 35,  ...,  2,  2,  2],\n",
      "        [14, 15, 17,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 7,  6,  8,  ..., -1, -1, -1],\n",
      "        [ 0,  1,  3,  ..., -1, -1, -1],\n",
      "        [ 3,  1,  3,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 1,  0,  5,  ..., -1, -1, -1],\n",
      "        [ 3,  3,  6,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  3,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,   50,  ..., -100, -100, -100],\n",
      "        [1233,  224,  263,  ..., -100, -100, -100],\n",
      "        [1233,  224,  495,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  279,  ..., -100, -100, -100],\n",
      "        [1233,  224,  498,  ..., -100, -100, -100],\n",
      "        [1233,  224,  356,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[15, 17, 18,  ...,  2,  2,  2],\n",
      "        [27, 28, 38,  ...,  2,  2,  2],\n",
      "        [31, 33, 39,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [26, 27, 28,  ...,  2,  2,  2],\n",
      "        [14, 15, 26,  ...,  2,  2,  2],\n",
      "        [16, 17, 18,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 1,  2,  3,  ..., -1, -1, -1],\n",
      "        [ 3,  3,  1,  ..., -1, -1, -1],\n",
      "        [ 4,  3,  7,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 3,  6,  4,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  3,  ..., -1, -1, -1],\n",
      "        [ 0,  4,  4,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,   49,  ..., -100, -100, -100],\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,  306,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,   38,  ..., -100, -100, -100],\n",
      "        [1233,  224,  453,  ..., -100, -100, -100],\n",
      "        [1233,  224,  295,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[33, 34, 38,  ...,  2,  2,  2],\n",
      "        [28, 29, 30,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2],\n",
      "        [26, 27, 28,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 4,  0,  2,  ..., -1, -1, -1],\n",
      "        [ 5,  4,  6,  ..., -1, -1, -1],\n",
      "        [ 6,  2,  7,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 7,  1,  7,  ..., -1, -1, -1],\n",
      "        [ 1,  4,  1,  ..., -1, -1, -1],\n",
      "        [ 4,  7,  5,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,   50,  ..., -100, -100, -100],\n",
      "        [1233,  224,  265,  ..., -100, -100, -100],\n",
      "        [1233,  224,   50,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  285,  ..., -100, -100, -100],\n",
      "        [1233,  224,  278,  ..., -100, -100, -100],\n",
      "        [1233,  224,   50,  ..., -100, -100, -100]])}\n",
      "{'input_ids': tensor([[15, 26, 27,  ...,  2,  2,  2],\n",
      "        [26, 27, 28,  ...,  2,  2,  2],\n",
      "        [27, 28, 29,  ...,  2,  2,  2],\n",
      "        ...,\n",
      "        [33, 36, 37,  ...,  2,  2,  2],\n",
      "        [39, 40, 41,  ...,  2,  2,  2],\n",
      "        [15, 27, 28,  ...,  2,  2,  2]]), 'position_ids': tensor([[ 4,  5,  8,  ..., -1, -1, -1],\n",
      "        [ 0,  3,  4,  ..., -1, -1, -1],\n",
      "        [ 6,  4,  6,  ..., -1, -1, -1],\n",
      "        ...,\n",
      "        [ 3,  2,  1,  ..., -1, -1, -1],\n",
      "        [ 7,  5,  9,  ..., -1, -1, -1],\n",
      "        [ 3,  6,  6,  ..., -1, -1, -1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1233,  224,  330,  ..., -100, -100, -100],\n",
      "        [1233,  224,  263,  ..., -100, -100, -100],\n",
      "        [1233,  224,  452,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [1233,  224,  261,  ..., -100, -100, -100],\n",
      "        [1233,  224,   38,  ..., -100, -100, -100],\n",
      "        [1233,  224,  276,  ..., -100, -100, -100]])}\n",
      "n_sample = 20\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=datapipes[\"valid\"][\"30M_rassp\"], batch_size=8, num_workers=1, collate_fn=collate_fn)\n",
    "first = next(iter(dl))\n",
    "n_sample = 0\n",
    "for row in iter(dl):\n",
    "    print(row)\n",
    "    n_sample += 1\n",
    "    if n_sample == 20:\n",
    "        break\n",
    "print(f\"{n_sample = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapipes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datapipes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datapipes' is not defined"
     ]
    }
   ],
   "source": [
    "datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[39m.\u001b[39mpad_token_id\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = range(10)[None:4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAh7ElEQVR4nO3deVwT5/Y/8AMEQSoKuIuiFU1EUNzrhhsueCvuC4i7uIvs7oq4Vm19WbdrtV59eRXB6lXRe9WqFW3dF2pFAlFUUBBQAgQhhEDm98fcb35ea1uSeZJnZnLef/IyZ85L/fBM5sw8Y8UwDCCE6LGm3QBClg5DiBBlGEKEKMMQIkQZhhAhyjCECFGGIUSIMgwhQpRhCBGiDEOIEGUYQoQowxAiRBmGECHKMIQIUYYhRIgyDCFClGEIEaIMQ4gQZRhChCjDECJEGYYQIcowhAhRhiFEiDIMIUKUYQgRogxDiBBlGEKEKMMQIkQZhhAhyiS0G6BArVZnZWV99ENbW1sHBwcq/VimsrIyrVb70Q/d3Nxq1qxJpR+aGAuTlJTk4uJC+28dfZqLi0tSUhLt/yPmZsVY2PsJXV1dc3JyrKysrKysPvy5nZ1d7dq1aXVlgVQqlUaj+fAn7P/IJk2aZGdn0+qKCss6Hf3mm2/YBD548KBjx46020H/IyUlpX379jk5OZs2bVq2bBntdszHglbCioqKOnXqlJeXDxky5MKFC7TbQZ8wZMiQH3/80c7OrqioyN7ennY7ZmJBV0cnT55cXl5ua2sbHx9Puxf0aSdPnrS1tdVoNNOmTaPdi/lYSghfvHhx4sQJAIiIiHBycqLdDvq0WrVqhYWFAcDx48efPn1Kux0zsZTT0aCgoLi4OGdnZ6VSSbsX9Bfq1q2rVCqDgoKOHDlCuxdzsIiVUC6X//DDDzY2NidPnqTdC/prp0+flkgkCQkJKSkptHsxB4sIYUREhFarnTNnTv/+/Wn3gv6aj4/PrFmzKisr2VNT0RP/6WhiYuKIESOcnZ0VCkW9evVot4OqRalUSqXSgoKCxMREf39/2u2YlshXwoqKiujoaABYs2YNJlBAXFxcVq1aBQDh4eEfzfTFR+Qh3L59u0Kh8PDwmDdvHu1ekGEWLFjg5eWVkZGxY8cO2r2YlphPR/Pz86VSaXFx8fnz5/38/Gi3gwx25cqVgQMHOjo6pqenN27cmHY7piLmlXD58uXFxcX+/v6YQIHy9fUdNmxYSUnJ6tWrafdiQqJdCZOTk7t06SKRSB4/fiyVSmm3g4yUkZHh6emp1Wpv377dtWtX2u2YhGhXwrCwMJ1OFxoaigkUNHd395CQEJ1OFxYWJtYFQ5wr4bFjxyZOnNigQQOFQlGnTh3a7SBOSkpKZDLZmzdvjh07FhAQQLsd8kS4EqrVavZBmI0bN2ICRcDR0XHt2rUAEB0dXVpaSrsd8kQYws2bN2dmZnbs2HH69Om0e0FkzJgxo0uXLq9fv/76669p90Ke2E5HX79+3aZNm9LS0mvXrvXp04d2O4iYmzdv9u7d297eXi6XN2/enHY7JIkthIGBgfHx8QEBAceOHeNS55dfftm7dy+prhAAzJ07t3fv3lwqBAQEJCQkBAYGxsXFkeqKF2hsbGMqN27csLKyqlmz5suXLzmWOnToEO1/GbE5dOgQx3+UV69effbZZwBw7do1jqV4RTwroU6n6969+71792JiYtasWcOx2vPnz2/evEmiL/RfPXv2bNmyJccia9asiY2N7dix4/37962tRXJFQzwhPHDgQHBwcNOmTdPS0tjfl0h81Gq1h4dHZmbmgQMHZsyYQbsdMkQSQv0oKS4uLjAwkHY7yITi4uKCgoLENAQWyYK+bt26N2/e9OjRQ5TDXPShwMBAHx+f/Pz8jRs30u6FDDGshJZweyH6kMhuDBbDShgREcFukocJtBAdO3acOnVqRUXF4sWLafdCgOBXQgt55Ax9JC8vTyaTFRcXX7hwYciQIbTb4UTYK2FlZWV4eDgArFy5EhNoURo2bMjeIRweHv77tzsJi7BDuGfPnsePH7u7u4eGhtLuBZlbeHi4VCqVy+VCv7dJwKejhYWFrVu3LigoOHPmzPDhw2m3gyg4c+bMyJEjhb6VnoBXwlWrVhUUFAwYMAATaLFGjBgxZMiQwsLC2NhY2r0YT6grYWpqqre3N8MwycnJ7dq1o90OoiY1NbVDhw46nU64/xOEuhKGh4dXVlbOnz9foH/viJS2bdvOmTOnqqpKuNt1C3IlPHXq1OjRo52dnZ8+fVq3bl3a7SDKCgsLpVLpu3fvTp06NXLkSNrtGEx4K2FFRcWSJUsAYN26dZhABADOzs4xMTEAEBkZKcTtuoUXwm3btj19+pQ9CaHdC+KLefPmtWvX7vnz59u3b6fdi8EEdjqal5cnlUpVKpUI7pNAZP3000++vr5CvHdKYCvh0qVLVSrVyJEjMYHoIwMGDBgxYkRJScmKFSto92IYIa2EDx8+7Nq1q0QiSUlJad26Ne12EO88f/68bdu2Wq321q1b3bp1o91OdQlmJWQYJjQ0VKfTRUREYALRJ7Vs2ZLdeV1Y23ULZiU8evTopEmTGjZsqFAoateuTbsdxFP6PRaOHj06ceJE2u1UizBWQrVavXz5cgDYtGkTJhD9CUdHx/Xr1wPA4sWLhbJdtzBCuGnTpqysrE6dOk2dOpV2L4jvpk2b1q1bt+zs7C1bttDupVoEcDr66tWrNm3aqNXqa9eu+fj40G4HCcCtW7d69eplb2+fmpraokUL2u38BQGshJGRkWVlZRMnTsQEomrq0aNHYGCgWq1mb67iOb6vhDdu3PDx8bG3t09LS3Nzc6PdDhKM7OxsmUxWWlqalJTUt29f2u38GV6vhPprzUuXLsUEIoO4urpGR0cDQFhYWFVVFe12/gyvV8J9+/bNmTOnWbNmaWlpDg4OtNtBAqNWq9u2bfvy5ct9+/bNmjWLdjt/iL8hVKlUMpksNzc3ISFh/PjxtNtBgpSQkBAQENCgQYP09HQnJyfa7Xwaf09HY2Njc3Nze/XqNW7cONq9IKGaMGFC37598/Pz2eEhP/F0JXz27JmXl5dWq71z506XLl1ot4ME7Ndff+3SpYuNjc1vv/0mk8lot/MJPF0Jw8LCNBrNzJkzMYGIow4dOkyfPr2ioiIqKop2L5/Gx5Xw8uXLgwYNcnR0VCgUjRo1ot0OErz8/HypVFpcXPyf//xn6NChtNv5GO9WwsrKSnbHnpiYGEwgIqJBgwYrV64EgIiICB5u1827EO7atevJkyetWrVauHAh7V6QeCxatEgmk6Wlpe3Zs4d2Lx/j1+moUqmUSqUFBQXnzp378ssvabeDROXcuXP+/v483K6bXyvhihUrCgoKBg4ciAlExA0bNszPz6+wsHD16tW0e/kfPFoJnzx50qFDBwBITk728vKi3Q4SIblc7u3trdPpHjx44O3tTbud/+LRSshuqr1w4UJMIDIRDw+P+fPnV1VVsW/U4wm+rIQnT54cO3asi4uLQqHALX2R6ei36z558uTo0aNptwPAk5VQo9EsXboUADZs2IAJRCbl7Oy8du1aAIiKiiovL6fdDgBPQvj1118/e/bM09MzODiYdi9I/GbPnt2+ffsXL15s27aNdi8AfDgdzc3NlclkKpXqxx9/HDRoEN1mkIW4evXqgAEDatWqlZ6e3qRJE7rN0F8JFy9erFKpxowZgwlEZtO/f//Ro0e/f/+effE9XZRXwgcPHnTr1s3W1jYlJaVVq1YUO0GW5sWLF23bttVoNLdu3friiy8odkJzJWQYZsGCBTqdLjIyEhOIzOzzzz8PDw/X/yek2AnNlfDw4cNTp07FTbURLe/fv5fJZDk5OYcPH548eTKtNqithPrT8S1btmACERW1atXauHEj/N+FCVptUAvhpk2bcnJyOnfuPGnSJFo9IDRlypQvvvgiNzeX4nbddE5H9d+Jr1+/3rt3b/M3gJDe7du3e/bsWaNGDVpXB+mshNHR0eXl5ZMmTcIEIuq6d+8eFBSk0WhojSsorITsnNTBwUEul+OWvogPsrOz27Rp8/79eyp3jJh7JdTfwL58+XJMIOIJV1dX9q0V7KM8Zj66uUO4b9++R48eubm58epZEoSioqI+//zzJ0+efP/992Y+tFlPR4uKilq3bv3u3bsTJ06MGTPGbMdFqDpOnDgxbtw4FxeXp0+furi4mO24Zl0JY2Nj371717t3b548x4XQh8aOHduvXz+lUmnm7brNtxKmpaW1b9+ebzsLIPQh/R4rv/76q6enp3kOar6VkN3ycdasWZhAxFuenp4zZ87Ub35rHmZaCdnd5pycnBQKRf369c1wRISMo1QqW7durVQqzbbvpjlWQq1Wy74GICYmBhOIeM7FxYXdrpt9IYoZjmiOEO7YsSM9Pb1NmzYLFiwww+EQ4igkJMTT0/PZs2e7d+82w+FMfjqan58vk8mKior4+S4OhD7p0qVLgwcPrl27dnp6uqnfiWLylXDlypVFRUVffvklJhAJyKBBg/72t7+pVKqYmBhTH8u0KyH7fkZra+vHjx/z8/2MCP0Rs72p1rQrYVhYWFVVFftCHJMeCCHiWrVqxe58ERYWZtK1yoQr4fHjxydMmFC/fn2FQuHk5GSioyBkOiqVSiaT5ebmHj9+fNy4cSY6iqlWQrVazd6Wvn79ekwgEqjatWuvWbMGACIjI8vKykx0FFOFcOvWrS9fvuzQocPMmTNNdAiEzGDWrFmdO3d+9erVN998Y6JDmOR0NDs7WyaTlZaWJiUl9e3bl3h9hMzpxo0bPj4+9vb2aWlppngI1iQr4eLFi0tLS8ePH48JRCLQq1evsWPHqtXq5cuXm6I++ZXw1q1bvXr1srOzk8vlLVq0IFscISpevXrVpk0btVptiq3JCK+E+uu50dHRmEAkGs2aNYuIiGAYJjQ0lPh23YRXwoMHD86YMcPV1TU9Pf2zzz4jWBkhusrKyjw8PLKysg4ePDht2jSClUmGsKSkRCaTvXnz5siRI0FBQaTKIsQTR44cmTx5MvEXN5A8Hd2wYcObN2969OgxceJEgmUR4omgoKDevXvn5eVt2rSJYFliK+Hz5889PT01Gs3t27e7detGpCZCfPPw4cOuXbtKJJKUlJTWrVsTqUlsJYyMjCwvL586dSomEIlYp06dJk+eXFFRwd4QRgSZlfCnn37y9fXlycuHETKpvLw8qVSqUqkuXrw4ePBg7gUJrIRVVVXsrjgrVqzABCLRa9iw4dKlS4Hcdt0EQrh3797Hjx+3bNnSnBtUIURRZGRk69atU1NT9+3bx70a19PRwsJCqVT67t27U6dOjRw5kntDCAnCqVOnRo8e7eLiolAo6taty6UU15UwJibm3bt3AwYMwAQiizJq1KjBgwcrlcq1a9dyLMVpJZTL5d7e3jqd7uHDh+3bt+fYCkLCkpqayu5k/fDhw3bt2hldh9NKGB4ertVq586diwlEFqht27azZ8+urKzk+Iox41fCxMTEESNGODs7KxSKevXqcWkCIYFSKpVSqbSgoCAxMdHf39+4IkauhBUVFdHR0QAQGxuLCUQWy8XFZfXq1QAQHh5u9HbdRoZw+/btCoXCw8Nj7ty5xlVASBzmz5/v5eWVkZGxY8cO4yoYczqan58vlUqLi4vPnz/v5+dn3IEREo0rV64MHDjQ0dExPT29cePGhn7cmJVw2bJlxcXFw4cPxwQiBAC+vr7+/v4lJSWrVq0y4uMGr4TJycldunSRSCSPHz+WSqVGHBIh8cnIyPD09NRqtbdv3+7atatBnzVsJWQYJjg4WKfThYaGYgIR0nN3dw8JCdHpdLNmzTJ0/wvDVsJFixbt3LnTwcEhJyenTp06BvaJkJiVlJQ0bty4tLQ0JCTEoIs0BqyESqXy73//OwCMGzcOE4jQRxwdHceMGQMAe/bsyc/Pr/4HDVgJ+/Xrd+3atZo1a6pUKolEYkybCIlaZWWlk5NTaWlpv379rl69Ws1PVXclvHfv3rVr1wBg8+bNmECEPkkikbC75SclJd28ebOan6ruSti8efOsrCw3N7fMzEzje0TIArBhad68+cuXL6vz56u1Et69ezcrKwsAEhISuDQHAHK5/MWLFxyLIGQiL168kMvlHIuwMcnMzLx79251/rzJX5f9ofj4eG9v79DQUHMeFKHqCw0N9fb2jo+PN+tRmepp3rw5ALi5uVXzz39SXl4ee1n1/PnzXOogZAqXLl0CAEdHx5ycHC51mjVrBgAtWrSo5p+vbgj1C+uOHTuM7Y1hGGbLli0A4OHhUVFRwaUOQmRptVovLy8A2Lp1K5c6e/fuZZNy48aNan6kuiFkGKZfv34AULNmTY1GY1R7DMMwGo2GvdXm22+/NboIQsRt374dANzd3cvLy40uotVq2Vew9O/fv/qfMiCEBQUF7HBiypQphrf3/505cwYAnJ2d3759y6UOQqQUFBSwmzUlJiZyqTN58mQAsLGxycvLq/6nDAghwzAhISEA4ODgUFRUZGB7/4N9/GL+/PlciiBEyrx58wDA19eXSxGVSuXg4AAAixYtMuiDhoVQp9N16tQJAKKiogz64EdSU1NtbW1tbGwePXrEpQ5C3KWkpEgkEvbBIC51IiMjAcDb27uqqsqgDxoWQoZhHj58aG1tXaNGjfT0dEM/+6FFixYZeuqMkCkMGjQIAEJDQ7kUefbsmZ2dnbW19b179wz9rMEhZBhm5syZAODv72/EZ/WUSiW7Oc2//vUvLnUQ4uLkyZMA4OLi8u7dOy51hg0bBgDBwcFGfNaYEJIa9+3atQsAWrZsqVarudRByDgajYZ9vdnu3bu51OE4YDQmhAyhcV9lZSW7YenGjRuNLoKQ0TZs2AAAbdu21Wq1RhfhPmA0MoSkxn1XrlwBgFq1amVnZ3Opg5ChcnNz2VdeX7x4kUsd7gNGI0PIMExiYiKRcd+oUaMAYOrUqVyKIGSoKVOmAMDo0aO5FNEPGM+ePWt0EeNDyBAa92VkZNjb21tZWd25c4dLHYSq7/79++xFfoVCwaUOkQEjpxCSGvexr1zs3r27TqfjUgeh6tDpdL179waAZcuWcalDasDIKYQMoXFfSUkJ+4rff/7znxz7QegvHT58GAAaNmxYXFzMpQ6RASPDPYSkxn0HDx4EAFdX15KSEo4tIfQnSktL3dzcAODQoUNc6pAaMDLcQ8gwzO7du7mP+3Q6Xbdu3QBg5cqV3FtC6I+sWLECADp37mzozWUf0g8Y9+zZw70lAiEkNe67deuWlZWVvb39ixcvuHeF0O9lZWU5ODhYWVn9/PPPXOoQGTDqEQghQ27cFxQUBADjxo0j0hVCHxk7diwATJo0iUsRUgNGPTIhZAiN+16/fs0+E3n16lUybSH0f37++WcrKysHB4fMzEwudYgMGD9ELISkxn1r165lnweprKwk1RtCVVVVnTt3BoB169ZxqUNqwPghYiFkCI371Gp1ixYtAOC7774j2BuycOzWL82aNSstLTW6CKkB40dIhpDUuO/48eMAUL9+/cLCQkKtIYtWXFzcqFEjAPjhhx+41CE1YPwIyRAy5MZ9ffv2BYCIiAhSjSFLFh4eDgC9evXico5GasD4e4RDSGrcl5ycbGNjI5FIUlJSSPWGLJNcLre1tbW2tr5//z6XOkQGjJ9EOIQMuXHf7NmzAWDQoEGE+kIWaujQoQAwZ84cLkVIDRg/iXwIGULjvvz8fCcnJwD497//TaoxZGnOnTsHALVr137z5g2XOkQGjH/EJCEkNe5j3zLVqlUrLtsNI4tVUVEhk8kAYNu2bVzqkBow/hGThJAhNO4j9ZeILBORX+KkBox/wlQh1I/79u7dy6UOqdMJZGlIfZ1hXxHPccD450wVQobcuI/IF2tkaYhc2CsuLm7YsCH3AeOfM2EIGULjPlKXmJHlIDXiIjJg/EumDaGw/i6QaAjrt79pQ8gI6qwAiYPgvgeZPIQC+n6MRECIVwRNHkJGOFeKkQgIcTZmjhAKZWaKhE6gd4mYI4SMQO4eQkIn0PslzRRCRgj30SJBE+6TA+YLIf+fKEHCJehn6MwXQob3z1Yi4RL00+RmDSGpcZ+JdhlAAiX0fVXMGkKG0LjPRPvtIIEiu8MYxwGjEcwdQj7vPIeESAR7bZo7hAyP92BFQiSCXacphJDh627kSHDE8f4FOiHk53s5kLCI5k1EdELI8PINVUhYRPNOPmoh5OG7GpGAiOnttNRCyPDvrcVIQMT0nnaaISQ17ktJSZFIJBKJ5PHjx6R6Q3yWmppqa2trY2Pz6NEjLnWIDBi5oxlChty4b968eQDg6+tLqjHEZ35+fgAwf/58LkVIDRi5oxxChtC4r6CgoG7dugBw9uxZUo0hfkpMTAQAZ2fnt2/fcqlDZMBIBP0Qkhr3bd++HQDc3d3Ly8tJ9Yb4RqPRSKVSAPj222+51CE1YCSCfggZQuM+rVbr5eUFAFu3biXYG+KVLVu2AICHh0dFRYXRRUgNGEnhRQhJjfsuXboEAI6Ojjk5OaR6Q/yRl5dXp04dADh//jyXOkQGjATxIoQMuXHfsGHDACA4OJhUY4g/Zs6cCQD+/v5cipAaMBLElxAyhMZ9z549s7Ozs7a2vnv3LqG+EC88fPiQvZCenp7OpQ6RASNZPAohqXFfVFQUAPTs2RO36xaTPn36AEB0dDSXIqQGjGTxKIQMoXGfSqVq1KgRAMTHx5NqDNF17NgxAGjQoEFRURGXOkQGjMTxK4Skxn379u0DgKZNm75//55Ub4iWsrKy5s2bA8D+/fu51CE1YCSOXyFkCI37qqqqunTpAgBr1qwh2BuiIiYmBgA6duzI5Zl3UgNGU+BdCEmN+27cuGFlZVWzZs2XL1+S6g2Z36tXr9hn3q9du8alDpEBo4nwLoQMuXHfhAkTACAwMJBUY8j8AgICACAgIIBLEVIDRhPhYwgZQuO+V69esc/vX79+nVRjyJxu3rxJ5HSGyIDRdHgaQv247969e1zqrF69mv06gdt1C05VVVXXrl0BICYmhksdUgNG0+FpCBmGiYyM5D7u019YO3DgAMHekBl8//33RC5xswPGqKgoUo0Rx98Qkhr3HT16lMiICZmTSqVq3LgxAMTFxXGpQ2rAaFL8DSFDaNyn0+l8fHwAYPHixQR7QyYVHR0NAD169CByHsRxwGhqvA4hqXEf/78VoA+RugGYyIDRDHgdQobcuG/69OkAMGLECEJ9IRMaPnw4AMyYMYNLEVIDRjPgewgZhhk/fjwATJw4kUuR3NxcdlJ04cIFUo0hU7h8+TKRKXFgYCAATJgwgVRjpiOAEOq36+Y47vvqq694e88EYmm12nbt2gHA5s2budTRDxhpbaptEAGEkCE07tPfPbhz506CvSGCduzYQeTOYSIDRrMRRghJjftOnz7Nz/voEcMwSqWSfYbmzJkzXOqQGjCajTBCyJAb9w0ZMgQAFi5cSKoxRMqCBQsAYMCAAVyKkBowmpNgQqgf9y1ZsoRLnSdPnrDPVv/222+kekPcPXnyRCKRcP93Wbx4MfcBo5kJJoQMwzx48IDIuG/hwoXcf+MisgYPHgwAISEhXIroB4zUN9U2iJBCyBAa9+n32zp9+jShvhAnp06dYr+rc9xrj8iA0fwEFkJS476dO3eyO0/idt3U6Xed3bVrF5c6pAaM5iewEDKExn2VlZXsPOqrr74i2BsywqZNm9j914n8g3IcMFIhvBDqf3FyHPexbyMQ4i9OMdG/iYTjqQ07YBToqY3wQsh88BWC47hvxIgRADB9+nRSjSFDTZs2DQBGjhzJpYh+wCjQL/mCDCFDaNyXkZEhxItpoqG/3M3x7ZREBowUCTWEpMZ9S5YsEdxYSRz072leunQplzqkBowUCTWEDKFxn/4Gi6NHj5JqDFXHkSNHAKBhw4bFxcVc6hAZMNIl4BCS+iZw4MABAHB1dRXKrYYiUFZW5ubmBgD/+Mc/uNQhNWCkS8AhZAhdE6uqqurWrRsArF69mmBv6E+sWrUKADp16sTxsRgi18mpE3YISY37hPX4mdCRekCUyICRD4QdQobcuG/ixIkAMH78eFKNoT8ybtw4AAgKCuJShNSAkQ8EH0KG0Ljv9evX7JYkSUlJpBpDv/fLL7+wJx2ZmZlc6hAZMPKEGEJIaty3Zs0aAOjQoQPPN+cSLv32ebGxsVzqkBow8oQYQsgQeoqsrKysRYsWALBv3z6CvSG97777DgCaNWtWWlpqdBFST5byh0hCSGrcFx8fzz6/X1hYSKg19F/FxcXsluoJCQlc6ugHjHzeVNsgIgkhQ27c17dvXwCIjIwk1RhiRUREAECvXr04nq0QGTDyinhCSGqPreTkZBsbmxo1aqSlpRFqDTFPnz7F12z9EfGEkCE37gsODh46dGhGRgahvhCTkZExdOhQji+cJDVg5BtRhZAhtO+yRqMh1Q/6EMe/WCJ7sfOQFcMwICKvX79u06ZNaWlpUlIS++0OicONGzd8fHzs7e3lcjm7Ca1oWNNugLCmTZuyb9UKCwurqqqi3Q4iQ6fThYWFMQyzdOlSkSUQAMS2EgKAWq328PDIzMzcv39/cHAw7XYQAfv37589e3bTpk3T09MdHBxot0OYCEMIAPHx8YGBgQ0aNFAoFOzubEi4SkpKpFJpbm5ufHz8hAkTaLdDnthOR1kBAQF9+vTJz89fv3497V4QV7Gxsbm5uT179mQvzIiPOFdCAEhOTu7atSu764FMJqPdDjLSs2fPvLy8tFrtnTt32PtOxUecKyEAdOzYcfr06RUVFVFRUbR7QcYLCwvTaDQzZ84UawJBxCshAOTn50ul0uLi4vPnz/v5+dFuBxns8uXLgwYNcnR0VCgU7H2noiTalRAAGjRosGLFCgCIiIjQarW020GGqaysDA8PB4DVq1eLOIEg7hACQGhoqFQqlcvle/bsod0LMsyuXbtSUlLc3d1DQkJo92JaYj4dZZ09e3b48OHOzs4KhYJ9GRPiP6VSKZVKCwoKzp49O2zYMNrtmJbIV0IA8Pf39/PzKywsZG/AR4KwYsWKgoKCgQMHij6BYAkrIQDI5XJvb2+dTnfp0qX+/fvTbgf9hevXr/v6+gJAcnKyl5cX7XZMTvwrIQB4eHiMHz++qqpqzJgxtHtBf23UqFGVlZUBAQGWkECwkBACwLp166ytrQsLC9ndaBBvRUdHK5VKKysry/n6YBGno6yAgICEhASJRPL27VsnJyfa7aBPUKlU9erV02q1AQEBx44do92OmVhQCCsqKurUqVNeXj548OCLFy/Sbgd9wuDBgy9dumRnZ1dUVGRvb0+7HTOxlNNRAKhRo8bGjRsB4NKlS8nJybTbQR9LSUlh3zsfGxtrOQkEi1oJWa6urjk5OVZWVlZWVh/+3M7Ojt1WHZmHSqXSaDQf/oTd66FJkybZ2dm0uqJCQrsBc4uLixs9erRSqfzot49arVar1bS6QiwXF5e4uDjaXZibxa2EAKBWq7Oysj76oa2trfge2eazsrKy39/Q6+bmVrNmTSr9UGSJIUSIVyzowgxC/IQhRIgyDCFClGEIEaIMQ4gQZRhChCjDECJEGYYQIcowhAhRhiFEiDIMIUKUYQgRogxDiBBlGEKEKMMQIkQZhhAhyjCECFGGIUSIMgwhQpRhCBGiDEOIEGUYQoQowxAiRBmGECHKMIQIUYYhRIgyDCFClGEIEaIMQ4gQZf8PaksWaQM25q8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "Chem.Draw.MolToImage(Chem.MolFromSmiles(\"C1=CC=CC=C1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xhajek9/miniconda3/envs/BARTtrain/bin/python'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the path of python behind this notebook\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit.Chem.Draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw, MolFromSmiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import pathlib\n",
    "import shutil\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tokenizers\n",
    "import wandb\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import warnings\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Draw, MolFromSmiles, RDKFingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdkit.Chem.rdchem.Mol"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mol = Chem.MolFromSmiles(\"C1=CC=CC=C1\")\n",
    "type(pred_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m PredictionLogger \u001b[39m# compute_cos_simils\u001b[39;00m\n",
      "File \u001b[0;32m~/gc-ms_bart/callbacks.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39micecream\u001b[39;00m \u001b[39mimport\u001b[39;00m ic\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbart_spektro\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_bart_spektro\u001b[39;00m \u001b[39mimport\u001b[39;00m BartSpektroForConditionalGeneration\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_cos_simils\n\u001b[1;32m     24\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPredictionLogger\u001b[39;00m(transformers\u001b[39m.\u001b[39mTrainerCallback):\n\u001b[1;32m     25\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     26\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m         datasets: \u001b[39mlist\u001b[39m[torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mIterableDataset],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39m# super().__init__(**kwargs) # not needed?\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from callbacks import PredictionLogger # compute_cos_simils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"a\":2, \"b\":3}\n",
    "x = a.get(\"c\", None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`Trainer` requires either a `model` or `model_init` argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformers\u001b[39m.\u001b[39;49mTrainer()\n",
      "File \u001b[0;32m~/miniconda3/envs/BARTtrain/lib/python3.8/site-packages/transformers/trainer.py:354\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    352\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_model_init()\n\u001b[1;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`Trainer` requires either a `model` or `model_init` argument\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m model_init \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `Trainer` requires either a `model` or `model_init` argument"
     ]
    }
   ],
   "source": [
    "transformers.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEIMSpy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
